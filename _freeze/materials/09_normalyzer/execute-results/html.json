{
  "hash": "f3d09bba5eb7bd40b01b80cdc202d6cc",
  "result": {
    "markdown": "---\ntitle: Exploring normalisation methods\nbibliography: course_refs.bib\neditor_options: \n  chunk_output_type: console\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n::: callout-tip\n#### Learning Objectives\n\n-   Use the `normalyzer` function from the `NormalyzerDE` package (@Willforss2018) \nto explore the effect of different normalisation methods on the data\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.006.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n::: callout-note\nThis workflow is an adjunct to the [Normalisation and aggregation](./04_normalisation_aggregation.html) \nsection which demonstrates how to normalise proteomics data using the `normalize`\nfunction within the `QFeatures` infrastructure. Please first read through that \nmaterial, since it includes background explanations and discussions which \nare not repeated here.\n:::\n\n\n\n\n\n\n## Using NormalyzerDE\n\nSelecting an appropriate and optimal normalisation method will depend on the \nexact experimental design and data structure. Within the R Bioconductor\npackages, however, exists [`NormalyzerDE`](https://bioconductor.org/packages/release/bioc/html/NormalyzerDE.html) @Willforss2018,\na tool for evaluating different normalisation methods.\n\nThe `NormalyzerDE` package provides a function called `normalyzer` which is \nuseful for getting an overview of how different normalisation methods perform\non a dataset. The `normalyzer` function however **requires a raw intensity matrix\nas input, prior to any log transformation.** Therefore, to use this function we\nneed a non-log protein-level dataset.\n\n1. Create a copy of your `cc_qf` dataset for testing normalisation methods.\nLet's call this `norm_qf`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnorm_qf <- cc_qf\n\nnorm_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 2 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 25687 rows and 10 columns \n```\n:::\n:::\n\n\n2. Take the your data from the `psms_filtered` level and create a new assay in\nyour `QFeatures` object (`norm_qf`) that aggregates the data from this level \ndirectly to protein level. Call this assay `\"proteins_direct\"`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnorm_qf <- aggregateFeatures(norm_qf, \n                             i = \"psms_filtered\",\n                             fcol = \"Master.Protein.Accessions\",\n                             name = \"proteins_direct\",\n                             fun = MsCoreUtils::robustSummary,\n                             na.rm = TRUE)\n\n## Verify\nexperiments(norm_qf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nExperimentList class object of length 3:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns\n [2] psms_filtered: SummarizedExperiment with 25687 rows and 10 columns\n [3] proteins_direct: SummarizedExperiment with 3823 rows and 10 columns\n```\n:::\n:::\n\n\n3. Run the `normalyzer` function on the newly created (untransformed) \nprotein level data using the below code.\n\nNote: To run `normalyzer` on this data we need to pass `requireReplicates =\nFALSE` as we have only one sample of the control. We pass the un-transformed\ndata as the `normalyzer` function does an internal log2 transformation as part\nof its pipeline. For more details on using the `NormalyzerDE` package take a\nlook at the [package vignette](https://bioconductor.org/packages/release/bioc/vignettes/NormalyzerDE/inst/doc/vignette.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnormalyzer(jobName = \"normalyzer\",\n           experimentObj = norm_qf[[\"proteins_direct\"]],\n           sampleColName = \"sample\",\n           groupColName = \"condition\",\n           outputDir = \"normalyzer_output\",\n           requireReplicates = FALSE)\n```\n:::\n\n\nIf your job is successful a new folder will be created in your working directory\nunder `outputs` called `normalyzer`. Take a look at the PDF report. \n\nThe output report contains:\n\n- Total intensity plot: Barplot showing the summed intensity in each sample for the log2-transformed data\n- Total missing plot: Barplot showing the number of missing values found in each sample for the log2-transformed data\n- Log2-MDS plot: MDS plot where data is reduced to two dimensions allowing inspection of the main global changes in the data\n- Scatterplots: The first two samples from each dataset are plotted.\n- Q-Q plots: QQ-plots are plotted for the first sample in each normalized dataset.\n- Boxplots: Boxplots for all samples are plotted and colored according to the replicate grouping.\n- Relative Log Expression (RLE) plots: Relative log expression value plots. Ratio between the expression of the variable and the median expression of this variable across all samples. The samples should be aligned around zero. Any deviation would indicate discrepancies in the data.\n- Density plots: Density distributions for each sample using the density function. Can capture outliers (if single densities lies far from the others) and see if there is batch effects in the dataset (if for instance there is two clear collections of lines in the data).\n- MDS plots: Multidimensional scaling plot using the `cmdscale()` function from the `stats` package. Is often able to show whether replicates group together, and whether there are any clear outliers in the data.\n- Dendograms: Generated using the `hclust` function. Data is centered and scaled prior to analysis. Coloring of replicates is done using `as.phylo` from the `ape` package.\n\n\n## Interpreting the results of Normalyzer\n\nWhen interpreting our `normalyzer` output we need to consider our experimental\ndesign. If all samples come from the same cells and we don't expect the treatment/conditions\nto cause huge changes to the proteome, we expect the distributions of the\nintensities to be roughly the same. We can compare across samples by plotting\nthe distribution in each sample together. When doing this you should get an idea\nof where the majority of the intensities lie. We expect samples from the same\ncondition to have intensities that lie in the same range and if they do not then we\ncan assume that this is due to technical noise, and we want to normalise for this\ntechnical variability. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/density_plots_example.png){#fig-density fig-align='center' width=90%}\n:::\n:::\n\n\n@fig-density shows a screenshot of the PDF report output from running the\n`normalyzer` pipeline. We see that the data before normalisation (log2, topleft)\nhas curves/peaks at different locations and what we want to do is try and\nregister the curves at the same location.\n\n**Which method to choose?** For the use-case data, there is no clear differences\nwhen applying different normalisation methods within `normalyzer`. Really you\nneed to look at the underlying summary statistics. For example, the mean is\nvery sensitive to outliers and in proteomics we often have outliers, so this is\nnot a method we would choose. The median (or median-based methods) are a good\nchoice for most quantitative proteomics data. Quantile normalisation is not\nrecommended for quantitative proteomics data. Quantile methods will not change\nthe median but will change all quantiles of the distribution so that all\ndistributions coincide. We could do this but this often causes problems due to\nthe fact that we have missing data in proteomics. This makes the normalisation\neven more challenging than in other omics types of data.\n\nThe decision is ultimately up to the user, but it is often best to explore \ndifferent normalisation methods and their impact on the data.\n\n## References {.unnumbered}",
    "supporting": [
      "09_normalyzer_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}