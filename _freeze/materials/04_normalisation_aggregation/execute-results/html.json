{
  "hash": "3bc6dda05c71ecbbd4323210a308099f",
  "result": {
    "markdown": "---\ntitle: Data normalisation and data aggregation\nbibliography: course_refs.bib\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.callout-tip}\n#### Learning Objectives\n\n* Be able to aggregate peptide-level information to protein-level using the `aggregateFeatures` function in the `QFeatures` infrastructure\n* Recognise the importance of log transformation (`logTransform`) \n* Know how to normalise your data (using `normalize`) and explore the most appropriate methods for expression proteomics data \n\n:::\n\n\n\n\n\n\n\nLet's start by recapping which stage we have reached in the processing of our \nquantitative proteomics data. In the previous two lessons we have so far learnt,\n\n* how to import our data into R and store it in a `QFeatures` object\n* work with the structure of `QFeatures` objects\n* clean data using a series of non-specific and data-dependent filters\n\nIn this next lesson we will continue processing the PSM level data, explore log\ntransformation, normalisation and then aggregate our data to protein-level\nintensities.\n\n<!-- ```{r, echo = FALSE, fig.align = \"center\", out.width = \"90%\"} -->\n<!-- knitr::include_graphics(\"figs/flow_chart/flow_chart.006.png\", error = FALSE) -->\n<!-- ``` -->\n\n\n## Logarithmic transformation\n\nLet's recap our data,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 2 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 25687 rows and 10 columns \n```\n:::\n:::\n\n\nNow that we are satisfied with our PSM quality, we need to log2 transform the\nquantitative data. If we take a look at our current (raw) quantitative data we will \nsee that our abundance values are dramatically skewed towards zero.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Look at distribution of abundance values in untransformed data\ncc_qf[[\"psms_filtered\"]] %>%\n  assay() %>%\n  longFormat() %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() + \n  theme_bw() +\n  xlab(\"Abundance (raw)\")\n```\n\n::: {.cell-output-display}\n![](04_normalisation_aggregation_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nThis is to be expected since the majority of proteins exist at low abundances\nwithin the cell and only a few proteins are highly abundant. However, if we \nleave the quantitative data in a non-Gaussian distribution then we will not be\nable to apply parametric statistical tests later on. Consider the case where\nwe have a protein with abundance values across three samples A, B and C. If the\nabundance values were 0.1, 1 and 10, we can tell from just looking at the numbers\nthat the protein is 10-fold more abundant in sample B compared to sample A, and\n10-fold more abundant in sample C than sample B. However, even though the fold-changes \nare equal, the abundance values in A and B are much closer together on \na linear scale than those of B and C. A parametric test would not account for \nthis bias and would not consider A and B to be as equally different as B and C.\n**By applying a logarithmic transformation we can convert our skewed asymmetrical data distribution into a symmetrical, Gaussian distribution.**\n\n::: {.callout-note}\n#### Why use base-2?\nAlthough there is no mathematical reason for applying a log2 transformation\nrather than using a higher base such as log10, the log2 scale provides an easy\nvisualisation tool. Any protein that halves in abundance between conditions will\nhave a 0.5 fold change, which translates into a log2 fold change of -1. Any\nprotein that doubles in abundance will have a fold change of 2 and a log2 fold\nchange of +1.\n:::\n\n\n::: {.callout-note}\n#### At which stage of the processing should I perform log transformation?\nLogarithmic transformation can be applied at any stage of the data processing.\nThis decision will depend upon the other data processing steps being completed \nand the methods used to do so. For example, many imputation methods work on \nlog transformed data. We have chosen to log transform the data in this example\nprior to protein aggregation as we will use the `robust` method for summarisation \nand this method requires the data to be log transformed.\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Look at distribution of abundance values in untransformed data\ncc_qf[[\"psms_filtered\"]] %>%\n  assay() %>%\n  longFormat() %>%\n  ggplot(aes(x = log2(value))) +\n  geom_histogram() + \n  theme_bw() +\n  xlab(\"(Log2) Abundance\")\n```\n\n::: {.cell-output-display}\n![](04_normalisation_aggregation_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nTo apply this log2 transformation to our data we use the `logTransform` function\nand specify `base = 2`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- logTransform(object = cc_qf, \n                      base = 2, \n                      i = \"psms_filtered\", \n                      name = \"log_psms\")\n```\n:::\n\n\nLet's take a look again at our `QFeatures` object,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 3 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 25687 rows and 10 columns \n [3] log_psms: SummarizedExperiment with 25687 rows and 10 columns \n```\n:::\n:::\n\n\n\n## Feature aggregation \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.007.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\nWe have now reached the point where we are ready to aggregate our PSM level data\nupward to the protein level. In a bottom-up MS experiment we initially identify\nand quantify peptides. Further, each peptide can be identified and quantified on \nthe basis of multiple matched spectra (the peptide spectrum matches, PSMs). We \nnow want to group information from all PSMs that correspond to the same master\nprotein accession. \n\nTo aggregate upwards from PSM to proteins we can either do this (i) directly\n(from PSM straight to protein, if we are not interested in peptide level\ninformation) or (ii) include an intermediate step of aggregating from PSM to\npeptides, and then from the peptide level to proteins. Which you do will depend\non your biological question. For the purpose of demonstration, let's perform\nthe explicit step of PSM to peptide aggregation.\n\n### Step 1: Aggregation of PSMs to peptides\n\nIn your console run the `aggregateFeatures` function on your `QFeatures` object.\nWe wish to aggregate from PSM to peptide level so pass the argument \n`i = \"log_psms\"` to specify we wish to aggregate the log transformed PSM\ndata, and then pass `fcol = \"Sequence\"` to specify we wish to\ngroup by the peptide amino acid sequence.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- aggregateFeatures(cc_qf, \n                           i = \"log_psms\", \n                           fcol = \"Sequence\",\n                           name = \"log_peptides\",\n                           fun = MsCoreUtils::robustSummary,\n                           na.rm = TRUE)\n\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 4 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 25687 rows and 10 columns \n [3] log_psms: SummarizedExperiment with 25687 rows and 10 columns \n [4] log_peptides: SummarizedExperiment with 17231 rows and 10 columns \n```\n:::\n:::\n\n\nWe see we have created a new assay called `log_peptides` and summarised \n25687 PSMs into 17231\npeptides.\n\nThere are many ways in which we can combine the quantitative values from each of\nthe contributing PSMs into a single consensus peptide or protein quantitation.\nSimple methods for doing this include calculating the peptide or master protein\nquantitation based on the mean, median or sum PSM quantitation. Although the use\nof these simple mathematical functions can be effective, using `colMeans` or\n`colMedians` can become difficult for data sets that still contain missing\nvalues. Similarly, using `colSums` can result in protein quantitation values\nbeing biased by the presence of missing values. That said, when missing values \nare not a problem, `colSums` can provide a beneficial bias towards the more \nabundant PSMs or peptides, which are also more likely to be accurate. Here we will use\n`robustSummary`, a state-of-the art aggregation method that is able to aggregate\neffectively even in the presence of missing values @Sticker2020.\n\n### Step 2: Aggregation of peptides to proteins\n\nLet's complete our aggregation by now aggregating our peptide level data to \nprotein level data. Let's again use the `aggregateFeatures` function and pass\n`fcol = \"Master.Protein.Accessions\"` to specify we wish to\ngroup by `\"Master.Protein.Accessions\"`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- aggregateFeatures(cc_qf, \n                           i = \"log_peptides\", \n                           fcol = \"Master.Protein.Accessions\",\n                           name = \"log_proteins\",\n                           fun = MsCoreUtils::robustSummary,\n                           na.rm = TRUE)\n\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 5 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 25687 rows and 10 columns \n [3] log_psms: SummarizedExperiment with 25687 rows and 10 columns \n [4] log_peptides: SummarizedExperiment with 17231 rows and 10 columns \n [5] log_proteins: SummarizedExperiment with 3823 rows and 10 columns \n```\n:::\n:::\n\n\nWe see we have now created a new assay with 3823 \nprotein groups. \n\n\n::: {.callout-note}\n#### Protein groups\nSince we are aggregating all PSMs that are assigned to the same master protein\naccession, the downstream statistical analysis will be carried out at the \nlevel of protein groups. This is important to consider since most people will \nreport \"proteins\" as displaying significantly different abundances across \nconditions, when in reality they are referring to protein groups.\n\n:::\n\n## Normalisation of quantitative data \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.008.png){fig-align='center' width=90%}\n:::\n:::\n\n\nWe now have log protein level abundance data to which we could apply a parametric\nstatistical test. However, to perform a statistical test and discover whether any \nproteins differ in abundance between conditions (here cell cycle stages), we first\nneed to account for non-biological variance that may contribute to any differential\nabundance. Such variance can arise from experimental error or technical variation,\nalthough the latter is much more prominent when dealing with label-free DDA data.\n\nNormalisation is the process by which we account for non-biological variation in\nprotein abundance between samples and attempt to return our quantitative data \nback to its 'normal' condition i.e., representative of how it was in the original\nbiological system. There are various methods that exist to normalise expression\nproteomics data and it is necessary to consider which of these to apply on a \ncase-by-case basis. Unfortunately, there is not currently a single normalisation \nmethod which performs best for all quantitative proteomics datasets. \n\nIn `QFeatures` we can use the `normalize` function. To see which other \nnormalisation methods are supported within this function, type `?normalize` to \naccess the function's help page. \n\nOf the supported methods, median-based methods work well for most quantitative\nproteomics data. Unlike using the mean, median-based methods are less sensitive\nto the outliers which we often have in proteomics datasets. Let's apply a\ncenter median normalisation approach,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- normalize(cc_qf, \n                   i = \"log_proteins\", \n                   name = \"log_norm_proteins\",\n                   method = \"center.median\")\n```\n:::\n\n\nLet's verify the normalisation  by viewing the `QFeatures` object. We can call\n`experiments` to view all the assays we have created,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexperiments(cc_qf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nExperimentList class object of length 6:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns\n [2] psms_filtered: SummarizedExperiment with 25687 rows and 10 columns\n [3] log_psms: SummarizedExperiment with 25687 rows and 10 columns\n [4] log_peptides: SummarizedExperiment with 17231 rows and 10 columns\n [5] log_proteins: SummarizedExperiment with 3823 rows and 10 columns\n [6] log_norm_proteins: SummarizedExperiment with 3823 rows and 10 columns\n```\n:::\n:::\n\n\n\n:::{.callout-exercise}\n#### Challenge 2: Visualising the data prior and post-normalisation\n\n{{< level 3 >}}\n\n\n\nCreate two boxplots pre- and post-normalisation to visualise the effect it has\nhad on the data and add colour to distinguish between conditions.\n\n::: {.callout-answer collapse=true}\n\nUsing `ggplot2`,\n\n\n::: {.cell}\n\n```{.r .cell-code}\npre_norm <- cc_qf[[\"log_proteins\"]] %>%\n  assay() %>%\n  longFormat() %>%\n  ggplot(aes(x = colname, y = value)) +\n  geom_boxplot() +\n  labs(x = \"Sample\", y = \"log2(abundance)\", title = \"Pre-normalization\") \n\npost_norm <- cc_qf[[\"log_norm_proteins\"]] %>%\n  assay() %>%\n  longFormat() %>%\n  ggplot(aes(x = colname, y = value)) +\n  geom_boxplot() +\n  labs(x = \"Sample\", y = \"log2(abundance)\", title = \"Post-normalization\") \n\npre_norm  + post_norm \n```\n\n::: {.cell-output-display}\n![](04_normalisation_aggregation_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nColour coding by condition,\n\n\n::: {.cell}\n\n```{.r .cell-code}\npre_norm <- cc_qf[[\"log_proteins\"]] %>%\n  assay() %>%\n  longFormat() %>%\n  mutate(Condition = strsplit(as.character(colname), split = \"_\") %>% \n           sapply(\"[[\", 1)) %>%\n  ggplot(aes(x = colname, y = value, fill = Condition))  +\n  geom_boxplot() +\n  labs(x = \"Sample\", y = \"log2(abundance)\", title = \"Pre-normalization\") +\n  theme(legend.position = \"none\")\n\npost_norm <- cc_qf[[\"log_norm_proteins\"]] %>%\n  assay() %>%\n  longFormat() %>%\n  mutate(Condition = strsplit(as.character(colname), split = \"_\") %>% \n           sapply(\"[[\", 1)) %>% \n  ggplot(aes(x = colname, y = value, fill = Condition))  +\n  geom_boxplot() +\n  labs(x = \"Sample\", y = \"log2(abundance)\", title = \"Post-normalization\") \n\npre_norm + post_norm \n```\n\n::: {.cell-output-display}\n![](04_normalisation_aggregation_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n:::\n:::\n\nTo visualise the effect that log transformation followed by normalisation has \nhad on our data, we can also generate density plots. Density plots allow us to\nvisualise the distribution of quantitative values in our data and to see where\nthe majority of intensities lie. \n\n:::{.callout-exercise}\n#### Challenge 3: Visualising the impact of data transformation and normalisation\n\n{{< level 2 >}}\n\n\n\nCreate three density plots to visualise the distribution of intensities in (1) \nthe raw data, (2) the log transformed data and (3) the log normalised data.\n\n::: {.callout-answer collapse=true}\n\nUsing `plotDensities` from the `Limma` package,\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 3))  ## Set up panel to hold three figures\n\ncc_qf[[\"psms_filtered\"]] %>%\n  assay() %>%\n  plotDensities(legend = FALSE, \n                main = \"Raw PSMs\") \n\ncc_qf[[\"log_psms\"]] %>%\n  assay() %>%\n  plotDensities(legend = FALSE, \n                main = \"Log2 PSMs\") \n\ncc_qf[[\"log_norm_proteins\"]] %>%\n  assay() %>%\n  plotDensities(legend = FALSE, \n                main = \"Log2 norm proteins\") \n```\n\n::: {.cell-output-display}\n![](04_normalisation_aggregation_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n:::\n:::\n\nFrom our plots we can see that the center median normalisation has shifted the\ncurves according to their median such that all of the final peaks are overlapping.\nThis is what we would expect given that all of our samples come from the same \ncells and our treatment/conditions don't case massive changes in the proteome.\n\nTo explore the use of alternative normalisation strategies, the [`NormalyzerDE`](https://bioconductor.org/packages/release/bioc/html/NormalyzerDE.html) @Willforss2018 package can be used to compare normalisation approaches.\nPlease refer to the [Using NormalyzerDE to explore normalisation methods](./09_normalyzer.html) section.\n\n\n\n\n\n\n\n::: {.callout-tip}\n#### Key Points\n\n- Expression proteomics data should be log2 transformed to generate a Gaussian distribution which is suitable for parametric statistical testing. This is done using the `logTransform` function.\n- Aggregation from lower level data (e.g., PSM) to high level identification and quantification (e.g., protein) is achieved using the `aggregateFeatures` function, which also creates explicit links between the original and newly created `assays`.\n- To remove non-biological variation, data normalisation should be completed using the `normalize` function. To help users decide which normalisation method is appropriate for their data we recommend using the `normalyzer` function to create a report containing a comparison of methods.\n:::\n\n## References {-}\n",
    "supporting": [
      "04_normalisation_aggregation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}