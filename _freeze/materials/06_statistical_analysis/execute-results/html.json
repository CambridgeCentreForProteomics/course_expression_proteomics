{
  "hash": "bb2c57ffc543da4f29bccf9025ff43ab",
  "result": {
    "markdown": "---\ntitle: Statistical analysis\nbibliography: course_refs.bib\neditor_options: \n  chunk_output_type: console\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n::: callout-tip\n#### Learning Objectives\n\n-   Acknowledge the availability of different R/Bioconductor packages\n    for carrying out differential expression (abundance) analyses\n-   Using the `limma` package, design a statistical model to test for\n    differentially abundant proteins between two conditions\n-   Interpret the output of a statistical model and annotate\n    the results with user-defined significance thresholds\n-   Produce volcano plots and heatmaps to explore the results of differential\n    expression analyses\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.010.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n\n## Differential expression analysis\n\nHaving cleaned our data, aggregated from PSM to protein level, completed\na log2 transformation and normalised the data, we are now ready to carry\nout statistical analysis. \n\nTo simply the statistical analysis, we will focus on just two conditions here:\nM and G1 cell cycle stages. For a more complete statistical analysis of all cell\ncycles stages, please see the [Statistical analysis of all 3 cell cycle stages](./08_statistical_analysis_all_stages.html) section.\n\nThe aim of this section is to answer the\nquestion: *\"Which proteins show a significant change in abundance\nbetween M and G1?\"*.\n\nOur null hypothesis is: **(H0)** The change in abundance for a protein\nbetween cell cycle stages is 0.\n\nOur alternative hypothesis is: **(H1)** The change in abundance for a\nprotein between cell cycle stages is not 0.\n\nWe want to perform a statistical test to determine if there is sufficient evidence to reject the null hypothesis. This is carried out on each protein separately, though as we will see, all proteins are tested simultaneously and there is some sharing of information between the proteins.\n\n## Selecting a statistical test\n\nThere are a few aspects of our data that we need to consider prior to\ndeciding which statistical test to apply.\n\n-   The protein abundances in this data are not normally distributed\n    (i.e., they do not follow a Gaussian distribution). However, they\n    are approximately normal following a log-transformation.\n-   The cell cycle is not expected to have a large impact on biological\n    variability. We can assume that the variance is approximately equal across the groups.\n-   The samples are independent not paired. For example, M_1 is not\n    derived from the same cells as G1_1 and DS_1.\n\nThe first point relates to a key assumption that is made when\ncarrying out **Gaussian Linear modeling**, which assumes that the\nresiduals (difference between the observed values and the values predicted by the\nmodel) are Gaussian distributed. If this assumption is not met,\nthen it is not appropriate to use a Gaussian Linear model. For\nquantitative proteomics data, it's reasonable to assume\nthe residuals will be approximately Gaussian distributed if we first\nlog-transform the abundances.\n\nMany different R packages can be used to carry out differential\nexpression (abundance) analysis on proteomics data. Here we will use\n`limma`, a package that is widely used for omics analysis and can be used in single comparisons or multifactorial experiments using an\n**empirical Bayes-moderated linear model**. A simple example of the empirical\nBayes-moderated linear model is provided in @Hutchings2023. \n\nHere, we will perform a comparison between two groups (M and G1 phases) for each protein. For a multifactorial comparison of all cell cycle stages, see [Statistical analysis of all 3 cell cycle stages](./08_statistical_analysis_all_stages.html).\n\n\n### What does the empirical Bayes part mean?\n\nWhen carrying out high throughput omics experiments we not only have a\npopulation of samples but also a population of features - here we have\nseveral thousand proteins. Proteomics experiments are typically lowly replicated\n(e.g n < 10), therefore, the per-protein variance estimates are relatively\ninaccurate. The empirical Bayes method borrows information across\nfeatures (proteins) and shifts the per-protein variance estimates\ntowards an expected value based on the variance estimates of other\nproteins with a similar abundance. This improves the accuracy of the variance\nestimates, thus reducing false negatives for proteins with over-estimated variance and reducing false positives from proteins with under-estimated variance. For more detail about the empirical Bayes methods, see\n[here](https://online.stat.psu.edu/stat555/node/40/).\n\n\n## Extracting the required data\n\nWe subset to our log2 transformed protein-level data and retain just the M and G1 phase samples\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extract the log-normalised experiment from our QFeatures object\nall_proteins <- cc_qf[[\"log_norm_proteins\"]]\n\n# subset to retain only M and G1 samples\nall_proteins <- all_proteins[, all_proteins$condition %in% c(\"M\", \"G1\")]\n                             \n## Ensure that conditions are stored as levels of a factor with\n## explicitly defined levels\nall_proteins$condition <- factor(all_proteins$condition, \n                                 levels = c(\"M\", \"G1\"))\n```\n:::\n\n\n## Defining the statistical model\n\nBefore we apply our empirical Bayes moderated linear model, we first need\nto set up a model. To define the model design we use `model.matrix`. A\n**model matrix**, also called a design matrix, is a matrix in which rows\nrepresent individual samples and columns correspond to explanatory\nvariables, in our case the cell cycle stages. Simply put, the model\ndesign is determined by how samples are distributed across conditions.\n\nBelow, we define the model matrix with `condition` as the explanatory variable. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Design a matrix containing all factors that we wish to model\ncondition <- all_proteins$condition\n\nm_design <- model.matrix(~condition) # Model with intercept\n```\n:::\n\n\nInspecting the design matrix, we can see that we have a coefficient called `(Intercept)` and a coefficient called `conditionG1`. The first level of the variable (here, M) is considered the 'baseline' and modeled by the intercept. The second level of the variable (here, G1) is then modeled by an additional term in the model, which captures the difference between M and G1. This is the most appropriate way to model the data since the term `conditionG1` captures the difference we are interested in.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Inspect the design matrix\nm_design\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept) conditionG1\n1           1           0\n2           1           0\n3           1           0\n4           1           1\n5           1           1\n6           1           1\nattr(,\"assign\")\n[1] 0 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$condition\n[1] \"contr.treatment\"\n```\n:::\n:::\n\n\n::: callout-note\n\n### What happens if we don't include an intercept?\n\nWhen investigating the effect of a single explanatory variable, the design\nmatrix should be created using `model.matrix(~variable)`, such that an intercept term is included and the other model term captures the difference we are interested in.\n\nIf we specified a model without an intercept (`model.matrix(~0 + variable)`), the resultant coefficients in the model will capture the difference between each group (M or G1) and zero. Given our null hypothesis relates to the difference *between the groups*, not *between each group and zero*, this is not want we want! We could still use contrasts to explore the differences between the groups an intercept term in our model, but it's simpler to work with a model which inherently estimates this difference.\n\n:::\n\n\n## Running an empirical Bayes-moderated test using `limma`\n\nAfter we have specified the design matrix, the next step is to apply the\nstatistical model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Fit linear model using the design matrix and desired contrasts\nfit_model <- lmFit(object = assay(all_proteins), design = m_design)\n```\n:::\n\n\nThe initial model has now been applied to each of the proteins in our\ndata. We now update the model using the `eBayes` function. When we do\nthis we include two other arguments: `trend = TRUE` and `robust = TRUE`. \n\n-   `trend` - takes a logical value of `TRUE` or `FALSE` to indicate\n    whether an intensity-dependent trend should be allowed for the prior\n    variance (i.e., the population level variance prior to empirical\n    Bayes moderation). This means that when the empirical Bayes\n    moderation is applied the protein variances are not squeezed towards\n    a global mean but rather towards an intensity-dependent trend.\n-   `robust` - takes a logical value of `TRUE` or `FALSE` to indicate\n    whether the parameter estimation of the priors should be robust\n    against outlier sample variances.\n    \nSee (@Phipson2016 and @Smyth2004) for further details.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Update the model using the limma eBayes algorithm\n\nfinal_model <- eBayes(fit = fit_model, \n                      trend = TRUE,\n                      robust = TRUE)\n```\n:::\n\n\n### Accessing the model results\n\nThe `topTable` function extracts a table of the top-ranked proteins from\nour fitted linear model. By default, `topTable` outputs a table of the\ntop 10 ranked proteins, that is the 10 proteins with the highest\nlog-odds of being differentially abundant. To get the results for all of\nour proteins we use the `number = Inf` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Format results\nlimma_results <- topTable(fit = final_model,\n                          coef = 'conditionG1',\n                          adjust.method = \"BH\",    # Method for multiple hypothesis testing\n                          number = Inf) %>%        # Print results for all proteins\n  rownames_to_column(\"Protein\") \n\n## Verify\nhead(limma_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Protein     logFC   AveExpr         t      P.Value    adj.P.Val        B\n1  Q9NQW6 -2.077921  2.641270 -40.40812 1.139582e-15 4.356623e-12 25.79468\n2  Q9BW19 -2.343592  1.430210 -36.79774 4.073530e-15 7.786553e-12 24.71272\n3  P49454 -1.991326  2.598481 -34.88623 8.411188e-15 9.266757e-12 24.07905\n4  Q9ULW0 -2.152503  2.476087 -34.52309 9.695796e-15 9.266757e-12 23.95341\n5  Q562F6 -3.205603 -1.304111 -32.91865 1.849860e-14 1.414403e-11 23.37677\n6  O14965 -2.098029  0.797902 -31.22180 3.791132e-14 2.415583e-11 22.72604\n```\n:::\n:::\n\n\nDepending on whether the linear model is used to perform single comparisons or multifactorial comparisons, the test statistic for each protein will either be a t-value or an F-value, respectively. Here, we are performing a single comparison (M vs G1), so we obtain a *t-value*. We also obtain the *p-value* from the comparison of the t-value with a t-distribution.\n\n::: callout-note\n\n### What is a t-value?\n\nA t-value is a parametric statistical value used to compare the mean\nvalues of **two** groups. The t-value is the ratio of the difference in means to\nthe standard error of the difference in means. The further away from zero that a\nt-value lies, the more significant the difference between the groups is.\n:::\n\n::: callout-note\n\n### How is the p-value obtained?\n\nA p-value may be obtained from a t-value by comparing the value against a t-distribution with the appropriate degrees of freedom.\n    \n-   **degrees of freedom** = the number of observations minus the number\n    of independent variables in the model\n-   **p-value** = the probability of achieving the t-value under the\n    null hypothesis i.e., by chance\n    \n:::\n\nWe also see an *adjusted p-value* (`adj.P.Val`) column. This provides p-values adjusted to account\nfor the multiple hypothesis tests performed.\n\n### Multiple hypothesis testing and correction\n\nUsing the linear model defined above, we have carried out a\nstatistical test for each protein.\n\nMultiple testing describes the process of separately testing multiple null\nhypothesis i.e., carrying out many statistical tests at a time, each to\ntest a null hypothesis on different data. Here we have carried out\n3823 hypothesis tests.\nIf we were to use the typical p \\< 0.05 significance threshold for each\ntest, we would expect a 5% chance of incorrectly rejecting the null\nhypothesis *per test*. Here, we would expect approximately\n191 p-values <= 0.05 by chance.\n\nIf we do not account for the fact that we have carried out multiple\nhypothesis, we risk including false positives in our data. Many\nmethods exist to correct for multiple hypothesis testing and these\nmainly fall into two categories:\n\n1.  Control of the Family-Wise Error Rate (FWER)\n2.  Control of the False Discovery Rate (FDR)\n\nAbove we specified the \"BH\" method for adjusting p-values in our `topTable` function call. This is shorthand for the Benjamini-Hochberg procedure, to control the FDR. \n\n::: callout-tip\n#### The False Discovery Rate\n\nThe False Discovery Rate (FDR) defines the fraction of false discoveries\nthat we are willing to tolerate in our list of differential proteins.\nFor example, an FDR threshold of 0.05 means that approximately 5% of the\nproteins deemed differentially abundant will be false positives. It is up to you\nto decide what this threshold should be, but conventionally a value between 0.01\n(1% FPs) and 0.1 (10% FPs) is chosen.\n:::\n\n### Diagnostic plots to verify suitability of our statistical model\n\nAs with all statistical analysis, it is crucial to do some quality\ncontrol and to check that the statistical test that has been applied was\nindeed appropriate for the data. As mentioned above, statistical tests\ntypically come with several assumptions. To check that these assumptions\nwere met and that our model was suitable, we create some diagnostic\nplots.\n\nThe first plot that we generate is an SA plot to display the residual\nstandard deviation (sigma) versus log abundance for each protein to\nwhich our model was fitted. We can use the `plotSA` function to do this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotSA(fit = final_model,\n       cex = 0.5,\n       xlab = \"Average log2 abundance\")\n```\n\n::: {.cell-output-display}\n![](06_statistical_analysis_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nIt is recommended that an SA plot be used as a routine diagnostic plot\nwhen applying a limma-trend pipeline. From the SA plot we can visualise\nthe intensity-dependent trend that has been incorporated into our\nlinear model. It is important to verify that the trend line fits the\ndata well. If we had not included the `trend = TRUE` argument in our\n`eBayes` function, then we would instead see a straight horizontal line\nthat does not follow the trend of the data. Further, the plot also\ncolours any outliers in red. These are the outliers that are only\ndetected and excluded when using the `robust = TRUE` argument.\n\nNext, we plot a histogram of the raw p-values (not adjusted\np-values). This can be done by passing our results data into standard\n`ggplot2` plotting functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlimma_results %>%\n  as_tibble() %>%\n  ggplot(aes(x = P.Value)) + \n  geom_histogram()\n```\n\n::: {.cell-output-display}\n![](06_statistical_analysis_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nThe histogram we have plotted shows an anti-conservative distribution,\nwhich is good. The near-flat distribution across the bottom corresponds to\nnull p-values which are distributed approximately uniformly between 0\nand 1. The peak close to 0 contains a combination of our significantly changing proteins (true positives) and proteins with a low p-value by chance (false positives).\n\nOther examples of how a p-value histogram could look are shown below.\nWhilst in some experiments a uniform p-value distribution may arise due\nto an absence of significant alternative hypotheses, other distribution\nshapes can indicate that something was wrong with the model design or\nstatistical test. For more detail on how to interpret p-value histograms\nthere is a great\n[blog post](http://varianceexplained.org/statistics/interpreting-pvalue-histogram/)\nby David Robinson, from which the examples below are taken.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Examples of p-value histograms.](figs/phist_shapes.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n### Interpreting the output of our statistical model\n\nHaving checked that the model we fitted was appropriate for the data, we\ncan now take a look at the results of our test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(limma_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Protein     logFC   AveExpr         t      P.Value    adj.P.Val        B\n1  Q9NQW6 -2.077921  2.641270 -40.40812 1.139582e-15 4.356623e-12 25.79468\n2  Q9BW19 -2.343592  1.430210 -36.79774 4.073530e-15 7.786553e-12 24.71272\n3  P49454 -1.991326  2.598481 -34.88623 8.411188e-15 9.266757e-12 24.07905\n4  Q9ULW0 -2.152503  2.476087 -34.52309 9.695796e-15 9.266757e-12 23.95341\n5  Q562F6 -3.205603 -1.304111 -32.91865 1.849860e-14 1.414403e-11 23.37677\n6  O14965 -2.098029  0.797902 -31.22180 3.791132e-14 2.415583e-11 22.72604\n```\n:::\n:::\n\n\nInterpreting the output of `topTable`:\n\n-   `logFC` = The observed log2FC for G1 vs M cell cycle stages \n-   `AveExpr` = the average log abundance of the protein across samples\n-   `t` = eBayes moderated t-value. Interpreted in the same way as a\n    normal t-value (see above).\n-   `P.Value` = Unadjusted p-value\n-   `adj.P.Val` = FDR-adjusted p-value (note that this adjustment is only for multiple proteins, not multiple contrasts i.e., separate rather than global correction)\n\nWe have used the statistical test to ask *\"Does this protein show a\nsignificant change in abundance between M and G1 cell cycle stages?\"* for each\nprotein.\n\nOur null hypothesis is: **(H0)** The change in abundance for a protein\nbetween cell cycle stages is 0.\n\nOur alternative hypothesis is: **(H1)** The change in abundance for a\nprotein between cell cycle stages is greater than 0.\n\nFrom our output we can see that some of our proteins have high t-values\nand low adjusted p-values (below any likely threshold of significance).\nThese adjusted p-values tell us that these protein have a significantly\ndifferent abundance across M and G1 cell cycle stages. \n\n#### Adding user-defined significance thresholds\n\nThe output of our statistical test will provide us with key information\nfor each protein, including its p-value, BH-adjusted p-value and logFC.\nHowever, it is up to us to decide what we consider to be significant.\nThe first parameter to consider is the `adj.P.Val` threshold that we wish\nto apply. The second parameter which is sometimes used to define significance\nis the `logFC`. This is mainly because larger fold changes are deemed more likely \nto be 'biologically relevant'.\n\nHere we are going to define significance based on an `adj.P.Val` \\<\n0.01. We can add a column to our results to indicate significance as\nwell as the direction of change.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Add direction and significance information\nlimma_results <- limma_results %>%\n  mutate(direction = ifelse(logFC > 0, \"up\", \"down\"),\n         significance = ifelse(adj.P.Val < 0.01, \"sig\", \"not.sig\"))\n\n\n## Verify\nhead(limma_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Protein     logFC   AveExpr         t      P.Value    adj.P.Val        B\n1  Q9NQW6 -2.077921  2.641270 -40.40812 1.139582e-15 4.356623e-12 25.79468\n2  Q9BW19 -2.343592  1.430210 -36.79774 4.073530e-15 7.786553e-12 24.71272\n3  P49454 -1.991326  2.598481 -34.88623 8.411188e-15 9.266757e-12 24.07905\n4  Q9ULW0 -2.152503  2.476087 -34.52309 9.695796e-15 9.266757e-12 23.95341\n5  Q562F6 -3.205603 -1.304111 -32.91865 1.849860e-14 1.414403e-11 23.37677\n6  O14965 -2.098029  0.797902 -31.22180 3.791132e-14 2.415583e-11 22.72604\n  direction significance\n1      down          sig\n2      down          sig\n3      down          sig\n4      down          sig\n5      down          sig\n6      down          sig\n```\n:::\n:::\n\n\n## Visualising the results of our statistical model\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.011.png){fig-align='center' width=90%}\n:::\n:::\n\n\nThe final step in any statistical analysis is to visualise the results.\nThis is important for ourselves as it allows us to check that the data\nlooks as expected.\n\nThe most common visualisation used to display the results of expression\nproteomics experiments is a volcano plot. This is a scatterplot that\nshows statistical significance (p-values) against the magnitude of fold\nchange. Of note, when we plot the statistical significance we use the\nraw unadjusted p-value (`-log10(P.Value)`). This is because it is better\nto plot the statistical test results in their 'raw' form and not values derived from them (the\nadjusted p-value is derived from each p-value using the BH-method of\ncorrection). Furthermore, the process of FDR correction can result in some points\nthat previously had distinct p-values having the same adjusted p-value.\nFinally, different methods of correction will generate different\nadjusted p-values, making the comparison and interpretation of values\nmore difficult.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlimma_results %>%\n  ggplot(aes(x = logFC, y = -log10(P.Value), fill = significance)) +\n  geom_point(shape = 21, stroke = 0.25, size = 3) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](06_statistical_analysis_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n::: callout-exercise\n#### Challenge: Volcano plots\n\n\n{{< level 2 >}} \n\n\n\nRe-generate your volcano plot defining significance\nbased on an adjusted P-value \\< 0.01 and a log2 fold-change of \\> 1.\n\n::: {.callout-answer collapse=\"true\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_results <- \n  limma_results %>%\n  mutate(direction = ifelse(logFC > 0, \"up\", \"down\"), \n         significance = ifelse(adj.P.Val < 0.01 & abs(logFC) > 1, \"sig\", \"not.sig\"))\n\nmy_results %>%\n  ggplot(aes(x = logFC, y = -log10(P.Value), fill = significance)) +\n  geom_point(shape = 21, stroke = 0.25, size = 3) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](06_statistical_analysis_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n:::\n\n:::\n\n## A more statistically valid way to include a fold-change threshold\n\nAlthough it is commonplace to see a threshold being applied to the point estimate for the log fold-change (logFC) to determine the 'biologically significant' changes, there is a drawback. The point estimate does not take into account the confidence interval for the logFC. As such, proteins with poorly estimated fold-changes are more likely to pass the logFC threshold by chance, while proteins with very well estimated fold-changes which fall just below the threshold would not be deemed biologically significant. \n\nThankfully, `limma` has in-built functions which allows us to specify a different null hypothesis and more appropriately test whether a protein has a fold-change greater than a given value. This test whether the fold-change is greater than a specific value is more stringent than a post-hoc threshold on the point estimate and it thus makes sense to use a slightly lower threshold. Here we will use a threshold of absolute logFC > 0.5 (>1.4 fold-change).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_model_treat <- treat(final_model,\n                           lfc = 0.5, # null hypothesis is 'absolute logFC < 0.5'\n                           trend = TRUE, \n                           robust = TRUE)\n\n# We now need to use TopTreat in place of TopTable\nlimma_results_treat <- topTreat(final_model_treat,\n                                coef = \"conditionG1\",\n                                n = Inf) %>%\n  rownames_to_column(\"Protein\")\n```\n:::\n\n\nAgain, we add columns specifying the direction of change and significance (using the adjusted p-value alone).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Add direction and significance information\nlimma_results_treat <- limma_results_treat %>%\n  mutate(direction = ifelse(logFC > 0, \"up\", \"down\"),\n         significance = ifelse(adj.P.Val < 0.01, \"sig\", \"not.sig\"))\n```\n:::\n\n\nFinally, we visualise the volcano plot.\n\n::: {.cell}\n\n```{.r .cell-code}\nlimma_results_treat %>%\n  ggplot(aes(x = logFC, y = -log10(P.Value), fill = significance)) +\n  geom_point(shape = 21, stroke = 0.25, size = 3) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](06_statistical_analysis_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n::: callout-exercise\n#### Challenge: Compare logFC thresholding post-hoc with LogFC null hypothesis \n\n\n{{< level 3 >}} \n\n\n\n- Compare the overall results for each logFC thresholding approach by creating a 2 x 2 table with the number of proteins with increased/decreased abundance and significant/not significant change, for each approach. \n- Identify the proteins which are significant when using the TREAT functions to define a logFC threshold for the null hypothesis but not when thresholding on the logFC post-hoc. You can use the existing `my_results` and `limma_results_treat` objects for this. \n- Re-make the volcano plots for the two logFC thresholding approaches, but this time with the proteins identified above highlighted by the point shape.\n\\> 1.\n\n::: {.callout-answer collapse=\"true\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tabulate direction of change and significance\n# for both logFC threshold approaches\ntable(my_results$direction,\n      my_results$significance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      \n       not.sig  sig\n  down    1792   35\n  up      1961   35\n```\n:::\n\n```{.r .cell-code}\ntable(limma_results_treat$direction,\n      limma_results_treat$significance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      \n       not.sig  sig\n  down    1791   36\n  up      1974   22\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify the proteins which are significant using \n# TREAT, but not with the post hoc threshold on fold-change\npost_hoc_not_sig <- my_results %>%\n  filter(significance == 'not.sig') %>%\n  pull(Protein)\n\ntreat_sig <- limma_results_treat %>% \n  filter(significance == 'sig') %>%\n  pull(Protein)\n\nsig_treat_only <- intersect(post_hoc_not_sig, treat_sig)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make a volcano plot highlighting these proteins\nmy_results %>%\n  # Add a new column to annotate the proteins to highlight\n  mutate(highlight = Protein %in% sig_treat_only) %>% \n  # Use the highlight column to control the shape aesthetic\n  ggplot(aes(x = logFC, y = -log10(P.Value),\n             fill = significance,\n             shape = highlight)) + \n  geom_point(stroke = 0.25, size = 3) +\n  # Define the shapes\n  scale_shape_manual(values = c(21, 8),\n                     name = 'Post-hoc logFC\\nthresh. sig. only') + \n  guides(fill = guide_legend(override.aes = list(shape=21))) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](06_statistical_analysis_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlimma_results_treat %>%\n  mutate(highlight = Protein %in% sig_treat_only) %>% \n  ggplot(aes(x = logFC, y = -log10(P.Value),\n             fill = significance,\n             shape = highlight)) + \n  geom_point(stroke = 0.25, size = 3) +\n  scale_shape_manual(values = c(21, 8),\n                     name = 'Post-hoc logFC\\nthresh. sig. only') + \n  guides(fill = guide_legend(override.aes = list(shape=21))) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](06_statistical_analysis_files/figure-html/unnamed-chunk-21-2.png){width=672}\n:::\n:::\n\n:::\n\n:::\n:::\n\n## Visualising the protein abundances in a heatmap\n\nAnother widely used visualisation tool is a heatmap. A heatmap is a two-dimensional\nrepresentation of our quantitative data where the magnitude of values are depicted\nby colour. These visualisations are commonly combined with clustering tools to\nfacilitate the identification of groups of features, here proteins, that display\nsimilar quantitative behaviour. Here, we will use the `pheatmap` function from the \n`pheatmap` package to plot a heatmap of proteins that display a significant \ndifference in abundance between M-phase and G1-phase cells. Note that we will plot all samples though, not just M and G1 phase samples.\n\nWe first extract the accessions of proteins with significant differences. We \nuse these accessions to subset the original quantification data which is currently\nstored in the `assay` of our `cp_qf` object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Extract accessions of significant proteins\nsig_proteins <- limma_results %>%\n  filter(significance == \"sig\") %>%\n  pull(Protein)\n\n## Subset quantitative data corresponding to significant proteins\nquant_data <- cc_qf[[\"log_norm_proteins\"]]\n\nquant_data <- quant_data[sig_proteins, ] %>% assay() \n```\n:::\n\n\nNow we use the quantitative data to plot a heatmap using `pheatmap`. We will normalise each row of protein abundances to Z-scores (standard deviations away from the mean).\n\n\n::: {.cell}\n\n```{.r .cell-code}\npheatmap(mat = quant_data,\n         scale = 'row', # Z-score normalise across the rows (proteins)\n         show_rownames = FALSE)  # Too many proteins to show all their names!\n```\n\n::: {.cell-output-display}\n![](06_statistical_analysis_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nA more in-depth overview of `pheatmap` and how to customise these plots further\ncan be found in the documentation (`?pheatmap`) and [here](https://davetang.org/muse/2018/05/15/making-a-heatmap-in-r-with-the-pheatmap-package/).\n\n\n\n\n\n::: {.callout-tip}\n#### Key Points\n\n-   The `limma` package provides a statistical pipeline for the analysis\n    of differential expression (abundance) experiments\n-   Empirical Bayes moderation involves borrowing information across\n    proteins to squeeze the per-protein variance estimates towards an\n    expected value based on the behavior of other proteins with similar\n    abundances. This method increases the statistical power and reduces\n    the number of false positives.\n-   Since proteomics data typically shows an intensity-dependent trend,\n    it is recommended to apply empirical Bayes moderation with\n    `trend = TRUE` and `robust = TRUE`. The validity of this approach can be\n    assessed by plotting an SA plot.\n-   Significance thresholds are somewhat arbitrary and must be selected\n    by the user. However, correction must be carried out for multiple\n    hypothesis testing so significance thresholds should be based on\n    adjusted p-values rather than raw p-values. \n-   The statistically appropriate way to threshold based on a log fold-change is\n    to use the TREAT functions in `limma` and define a null hypothesis that the\n    change is below a given value.\n-   The results of differential expression and abundance analyses are\n    often summarised with volcano plots and heatmaps.\n:::\n\n## References {.unnumbered}\n",
    "supporting": [
      "06_statistical_analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}