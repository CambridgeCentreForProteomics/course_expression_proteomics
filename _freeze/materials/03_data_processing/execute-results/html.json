{
  "hash": "0e93a766210e4e578246b67edf5c7f64",
  "result": {
    "markdown": "---\ntitle: Data processing\nbibliography: course_refs.bib\n---\n\n\n::: {.callout-tip}\n#### Learning Objectives\n\n* Be aware of key data cleaning steps which should or could be completed during the processing of expression proteomics data\n* Make use of the `filterFeatures` function to conditionally remove data from (i) an entire `QFeatures` object or (ii) specified assays of a `QFeatures` object\n* Understand the importance of dealing with missing values in expression proteomics datasets and be aware of different approaches to doing so\n* Be able to aggregate peptide-level information to protein-level using the `aggregateFeatures` function in the `QFeatures` infrastructure\n* Recognise the importance of log transformation (`logTransform`) and normalisation (`normalize`) during the processing of expression proteomics data \n\n:::\n\n\n\n\n\n## Data cleaning at the PSM-level\n\nNow that we have our PSM level quantitative data stored in a `QFeatures` object,\nthe next step is to carry out some data cleaning. However, as with all data \nanalyses, it is sensible to keep a copy of our raw data in case we need to refer\nback to it later. \n\n### Creating a copy of the raw data \n\nTo create a copy of the `psms_raw` data we can first extract the `assay` and \nthen add it back to our `QFeatures` object using the `addAssay` function. When\nwe do this, we give the second `assay` a new name. Here we will call it\n`psms_filtered` as by the end of our data cleaning and filtering, this `assay`\nwill have had the unwanted data removed, whilst the data remains in our \n`psms_raw` `assay`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Extract a copy of the raw PSM-level data\nraw_data_copy <- cc_qf[[\"psms_raw\"]] \n\n## Re-add the assay to our QFeatures object with a new name\ncc_qf <- addAssay(x = cc_qf, \n                  y = raw_data_copy, \n                  name = \"psms_filtered\")\n```\n:::\n\n\n\nWhen we use `addAssay` to add to a `QFeatures` object, the newly created `assay` \ndoes not automatically have links to the pre-exisiting `assay`s. We can use the\n`assayLink()` function to check which links exist for the `psms_filtered` assay. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Check which assay links exist for the psms_filtered assay\nassayLink(x = cc_qf,\n          i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAssayLink for assay <psms_filtered>\n[from:NA|fcol:NA|hits:0]\n```\n:::\n:::\n\n\nAs we expected, no links exist. If we wanted to explicitly add links between two\nassays we could do so using the `addAssayLink` function, as demonstrated below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Create assay link\ncc_qf <- addAssayLink(object = cc_qf, \n                      from = \"psms_filtered\", \n                      to = \"psms_raw\",\n                      varFrom = \"Master.Protein.Accessions\",\n                      varTo = \"Master.Protein.Accessions\")\n\n## Verify\nassayLink(x = cc_qf,\n          i = \"psms_raw\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAssayLink for assay <psms_raw>\n[from:psms_filtered|fcol:Master.Protein.Accessions|hits:2685193]\n```\n:::\n:::\n\n\n\n### Data cleaning using `filterFeatures`\n\nNow that we have created a copy of our raw data, we can start the process of data \ncleaning. We will only remove data from the second copy of our data, the one\nwhich we called `\"psms_filtered\"`. Standard data cleaning steps in proteomics \ninclude the removal of features which: \n\n1. Do not have an associated master protein accession\n2. Have a (master) protein accession matching to a contaminant protein \n3. Do not have quantitative data \n\nThe above steps are necessary for all quantitative proteomics datasets, \nregardless of the experimental goal or data level (PSM or peptide). If a feature\ncannot be identified and quantified then it does not contribute useful \ninformation to our analysis. Similarly, contaminant proteins that are introduced\nintentionally as reagents (e.g., trypsin) or accidentally (e.g., human keratins)\ndo not contribute to our biological question as they were not originally present\nin the samples.\n\nWe also have the option to get rid of any lower quality data by removing those\nfeatures which:\n\n4. Are not rank 1 \n5. Are not unambiguous\n\nSince each spectrum can have multiple potential matches (PSMs), the software \nused for our identification search provides some parameters to help us decide\nhow confident we are in a match. Firstly, each PSM is give a rank based on the\nprobability of it being incorrect - the PSM with the lowest probability of being \nwrong is allocated rank 1. Secondly, each PSM is assigned a level of ambiguity\nto tell us whether it was easy to assign with no other options (unambiguous), \nwhether it was selected as the best match from a series of potential matches \n(selected), or whether it was not possible to distinguish between potential \nmatches (ambiguous). High quality identifications should be both rank 1 and \nunambiguous. The exact filters we set here would depend on how exploratory or \nstringent we wish to be.\n\nFinally, depending upon the experimental question and goal, we may also wish to\nremove features which:\n\n6. Are not unique\n\nThe information regarding each of these parameters is present as a column in the \noutput of our identification search, hence is present in the `rowData` of our\n`QFeatures` object. \n\nTo remove features based on variables within our `rowData` we make use of the\n`filterFeatures` function. This function takes a `QFeatures` object as its\ninput and then filters this object against (indicated by the `~` operator) a\ncondition based on the `rowData`. If the condition is met and returns TRUE for\na feature, this feature will be kept. For example, to remove PSMs that do not\nhave an assigned master protein accession, we can pass `~ Master.Protein.Accessions != \"\"`\nas a condition and only features that do not have (`!=`) an empty `\"Master.Protein.Accessions\"`\ncolumn will be retained.\n\nThe `filterFeatures` function provides the option to apply our filter (i) to the\nwhole `QFeatures` object and all of its `assays`, or (ii) to specific assays within\nthe `QFeatures` object. To prevent removing PSMs from our `\"raw_psms\"` assay, we\nhere specify the `i = \"psms_filtered\"` argument to ensure that the filter is only\napplied to this assay.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## filterFeatures removes any features that return TRUE for the provided statement\n## filterFeatures can be applied to only the assay(s) of choice by specifying the i = argument\ncc_qf <- cc_qf %>% \n  filterFeatures(~ Master.Protein.Accessions != \"\", i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n'Master.Protein.Accessions' found in 2 out of 2 assay(s)\n```\n:::\n:::\n\n\n\n**Make into a challenge** \n\nUse filterFeatures to carry out the rest of the data cleaning steps described\nabove. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>% \n  filterFeatures(~ Contaminant != \"True\", i = \"psms_filtered\") %>%\n  filterFeatures(~ Quan.Info != \"NoQuanLabels\", i = \"psms_filtered\") %>%\n  filterFeatures(~ Rank == 1, i = \"psms_filtered\") %>%\n  filterFeatures(~ Search.Engine.Rank == 1, i = \"psms_filtered\") %>%\n  filterFeatures(~ PSM.Ambiguity == \"Unambiguous\", i = \"psms_filtered\") %>%\n  filterFeatures(~ Number.of.Protein.Groups == 1, i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n'Contaminant' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'Quan.Info' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'Rank' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'Search.Engine.Rank' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'PSM.Ambiguity' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'Number.of.Protein.Groups' found in 2 out of 2 assay(s)\n```\n:::\n:::\n\n\n\n### Addititional quality control filters available for TMT data\n\nAs well as the completion of standard data cleaning steps which are common to \nall quantitative proteomics experiments (see above), different experimental \nmethods are accompanied by additional data processing considerations. Although\nwe cannot provide an extensive discussion of all methods, we will draw attention\nto three key quality control parameters to consider for our use-case TMT data. \n\n1. Average reporter ion signal-to-noise (S/N)\n\nThe quantitation of a TMT experiment is dependent upon the measurement of \nreporter ion signals from either the MS2 or MS3 spectra. Since reporter ion\nmeasurements derived from a small number of ions are more prone to stochastic\nion effects and reduced quantitative accuracy, we want to remove PSMs that rely \nsuch quantitation to ensure high data quality. When using an orbitrap analyser, \nthe number of ions is proportional to the S/N ratio of a peak. Hence, removing\nPSMs that have a low S/N value acts as a proxy for removing low quality\nquantitation. \n\n2. Isolation interference (%)\n\nIsolation interference occurs when multiple TMT-labelled precursor peptides are\nco-isolated within a single data acquisition window. All co-isolated peptides go\non to be fragmented together and reporter ions from all peptides contribute to\nthe reporter ion signal. Hence, quantification for the identified peptide becomes\ninaccurate. To minimise the co-isolation interference problem observed at MS2,\nMS3-based analysis can be used @McAlister2014. Nevertheless, we remove PSMs with \na high percentage isolation interference to prevent the inclusion of inaccurate \nquantitation values.\n\n3. Synchronous precursor selection mass matches (%) - SPS-MM\n\nSPS-MM is a parameter unique to the Proteome Discoverer software which lets users\nquantify the percentage of MS3 fragments that can be explicitly traced back to\nthe precursor peptides. This is important given that quantitation is based on\nthe MS3 spectra.\n\nHere we will apply the default quality control thresholds as suggested by \nThermo Fisher and keep features with:\n\n* Average reporter ion S/N >= 10\n* Isolation interference < 75%\n* SPS-MM >= 65%\n\nWe also remove features that do not have information regarding these quality\ncontrol parameters i.e., have an NA value in the corresponding columns of the\n`rowData`. To remove these features we include the `na.rm = TRUE` argument.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>% \n  filterFeatures(~ Average.Reporter.SN >= 10, na.rm = TRUE, i = \"psms_filtered\") %>%\n  filterFeatures(~ Isolation.Interference.in.Percent <= 75, na.rm = TRUE, i = \"psms_filtered\") %>%\n  filterFeatures(~ SPS.Mass.Matches.in.Percent >= 65, na.rm = TRUE, i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n'Average.Reporter.SN' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'Isolation.Interference.in.Percent' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'SPS.Mass.Matches.in.Percent' found in 2 out of 2 assay(s)\n```\n:::\n:::\n\n\n\nIn reality, we advise that users take a look at their data to decide whether the\ndefault quality control thresholds applied above are appropriate. If there is\nreason to believe that the raw MS data was of lower quality than desired, it\nmay be sensible to apply stricter thresholds here. Similarly, if users wish to \ncarry out a more stringent or exploratory analyses, these thresholds can be \naltered accordingly.\n\n\n## Management of missing data \n\nHaving cleaned our data, the next step is to deal with missing values. It is \nimportant to be aware that missing values can arise for different reasons in \nMS data, and these reasons determine the best way to deal with the missing data.\n\n* Biological reasons - a peptide may be genuinely absent from a sample or have such low abundance that it is below the limit of MS detection\n* Technical reasons - technical variation and the stocastic nature of MS (particularly using DDA) may lead to some peptides not being quantified. Some peptides have a lower ionization efficiency which makes them less compatible with MS analysis\n\nMissing values that arise for different reasons can generally be deciphered by \ntheir pattern. For example, peptides that have missing quantitation values for\nbiological reasons tend to be low intensity or completely absent peptides. Hence,\nthese missing values are **missing not at random (MNAR)** and appear in an\nintensity-dependent pattern. By contrast, peptides that do not have quantitation\ndue to technical reasons are **missing completely at random (MCAR)** and appear\nin an intensity-independent manner.\n\n\n### Influence of experimental design  \n\nAll quantitative proteomics datasets will have some number of missing values, \nalthough the extent of data missingness differs between label-free and label-based\nDDA experiments as well as between DDA and DIA label-free experiments. \n\nWhen carrying out a label-free DDA experiment, all samples are analysed via \nindependent MS runs. Since the selection of precursor ions for fragmentation is\nsomewhat stochastic in DDA (e.g., top *N* most abundant precursors are selected)\nexperiments, different peptides may be identified and quantified across the \ndifferent samples. In other words, not all peptides that are analysed in one \nsample will be analysed in the next, thus introducing a high proportion of \nmissing values.\n\nOne of the advantages of using TMT labelling is the ability to multiplex samples\ninto a single MS run. In the use-case, 10 samples were TMT labelled and pooled\ntogether prior to DDA MS analysis. As a result, the same peptides were quantified\nfor all samples and we expect a lower proportion of missing values than if we\nwere to use label-free DDA. \n\nMore recently, DIA MS analysis of label-free samples has increased in popularity.\nHere, instead of selecting a limited number of precursor peptides (typically the\nmost abundance) for subsequent fragmentation and analysis, all precursors within\na selected *m/z* window are selected. The analysis of all precursor ions within\na defined range in every run results in more consistent coverage and accuracy\nthan DDA experiments, hence lower missing values.\n\n\n### Exploration of missing data\n\nThe management of missing data can be considered in three main steps:\n\n1. Exploration of missing data - determine the number and pattern of missing values\n2. Removal of data with high levels of missingness - this could be features with missing values across too many samples or samples with an abnormally high proportion of missingness compared to the average\n3. Imputation (optional)\n\n**Note**  \nBefore we begin managing the missing data, we first need to know what missing data\nlooks like. In our data, missing values are notated as `NA` values. Alternative \nsoftware may display missing values as being zero, or even infinite if \nnormalisation has been applied during the database search. All functions used for\nthe management of missing data within the `QFeatures` infrastructure use the `NA` \nnotation. If we were dealing with a dataset that had an alternative encoding, we\ncould apply the `zeroIsNA()` or `infIsNA()` functions to convert missing values\ninto `NA` values.\n\nThe main function that facilitates the exploration of missing data in `QFeatures`\nis `nNA`. Let's try to use this function. Again, we use the `i = ` argument to\nspecify which assay within the `QFeatures` object that we wish to look at.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnNA(cc_qf, i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$nNA\nDataFrame with 1 row and 3 columns\n          assay       nNA        pNA\n    <character> <integer>  <numeric>\n1 psms_filte...        14 0.00542888\n\n$nNArows\nDataFrame with 25788 rows and 4 columns\n              assay        name       nNA       pNA\n        <character> <character> <integer> <numeric>\n1     psms_filte...           7         0         0\n2     psms_filte...           8         0         0\n3     psms_filte...           9         0         0\n4     psms_filte...          16         0         0\n5     psms_filte...          18         0         0\n...             ...         ...       ...       ...\n25784 psms_filte...       45748         0         0\n25785 psms_filte...       45752         0         0\n25786 psms_filte...       45753         0         0\n25787 psms_filte...       45777         0         0\n25788 psms_filte...       45784         0         0\n\n$nNAcols\nDataFrame with 10 rows and 4 columns\n           assay        name       nNA        pNA\n     <character> <character> <integer>  <numeric>\n1  psms_filte...     Control         4 0.01551109\n2  psms_filte...         M_1         0 0.00000000\n3  psms_filte...         M_2         9 0.03489995\n4  psms_filte...         M_3         1 0.00387777\n5  psms_filte...        G1_1         0 0.00000000\n6  psms_filte...        G1_2         0 0.00000000\n7  psms_filte...        G1_3         0 0.00000000\n8  psms_filte...        DS_1         0 0.00000000\n9  psms_filte...        DS_2         0 0.00000000\n10 psms_filte...        DS_3         0 0.00000000\n```\n:::\n:::\n\n\nThe output from this function is a list of three data frames. The first of these\n(called `nNA`) gives us information about missing data at the global level (i.e.,\nfor the entire assay). We get information about the absolute number of missing\nvalues (`nNA`) and the proportion of the total data set that is missing values\n(`pNA`). The next two data frames also give us `nNA` and `pNA` but this time on \na per row/feature (`nNArows`) and per column/sample (`nNAcols`) basis.\n\nTo access one `DataFrame` within a list we use the standard `$` operator, \nfollowed by another `$` operator if we wish to access specific columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Output the number of missing values (nNA) per column (nNAcols)\nnNA(cc_qf, i = \"psms_filtered\")$nNAcols$nNA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 4 0 9 1 0 0 0 0 0 0\n```\n:::\n:::\n\n\n\nWe can also pass the output data from `nNA` to `ggplot` to visualise the missing\ndata. This is particularly useful so that we can see whether any of our samples\nhave an abnormally high proportion of missing values compared to the average. This\ncould be the case if something had gone wrong during sample preparation. It is \nalso useful to see whether there is any specific conditions that have a greater\nnumber of missing values.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Visualise the proportion of missing values per sample - check for sample and condition bias\n\n## Look at the raw PSMs\nnNA(cc_qf[[\"psms_raw\"]])$nNAcols %>%\n  as_tibble() %>%\n  mutate(condition = colData(cc_qf)$condition) %>%\n  ggplot(aes(x = name, y = pNA, group = condition, fill = condition)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Sample\", y = \"Missing values (%)\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](03_data_processing_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Look at the filtered PSMs\nnNA(cc_qf[[\"psms_filtered\"]])$nNAcols %>%\n  as_tibble() %>%\n  mutate(condition = colData(cc_qf)$condition) %>%\n  ggplot(aes(x = name, y = pNA, group = condition, fill = condition)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Sample\", y = \"Missing values (%)\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](03_data_processing_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n:::\n\n\n\n**note** **put into a box** \nIn this experiment we expect all samples to have a low proportion of missing \nvalues due to the TMT labelling strategy. We also expect that all samples should\nhave a similar proportion of missing values because we do not expect cell cycle\nstage to have a large impact on the majority of the proteome. Hence, the samples\nhere should be very similar. This is the case in most expression proteomics\nexperiments which aim to identify differential protein abundance upon a cellular\nperturbation. However, in some other MS-based proteomics experiments this would\nnot be the case. For example, proximity labelling and co-immunoprecipitation \n(Co-IP) experiments have control samples that are not expected to have any proteins\nin, although there is always a small amount of unwanted noise. In such cases it \nwould be expected to have control samples with a large proportion of missing\nvalues and experimental samples with a much lower proportion. It is important to\ncheck that the data corresponds to the experimental setup.\n\n\n**Challenge**\nIdeas ...\nSomething to do with missing data across rows - prior to filtering based on a \nfeature having >20% missing values. Ask them to work out how many this will be?\nAsk them to work out the max and min number of missing values per feature?\nAsk them to create a plot looking at the number of missing values across the\nintensity distribution (are they intensity dependent or independent?)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnNA(cc_qf[[\"psms_filtered\"]])$nNArows$nNA %>%\n  max()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3\n```\n:::\n\n```{.r .cell-code}\nnNA(cc_qf[[\"psms_filtered\"]])$nNArows$pNA %>%\n  max()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 30\n```\n:::\n:::\n\n\n\n### Removing data with high levels of missingness\n\nAlthough the use-case data has only a small number of missing values it is still\ncommon to remove individual features that have too many missing values across\nsamples. Here, we remove PSMs that have >20% missing values. This is done using\nthe `filterNA` function where the `pNA` argument specifies the maximum proportion\nof missing values to allow per feature.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>%\n  filterNA(pNA = 0.2, i = \"psms_filtered\")\n```\n:::\n\n\n\nWe already established that none of our samples have an abnormally high \nproportion of missing values (relative to the average). Therefore, we do not\nneed to remove any entire samples/columns.\n\n\n### Imputation of remaining missing values\n\nThe final step in managing our missing data is to consider whether to impute.\nImputation involves the replacement of missing values with probable values.\nUnfortunately, estimating probable values is difficult and requires complex \nassumptions about why a value is missing. For example, if a value is missing \nbecause a peptide is completely absent or present at an abundance below the limit\nof detection then the most suitable replacement value is arguably the lowest\nabundance value recorded in the data set (since this represents the limit of\ndetection). Alternatively, if a value is missing because of stochastic technical\nreasons then it might be more appropriate to replace it with a value derived \nfrom a similar peptide. Overall, left-censored methods such as minimal value and\nlimit of detection approaches work best for data that is MNAR (intensity-dependent\nmissing values). Hot deck methods such as k-nearest neighbors, random forest and \nmaximum likelihood methods work better for data that is MCAR (intensity-independent).\nTo confuse the situation further, most data sets contain missing values that are\na mixture of MNAR and MCAR, so mixed imputation methods can be applied.\n\nGiven that imputation is difficult to get right and can have substantial effects\non the results of downstream analysis, it is generally recommended to avoid\nit where we can. This means that if there is not a large proportion of missing\nvalues in our data, we should not impute. \n\nWe can now check to see how many missing values remain in the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnNA(cc_qf[[\"psms_filtered\"]])$nNA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDataFrame with 1 row and 2 columns\n        nNA        pNA\n  <integer>  <numeric>\n1        11 0.00426572\n```\n:::\n:::\n\n\nWe only have 0.0042657% missing values in our\ndata, so imputation is not really necessary here. We could either remove the \nPSMs that still have missing values or continue our analysis. The latter is \npossible since missing values are often lost during aggregation and there are\nnow aggregation methods that are able to deal with missing data.\n\nFor demonstration purposes we will carry out imputation anyway. Since we are \nonly imputing 11 values we do not expect\na large effect on the data structure or downstream analysis.\n\nImputation within the `QFeatures` infrastructure is completed using the `impute`\nfunction. To see what imputation methods this function facilitates we can use\n`MsCoreUtils::imputeMethods()`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Check which imputation methods are available within the QFeatures impute function\nMsCoreUtils::imputeMethods()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"bpca\"    \"knn\"     \"QRILC\"   \"MLE\"     \"MLE2\"    \"MinDet\"  \"MinProb\"\n [8] \"min\"     \"zero\"    \"mixed\"   \"nbavg\"   \"with\"    \"RF\"      \"none\"   \n```\n:::\n:::\n\n\n\nHere we will use a k-nearest neighbors (k-NN) method.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- impute(object = cc_qf,\n                method = \"knn\", \n                i = \"psms_filtered\",\n                name = \"psms_imputed\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required namespace: impute\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nImputing along margin 1 (features/rows).\n```\n:::\n:::\n\n\n\n## Logarithmic transformation\n\nNow that we are satisfied with our PSM quality, we need to log2 transform the\nquantitative data. If we take a look at our current quantitative data we will \nsee that our abundance values are dramatically skewed towards zero.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Look at distribution of abundance values in untransformed data\ncc_qf[[\"psms_imputed\"]] %>%\n  assay() %>%\n  longFormat() %>%\n  ggplot(aes(x = value)) +\n  geom_histogram() + \n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](03_data_processing_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\nThis is to be expected since the majority of proteins exist at low abundances\nwithin the cell and only a few proteins are highly abundant. However, if we \nleave the quantitative data in a non-Gaussian distribution then we will not be\nable to apply parametric statistical tests later on. Consider the case where\nwe have a protein with abundance values across three samples A, B and C. If the\nabundance values were 0.1, 1 and 10, we can tell from just looking at the numbers\nthat the protein is 10-fold more abundant in sample B compared to sample A, and\n10-fold more abundant in sample C than sample B. However, even though the fold-\nchanges are equal, the abundance values in A and B are much closer together on \na linear scale than those of B and C. A parametric test would not account for \nthis bias and would not consider A and B to be as equally different as B and C.\n\nBy applying a logarithmic transformation (log2 is the standard for proteomics\ndata) we can convert our skewed asymmetrical data distribution into a symmetrical,\nGaussian distribution, as visualised below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Look at distribution of abundance values in untransformed data\ncc_qf[[\"psms_imputed\"]] %>%\n  assay() %>%\n  longFormat() %>%\n  ggplot(aes(x = log2(value))) +\n  geom_histogram() + \n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](03_data_processing_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\nTo apply this log2 transformation to our data we use the `logTransform` function\nand specify `base = 2`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- logTransform(object = cc_qf, \n                      base = 2, \n                      i = \"psms_imputed\", \n                      name = \"log_imputed_psms\")\n```\n:::\n\n\n\n## Aggregation of PSMs to proteins\n\nWe have now reached the point where we are ready to aggregate our PSM level data\nupward to the protein level. In a bottom-up MS experiment we initially identify\nand quantify peptides. Further, each peptide can be identified and quantified on \nthe basis of multiple matched spectra (the peptide spectrum matches, PSMs). We \nnow want to group information from all PSMs that correspond to the same master\nprotein accession. \n\nWe are going to aggregate all PSMs from our `\"log_imputed_psms\"` assay that have\nthe same value in the `\"Master.Protein.Accessions\"` column of the `rowData`.\nThere are many ways in which we can combine the quantitative values from each of\nthe contributing PSMs into a single consensus protein quantitation. Simple methods\nfor doing this include calculating the master protein quantitation based on the \nmean, median or sum PSM quantitation. Although the use of these simple \nmathematical functions can be effective, using `colMeans` or `colMedians` can\nbecome difficult for data sets that still contain missing values. Similarly, \nusing `colSums` can result in protein quantitation values being biased by the\npresence of missing values. Here we will use `robustSummary`, a state-of-the\nart aggregation method that is able to aggregate effectively even in the \npresence of missing values @Sticker2020.\n\n\n**note** **potentially add to a box**\nSince we are aggregating all PSMs that are assigned to the same master protein\naccession, the downstream statistical analysis will be carried out at the \nlevel of protein groups. This is important to consider since most people will \nreport \"proteins\" as displaying significantly different abundances across \nconditions, when in reality they are referring to protein groups.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- aggregateFeatures(cc_qf, \n                           i = \"log_imputed_psms\", \n                           fcol = \"Master.Protein.Accessions\",\n                           name = \"log_proteins\",\n                           fun = MsCoreUtils::robustSummary,\n                           na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nYour row data contain missing values. Please read the relevant\nsection(s) in the aggregateFeatures manual page regarding the effects\nof missing values on data aggregation.\n```\n:::\n:::\n\n\n\n\n## Normalisation of quantitative data \n\nWe now have log protein level abundance data to which we could apply a parametric\nstatistical test. However, to perform a statistical test and discover whether any \nproteins differ in abundance between conditions (here cell cycle stages), we first\nneed to account for non-biological variance that may contribute to any differential\nabundance. Such variance can arise from experimental error or technical variation,\nalthough the latter is much more prominent when dealing with label-free DDA data.\n\nNormalisation is the process by which we account for non-biological variation in\nprotein abundance between samples and attempt to return our quantitative data \nback to its 'normal' condition i.e., representative of how it was in the original\nbiological system. There are various methods that exist to normalise expression\nproteomics data and it is necessary to consider which of these to apply on a \ncase-by-case basis.\n\n\n**Challenge: apply Normalyzer to non-log protein data**\nAsk them to aggregate directly from psms_filtered to proteins and call the assay\n\"raw_proteins\". Use this assay as input to the Normalyzer. Look at report and\ndetermine most appropriate normalisation strategy for the data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(NormalyzerDE)\ncc_qf <- aggregateFeatures(cc_qf,\n                           i = \"psms_imputed\",\n                           fcol = \"Master.Protein.Accessions\",\n                           name = \"raw_proteins\", \n                           fun = MsCoreUtils::robustSummary,\n                           na.rm = TRUE)\n\nnormalyzer(jobName = \"normalyzer\",\n           experimentObj = cc_qf[[\"raw_proteins\"]][,-1],\n           sampleColName = \"sample\",\n           groupColName = \"condition\",\n           outputDir = \".\")\n```\n:::\n\n\n\nTo demonstrate the approach to normalisation within `QFeatures`, we here normalise \nusing a center median method. This is achieved using the `normalize` function.\nTo see which other normalisation methods are supported within this function,\ntype `?normalize` to access the function's help page.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- normalize(cc_qf, \n                   i = \"log_proteins\", \n                   name = \"log_norm_proteins\",\n                   method = \"center.median\")\n```\n:::\n\n\n\n**Challenge**\nCreate two boxplots to visualise the process of normalisation?? \n\n\n**Challenge**\nDetermine how many PSMs, peptides and proteins were lost during processing of\nraw data to our final protein list?\n\n\n\n\n\n::: {.callout-tip}\n#### Key Points\n\n- The `filterFeatures` function can be used to remove data from a `QFeatures` object (or an `assay` within a `QFeatures` object) based on filtering parameters within the `rowData`.\n- Data processing includes (i) standard proteomics data cleaning steps e.g., removal of contaminants, and (ii) data-specific quality control filtering e.g., co-isolation interference thresholding for TMT data.\n- The management of missing quantitative data in expression proteomics data is complex. The `nNA` function can be used to explore missing data and the `filterNA` function can be used to remove features with undesirably high levels of missing data. Where imputation is absolutely necessary, the `impute` function exists within the `QFeatures` infrastructure.\n- Expression proteomics data should be log2 transformed to generate a Gaussian distribution which is suitable for parametric statistical testing. This is done using the `logTransform` function.\n- Aggregation from lower level data (e.g., PSM) to high level identification and quantification (e.g., protein) is achieved using the `aggregateFeatures` function, which also creates explicit links between the original and newly created `assays`.\n- To remove non-biological variation, data normalisation should be completed using the `normalize` function. To help users decide which normalisation method is appropriate for their data we recommend using the `normalyzer` function to create a report containing a comparison of methods.\n\n:::\n\n## References {-}\n",
    "supporting": [
      "03_data_processing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}