{
  "hash": "29055ff8bf0cb02fb091e408854e2098",
  "result": {
    "markdown": "---\ntitle: Data cleaning\nbibliography: course_refs.bib\n---\n\n\n::: {.callout-tip}\n#### Learning Objectives\n\n* Be aware of key data cleaning steps which should or could be completed during the processing of expression proteomics data\n* Make use of the `filterFeatures` function to conditionally remove data from (i) an entire `QFeatures` object or (ii) specified `experiment assays` of a `QFeatures` object\n* Understand the difference between non-specific and data-dependent filtering  \n* Be able to explore the metadata stored in the `rowData` and get a feel for how to make your own data-dependent decisions regarding data cleaning\n* Understand the importance of dealing with missing values in expression proteomics datasets and be aware of different approaches to doing so\n\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.002.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n\n\nNow that we have our PSM level quantitative data stored in a `QFeatures` object,\nthe next step is to carry out some data cleaning. However, as with all data \nanalyses, it is sensible to keep a copy of our raw data in case we need to refer\nback to it later. \n\n## Creating a copy of the raw data \n\nTo create a copy of the `psms_raw` data we can first extract the `experiment assay`\nand then add it back to our `QFeatures` object using the `addAssay` function.\nWhen we do this, we give the second `experiment assay` (our copy) a new name. Here we will\ncall it `psms_filtered` as by the end of our data cleaning and filtering, this\ncopy will have had the unwanted data removed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Extract a copy of the raw PSM-level data\nraw_data_copy <- cc_qf[[\"psms_raw\"]] \n\n## Re-add the assay to our QFeatures object with a new name\ncc_qf <- addAssay(x = cc_qf, \n                  y = raw_data_copy, \n                  name = \"psms_filtered\")\n\n## Verify\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 2 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 45803 rows and 10 columns \n```\n:::\n:::\n\n\nWe now see that a second `experiment assay` has been added to the `QFeatures`\nobject. When we use `addAssay` to add to a `QFeatures` object, the newly created\n`experiment assay` does not automatically have links to the pre-existing \n`experiment assay`s. We can use the `assayLink()` function to check which links\nexist for `psms_filtered`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Check which assay links exist for the psms_filtered assay\nassayLink(x = cc_qf,\n          i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAssayLink for assay <psms_filtered>\n[from:NA|fcol:NA|hits:0]\n```\n:::\n:::\n\n\nAs we expected, no links exist. If we wanted to explicitly add links between two\ndata we could do so using the `addAssayLink` function, as demonstrated below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Create assay link\ncc_qf <- addAssayLink(object = cc_qf, \n                      from = \"psms_filtered\", \n                      to = \"psms_raw\",\n                      varFrom = \"Master.Protein.Accessions\",\n                      varTo = \"Master.Protein.Accessions\")\n\n## Verify\nassayLink(x = cc_qf,\n          i = \"psms_raw\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAssayLink for assay <psms_raw>\n[from:psms_filtered|fcol:Master.Protein.Accessions|hits:2685193]\n```\n:::\n:::\n\n\nAdding a relation between these two `experiment assays` ensure traceability. We\nwill learn more about assay links as we progress through this course.\n\n::: {.callout-note}\n#### Assay links\n`QFeatures` maintains the hierarchical links between quantitative levels whilst\nallowing easy access to all data levels for individual features (PSMs, peptides \nand proteins) of interest. This is fundamental to the `QFeatures` \ninfrastructure and will be exemplified throughout this course.\n\n:::\n\n\n## Data cleaning\n\nNow that we have created a copy of our raw data, we can start the process of data \ncleaning. We will only remove data from the second copy of our data, the one\nwhich we have called `\"psms_filtered\"`. Standard data cleaning steps in proteomics \ninclude the removal of features which: \n\n1. *Do not have an associated master protein accession*\n2. *Have a (master) protein accession matching to a contaminant protein*\n3. *Do not have quantitative data*\n\nThe above steps are necessary for all quantitative proteomics datasets, \nregardless of the experimental goal or data level (PSM or peptide). If a feature\ncannot be identified and quantified then it does not contribute useful \ninformation to our analysis. Similarly, contaminant proteins that are introduced\nintentionally as reagents (e.g., trypsin) or accidentally (e.g., human keratins)\ndo not contribute to our biological question as they were not originally present\nin the samples.\n\nWe also have the option to get rid of any lower quality data by removing those\nfeatures which:\n\n4. *Are not rank 1* \n5. *Are not unambiguous*\n\nSince each spectrum can have multiple potential matches (PSMs), the software \nused for our identification search provides some parameters to help us decide\nhow confident we are in a match. Firstly, each PSM is given a rank based on the\nprobability of it being incorrect - the PSM with the lowest probability of being \nwrong is allocated rank 1. Secondly, each PSM is assigned a level of ambiguity\nto tell us whether it was easy to assign with no other options (unambiguous), \nwhether it was selected as the best match from a series of potential matches \n(selected), or whether it was not possible to distinguish between potential \nmatches (ambiguous). High quality identifications should be both rank 1 and \nunambiguous. The exact filters we set here would depend on how exploratory or \nstringent we wish to be.\n\nFinally, depending upon the experimental question and goal, we may also wish to\nremove features which:\n\n6. *Are not unique*\n\nThe information regarding each of these parameters is present as a column in the \noutput of our identification search, hence is present in the `rowData` of our\n`QFeatures` object. \n\n::: {.callout-note}\n#### Third party software\nThe use-case data was searched using the [Proteome Discoverer software](https://www.thermofisher.com/uk/en/home/industrial/mass-spectrometry/liquid-chromatography-mass-spectrometry-lc-ms/lc-ms-software/multi-omics-data-analysis/proteome-discoverer-software.html) (Thermo Fisher Scientific). \nThis is one among several third party softwares available for protein\nidentification. Each software has it's own naming conventions, formatting and\nmetrics for quantitation and associated metadata. As such, users following\nthis course with their own data should be mindful of this and adapt the \nproposed filters and steps accordingly.\n\n:::\n\n\n### Non-specific filtering\n\nTo remove features based on variables within our `rowData` we make use of the\n**`filterFeatures` function**. This function takes a `QFeatures` object as its input\nand then filters this object against (indicated by the `~` operator) a condition\nbased on the `rowData`. If the condition is met and returns TRUE for a feature,\nthis feature will be kept.\n\nThe `filterFeatures` function provides the option to apply our filter (i) to the\nwhole `QFeatures` object and all of its `experiment assays`, or (ii) to specific\nassays within the `QFeatures` object. We wish to only filter on the data in our\n`QFeatures` object called `psms_filtered` (and not every assay) so in the\nfollowing code chunks we always pass the argument `i = \"psms_filtered\"`.\n\nLet's begin by filtering out any PSMs that **do not have a master protein**.\nThese instances are characterised by an empty `character` i.e. `\"\"`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Before filtering\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 2 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 45803 rows and 10 columns \n```\n:::\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>% \n  filterFeatures(~ Master.Protein.Accessions != \"\", i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n'Master.Protein.Accessions' found in 2 out of 2 assay(s)\n```\n:::\n\n```{.r .cell-code}\n## After filtering\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 2 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 45691 rows and 10 columns \n```\n:::\n:::\n\n\nWe see a message printed to the screen `\"Master.Protein.Accessions' found in 2 out of 2 assay(s)\"` this is informing us that the column\n`\"Master.Protein.Accessions\"` is present in the `rowData` of the two \n`experiment assays` in our `QFeatures` object. We can see from looking \nat our `cc_qf` object before and after filtering we have lost several hundred \nPSMs that do not have a master protein.\n\nAs mentioned above it is standard practice in proteomics to filter MS data for\n**common contaminants**. This is done by using a carefully curated,\nsample-specific contaminant database. In this study the data was searched against\nthe [Hao Group's Protein Contaminant Libraries for DDA and DIA Proteomics](https://github.com/HaoGroup-ProtContLib/Protein-Contaminant-Libraries-for-DDA-and-DIA-Proteomics/)\n@Frankenfield2022 during the PD search. The PD software flags PSMs that originate\nfrom proteins that match a contaminant and this is recorded in the \"Contaminant\"\ncolumn in the PD output and propagated to the `rowData` of our `QFeatures`\nobject.\n\n\n:::{.callout-exercise}\n#### Challenge 1: Filtering for contaminants \n\n{{< level 2 >}}\n\n\n\nThe Proteome Discoverer software flags a potential contaminant in the\n`Contaminants` column found in the `rowData` of the `experiment assay`.\n\nwe can count how many contaminants there are using,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%  \n  rowData() %>% \n  as_tibble() %>% \n  count(Contaminant)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  Contaminant     n\n  <chr>       <int>\n1 False       42751\n2 True         2940\n```\n:::\n:::\n\n\nExamine the `class` of this column,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%  \n  rowData() %>% \n  as_tibble() %>% \n  pull(Contaminant) %>% \n  class()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n:::\n\n\nCareful: it is not a `logical` TRUE or FALSE. It is a `character` and takes\ntwo values, `\"True\"` or `\"False\"`. \n\n1. Use the `filterFeatures` function on the `psms_filtered` experiment assay \nand filter out any contaminants which have been flagged as `\"True\"`.\n\n2. How many PSMs are left after this step?\n\n::: {.callout-answer collapse=true}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>% \n  filterFeatures(~ Contaminant != \"True\", i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n'Contaminant' found in 2 out of 2 assay(s)\n```\n:::\n\n```{.r .cell-code}\n## After filtering\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 2 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 42751 rows and 10 columns \n```\n:::\n:::\n\n\nWe now have 42751 PSMs.\n\n:::\n:::\n\n::: {.callout-note}\n#### More on contaminants\nIt is also possible to filter against your own contaminants list uploaded into\nR. It may be that you have a second list or newer list you'd like to search\nagainst, or you perhaps did not add a contaminants list to filter against in the\nidentification search (which was performed in third party software). Full\ndetails including code can be found in @Hutchings2023.\n\nNote: Filtering on “Protein.Accessions”, rather than \"Master.Protein.Accessions\"\nensures the removal of PSMs which matched to a protein group containing a\ncontaminant protein, even if the contaminant protein is not the group’s master\nprotein.\n\n:::\n\n\nOne of the next filtering steps is to examine to see if we have any **PSMs which lack quantitative data**. In outputs derived from Proteome Discoverer this\ninformation is included in the “Quan.Info” column where PSMs are annotated as\nhaving “NoQuanLabels”. For users who have considered both lysine and N-terminal TMT labels as static modifications, the data should not contain any PSMs without quantitative information. See @Hutchings2023 for how to filter your data if you have TMT modifications set as dynamic.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>% \n  as_tibble() %>%\n  pull(Quan.Info) %>%\n  table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n< table of extent 0 >\n```\n:::\n:::\n\n\nWe see we have no annotation in this column and no PSMs lacking quantitative information.\n\n\n:::{.callout-exercise}\n#### Challenge 2: PSM ranking\n\n{{< level 2 >}}\n\n\n\nSince individual spectra can have multiple candidate PSMs, Proteome Discoverer\nuses a scoring algorithm to determine the probability of a PSM being incorrect.\nOnce each candidate PSM has been given a score, the one with the lowest score\n(lowest probability of being incorrect) is allocated rank 1. The PSM with the\nsecond lowest probability of being incorrect is rank 2, and so on. For the\nanalysis, we only want rank 1 PSMs to be retained. The majority of search\nengines, including SequestHT (used in this analysis), also provide their own PSM\nrank. To be conservative and ensure accurate quantitation, we also only retain\nPSMs that have a search engine rank of 1.\n\n1. Find the columns `Rank` and `Search.Engine.Rank` in the dataset and tabulate \nhow many PSMs we have at each level\n\n2. Use `filterFeatures` and keep,\n* PSMs with a `Rank` of 1\n* PSMs with a `Search.Engine.Rank` of 1\n* High confidence PSMs that have been unambiguously assigned\n\n::: {.callout-answer collapse=true}\n\n**Part 1**\n\nFirst let's examine the columns in the `rowData`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>% \n  names()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Checked\"                           \"Tags\"                             \n [3] \"Confidence\"                        \"Identifying.Node.Type\"            \n [5] \"Identifying.Node\"                  \"Search.ID\"                        \n [7] \"Identifying.Node.No\"               \"PSM.Ambiguity\"                    \n [9] \"Sequence\"                          \"Annotated.Sequence\"               \n[11] \"Modifications\"                     \"Number.of.Proteins\"               \n[13] \"Master.Protein.Accessions\"         \"Master.Protein.Descriptions\"      \n[15] \"Protein.Accessions\"                \"Protein.Descriptions\"             \n[17] \"Number.of.Missed.Cleavages\"        \"Charge\"                           \n[19] \"Original.Precursor.Charge\"         \"Delta.Score\"                      \n[21] \"Delta.Cn\"                          \"Rank\"                             \n[23] \"Search.Engine.Rank\"                \"Concatenated.Rank\"                \n[25] \"mz.in.Da\"                          \"MHplus.in.Da\"                     \n[27] \"Theo.MHplus.in.Da\"                 \"Delta.M.in.ppm\"                   \n[29] \"Delta.mz.in.Da\"                    \"Ions.Matched\"                     \n[31] \"Matched.Ions\"                      \"Total.Ions\"                       \n[33] \"Intensity\"                         \"Activation.Type\"                  \n[35] \"NCE.in.Percent\"                    \"MS.Order\"                         \n[37] \"Isolation.Interference.in.Percent\" \"SPS.Mass.Matches.in.Percent\"      \n[39] \"Average.Reporter.SN\"               \"Ion.Inject.Time.in.ms\"            \n[41] \"RT.in.min\"                         \"First.Scan\"                       \n[43] \"Last.Scan\"                         \"Master.Scans\"                     \n[45] \"Spectrum.File\"                     \"File.ID\"                          \n[47] \"Quan.Info\"                         \"Peptides.Matched\"                 \n[49] \"XCorr\"                             \"Number.of.Protein.Groups\"         \n[51] \"Contaminant\"                       \"Percolator.q.Value\"               \n[53] \"Percolator.PEP\"                    \"Percolator.SVMScore\"              \n```\n:::\n:::\n\n\nLet's examine the columns `Rank` and `Search.Engine.Rank`,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>% \n  as_tibble() %>%\n  count(Rank)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 2\n   Rank     n\n  <int> <int>\n1     1 42185\n2     2   442\n3     3    95\n4     4    20\n5     5     3\n6     6     5\n7     7     1\n```\n:::\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>% \n  as_tibble() %>%\n  count(Search.Engine.Rank)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 2\n  Search.Engine.Rank     n\n               <int> <int>\n1                  1 41794\n2                  2   798\n3                  3   122\n4                  4    28\n5                  5     3\n6                  6     4\n7                  7     2\n```\n:::\n:::\n\n\nWe can also visualise this by piping the results to `ggplot`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>% \n  as_tibble() %>%\n  count(Rank) %>% \n  ggplot(aes(Rank, n)) + \n  geom_col() + \n  scale_y_log10() \n```\n\n::: {.cell-output-display}\n![](03_data_processing_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>% \n  as_tibble() %>%\n  count(Search.Engine.Rank) %>% \n  ggplot(aes(Search.Engine.Rank, n)) + \n  geom_col() + \n  scale_y_log10() \n```\n\n::: {.cell-output-display}\n![](03_data_processing_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n:::\n\n\n**Part 2**\n\nNow let's keep only PSMs with a rank of 1,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>% \n  filterFeatures(~ Rank == 1, i = \"psms_filtered\") %>%\n  filterFeatures(~ Search.Engine.Rank == 1, i = \"psms_filtered\") %>%\n  filterFeatures(~ PSM.Ambiguity == \"Unambiguous\", i = \"psms_filtered\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n'Rank' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'Search.Engine.Rank' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'PSM.Ambiguity' found in 2 out of 2 assay(s)\n```\n:::\n\n```{.r .cell-code}\n## After filtering\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 2 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 41794 rows and 10 columns \n```\n:::\n:::\n\n\nWe now have 41794 PSMs.\n\n:::\n:::\n\nIn quantitative proteomics when thinking about what PSMs to consider for take \nforward for quantitation we consider **PSM uniqueness**. By definition uniqueness\nin this context refers to (i) PSMs corresponding to a single protein only, or it\ncan also refer to (ii) PSMs that map to multiple proteins within a single protein \ngroup. This distinction is ultimately up to the user. We do not consider PSMs \ncorresponding to razor and shared peptides as these are linked to multiple \nproteins across multiple protein groups.\n\nIn this workflow, the final grouping of peptides to proteins will be done based\non master protein accession. Therefore, differential expression analysis will \nbe based on protein groups, and we here consider unique as any PSM linked to \nonly one protein group. This means removing PSMs where “Number.of.Protein.Groups” \nis not equal to 1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>% \n  filterFeatures(~ Number.of.Protein.Groups == 1, i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n'Number.of.Protein.Groups' found in 2 out of 2 assay(s)\n```\n:::\n\n```{.r .cell-code}\n## After filtering\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 2 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 40044 rows and 10 columns \n```\n:::\n:::\n\n\n\n### Addititional quality control filters available for TMT data\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.003.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\nAs well as the completion of standard data cleaning steps which are common to \nall quantitative proteomics experiments (see above), different experimental \nmethods are accompanied by additional data processing considerations. Although\nwe cannot provide an extensive discussion of all methods, we will draw attention\nto three key quality control parameters to consider for our use-case TMT data. \n\n1. Average reporter ion signal-to-noise (S/N)\n\nThe quantitation of a TMT experiment is dependent upon the measurement of \nreporter ion signals from either the MS2 or MS3 spectra. Since reporter ion\nmeasurements derived from a small number of ions are more prone to stochastic\nion effects and reduced quantitative accuracy, we want to remove PSMs that rely \nsuch quantitation to ensure high data quality. When using an orbitrap analyser, \nthe number of ions is proportional to the S/N ratio of a peak. Hence, removing\nPSMs that have a low S/N value acts as a proxy for removing low quality\nquantitation. \n\n2. Isolation interference (%)\n\nIsolation interference occurs when multiple TMT-labelled precursor peptides are\nco-isolated within a single data acquisition window. All co-isolated peptides go\non to be fragmented together and reporter ions from all peptides contribute to\nthe reporter ion signal. Hence, quantification for the identified peptide becomes\ninaccurate. To minimise the co-isolation interference problem observed at MS2,\nMS3-based analysis can be used @McAlister2014. Nevertheless, we remove PSMs with \na high percentage isolation interference to prevent the inclusion of inaccurate \nquantitation values.\n\n3. Synchronous precursor selection mass matches (%) - SPS-MM\n\nSPS-MM is a parameter unique to the Proteome Discoverer software which lets users\nquantify the percentage of MS3 fragments that can be explicitly traced back to\nthe precursor peptides. This is important given that quantitation is based on\nthe MS3 spectra.\n\nHere we will apply the default quality control thresholds as suggested by \nThermo Fisher and keep features with:\n\n* Average reporter ion S/N >= 10\n* Isolation interference < 75%\n* SPS-MM >= 65%\n\nWe also remove features that do not have information regarding these quality\ncontrol parameters i.e., have an NA value in the corresponding columns of the\n`rowData`. To remove these features we include the `na.rm = TRUE` argument.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>% \n  filterFeatures(~ Average.Reporter.SN >= 10, \n                 na.rm = TRUE, i = \"psms_filtered\") %>%\n  filterFeatures(~ Isolation.Interference.in.Percent <= 75, \n                 na.rm = TRUE, i = \"psms_filtered\") %>%\n  filterFeatures(~ SPS.Mass.Matches.in.Percent >= 65, \n                 na.rm = TRUE, i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n'Average.Reporter.SN' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'Isolation.Interference.in.Percent' found in 2 out of 2 assay(s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n'SPS.Mass.Matches.in.Percent' found in 2 out of 2 assay(s)\n```\n:::\n:::\n\n\n\nIn reality, we advise that users take a look at their data to decide whether the\ndefault quality control thresholds applied above are appropriate. If there is\nreason to believe that the raw MS data was of lower quality than desired, it\nmay be sensible to apply stricter thresholds here. Similarly, if users wish to \ncarry out a more stringent or exploratory analyses, these thresholds can be \naltered accordingly. For code and more information please see @Hutchings2023.\n\n\n\n### Controlling false discovery rate (FDR)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.004.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\nThe data cleaning steps that we have carried out so far have mainly been \nconcerned with achieving high quality quantitation. However, we also want to be\nconfident in our PSMs and their corresponding peptide and protein identifications.\n\nTo identify the peptides present in each of our samples we used a third party \nsoftware to carry out a database search. Raw MS spectra are matched to theoretical \nspectra that are generated via *in silico* digestion of our desired protein \ndatabase. The initial result of this search is a list of peptide spectrum matches,\nPSMs. A database search will identify PSMs for the majority of MS spectra, but\nonly a minority of these will be true positives. In the same way that experiments \nmust be conducted with controls, database search identifications need to be \nstatistically validated to avoid false positives. The most widely used method\nfor reducing the number of false positive identifications is to control the\nfalse discovery rate (FDR).\n\n\n#### Target-decoy approach to FDR control {-}\n\nThe most common approach to FDR control is the target-decoy approach. This \ninvolves searching the raw MS spectra against both a target and decoy database.\nThe target database contains all protein sequences which could be in our sample\n(the human proteome and potential contaminants). The decoy database contains \nfake proteins that should not be present in the sample. For example, a decoy\ndatabase may contain reversed or re-shuffled sequences. The main principle is \nthat by carrying out these two searches we are able to estimate the the \nproportion of total PSMs that are false (matched to the decoy sequences) and\napply score-based thresholding to shift this false discovery rate to a \ndesired maximum. Typically expression proteomics utilises a maximum FDR of 0.01 \nor 0.05, that is to say 1% or 5% of PSMs are accepted false positives. \n\n\n#### PSM level local FDR {-}\n\nThe first FDR to be calculated is that for the PSMs themselves, often referred to\nas **local FDR**. As mentioned previously, each PSM is given a score indicating\nhow likely it is to be correct or incorrect, depending on the search engine used.\nBased on these scores, each candidate PSM is ranked such that rank 1 PSMs have\nthe highest probability of being correct or lowest probability of being incorrect.\nTo calculate the local FDR for a PSM, the score for that PSM is taken as a \nthreshold, and all PSMs with a score equal to or better than that PSM are extracted.\nThe proportion of false positives within this population of PSMs is taken as its\nlocal FDR. In this way, the FDR can be thought of as the proportion of false \npositives above the critical score threshold. \n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![An illustration of the local FDR calculation used to assign each PSM an FDR.](figs/local_fdr.png){fig-align='center' width=50%}\n:::\n:::\n\n\n\nIn the parameters for our identification search using Proteome Discoverer we\nspecified a PSM level FDR threshold. We did this by allocating PSM confidence\nlevels as 'high', 'medium' or 'low' depending on whether their FDR was < 0.01, \n< 0.05 or > 0.05. We then told Proteome Discoverer to only retain high \nconfidence PSMs, those with a local FDR < 0.01. The local FDR indirectly tells\nus the probability of a PSM being a false positive, given the score it has.\n\nLet's double check that we only have high confidence PSMs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"psms_raw\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(Confidence) %>%\n  table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n High \n45803 \n```\n:::\n:::\n\n\nAs expected, all of the PSMs in our data are of high confidence. \n\n#### Protein level FDR thresholding is still required {-}\n\nAlthough we have already applied a PSM level FDR threshold to the data (during\nthe identification search), it is highly recommended to set a protein level FDR\nthreshold. This is because each peptide can have multiple PSMs and each protein\ncan be supported by multiple peptides, thus resulting in the potential for\namplification of the FDR during data aggregation. At a given PSM level score\nthreshold, the peptide level FDR is greater than the PSM level FDR. Similarly,\nthe protein level FDR is greater than the peptide level FDR.\n\nTo be absolutely confident in our final protein data we need to apply a protein\nlevel FDR. Unfortunately, third party software typically generates output tables\nin a sequential manner and there is currently no way to include information\nabout the protein level FDR in the PSM level output. Therefore, we have to\nimport the protein level output to get this information. The file is called\n`cell_cycle_total_proteome_analysis_Proteins.txt`. \n\nWe begin by using the `read.delim` function to read in the data,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Applying protein level FDR - import protein output from database search\nprotein_data_PD <- read.delim(file = \"data/cell_cycle_total_proteome_analysis_Proteins.txt\")\n```\n:::\n\n\nLet's check the dimensions of the protein level output,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(protein_data_PD)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4904   72\n```\n:::\n:::\n\n\nThe output contains 4904 proteins. Let's compare this to the\nnumber of master protein accessions in our raw and imputed filtered PSM data,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Number of master proteins in our raw data\ncc_qf[[\"psms_raw\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(Master.Protein.Accessions) %>%\n  unique() %>%\n  length()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5267\n```\n:::\n\n```{.r .cell-code}\n## Number of master proteins in our filtered data\ncc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(Master.Protein.Accessions) %>%\n  unique() %>%\n  length()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3912\n```\n:::\n:::\n\n\nIt looks like the protein level output has fewer proteins than the raw PSM file\nbut more proteins than our filtered PSM data. This tells us that Proteome \nDiscoverer has done some filtering throughout the process of aggregating from \nPSM to peptide to protein, but not as much filtering as we have done manually in \nR. This makes sense because we did not set any quality control thresholds on \nco-isolation interference, reporter ion S/N ratio or SPS-MM during the search.\n\nNow let's look to see where information about the protein level FDR is stored.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(protein_data_PD) %>% \n  head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Checked\"                         \"Tags\"                           \n [3] \"Protein.FDR.Confidence.Combined\" \"Master\"                         \n [5] \"Proteins.Unique.Sequence.ID\"     \"Protein.Group.IDs\"              \n [7] \"Accession\"                       \"Description\"                    \n [9] \"Sequence\"                        \"FASTA.Title.Lines\"              \n```\n:::\n:::\n\n\nWe have a column called `\"Protein.FDR.Confidence.Combined\"`. Let's add this \ninformation to our `rowData` of the `psms_filtered` experiment assay of our `QFeatures` \nobject. \n\nFirst let's extract the `rowData` and convert it to a `data.frame` so we can \nmake use of `dplyr`,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Extract the rowData and convert to a data.frame\npsm_data_QF <- \n  cc_qf[[\"psms_filtered\"]] %>% \n  rowData() %>% \n  as.data.frame()\n```\n:::\n\n\nNow let's subset the `protein_data_PD` data to keep only accession and \nFDR information,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Select only the Accession and FDR info\nprotein_data_PD <- \n  protein_data_PD %>% \n  select(Accession, Protein.FDR.Confidence.Combined)\n```\n:::\n\n\nNow let's use `dplyr` and the `left_join` function to do the matching\nbetween the protein PD data and our PSM data for us. We need to specify how\nwe join them so we need to specify the argument \n`by = c(\"Master.Protein.Accessions\" = \"Accession\")` to tell R we wish to \njoin the two datasets by their protein Accessions. Note, in the `rowData` of\nthe `QFeatures` object we have `\"Master.Protein.Accessions\"` and in the PD \nprotein data the column is just called `\"Accessions\"`. Check with your own data\nthe explicit naming of your data files as this will differ between third party \nsoftwares.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Use left.join from dplyr to add the FDR data to PSM rowData data.frame \nfdr_confidence <- left_join(x = psm_data_QF,  \n                            y = protein_data_PD,\n                            by = c(\"Master.Protein.Accessions\" = \"Accession\")) %>% \n  pull(\"Protein.FDR.Confidence.Combined\")\n```\n:::\n\n\n::: {.callout-note}\n#### Joining data.frames\nNote: when using `left_join` we specify the argument `by =\nc(\"Master.Protein.Accessions\" = \"Accession\"))` (note the = equals sign between\nthe names). This tells `left_join` we want to match join the two `data.frames`\nby matching accession numbers between the the `Master.Protein.Accessions` column\nin `psm_data_QF` and the column called `Accession` in the `protein_data_PD`\ndata.\n:::\n\nNow let's add the FDR information back to the `QFeatures` object,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Now add this data to the QF object\nrowData(cc_qf[[\"psms_filtered\"]])$Protein.FDR.Confidence <- fdr_confidence\n```\n:::\n\n\nNow we can print a table to see how many of the PSMs in our data were found\nto have a high confidence after protein level FDR calculations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>% \n  as_tibble() %>% \n  pull(Protein.FDR.Confidence) %>%\n  table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n  High    Low Medium \n 25699      5     84 \n```\n:::\n:::\n\n\nMost of the PSMs in our data were found to originate from proteins with high \nconfidence (FDR < 0.01 at protein level), but there are a few that are medium \nor low confidence. Even though we set a PSM level FDR threshold of 0.01, some\nof the resulting proteins still exceed this FDR due to amplification of error\nduring aggregation. \n\nWe can now use the `filterFeatures` function to remove PSMs that do not have a\n`Protein_Confidence` of 'High'.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>%\n  filterFeatures(~ Protein.FDR.Confidence == \"High\", \n                 i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n'Protein.FDR.Confidence' found in 1 out of 2 assay(s)\nNo filter applied to the following assay(s) because one or more filtering variables are missing in the rowData: psms_raw.\nYou can control whether to remove or keep the features using the 'keep' argument (see '?filterFeature').\n```\n:::\n:::\n\n\nNotice, we see a message output to the terminal after running the function that \ntelling us that `Protein.FDR.Confidence` was only found in 1 of our experiment \nassays and as such no filter was applied to the raw data. This is correct and \nexpected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"psms_filtered\"]] %>%\n  rowData %>%\n  as_tibble %>%\n  pull(Protein.FDR.Confidence) %>%\n  table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n High \n25699 \n```\n:::\n:::\n\n\nFor more information about how FDR values are calculated and used see @Prieto2019.\n\n## Management of missing data \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.005.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\nHaving cleaned our data, the next step is to deal with missing values. It is \nimportant to be aware that missing values can arise for different reasons in \nMS data, and these reasons determine the best way to deal with the missing data.\n\n* Biological reasons - a peptide may be genuinely absent from a sample or have such low abundance that it is below the limit of MS detection\n* Technical reasons - technical variation and the stocastic nature of MS (particularly using DDA) may lead to some peptides not being quantified. Some peptides have a lower ionization efficiency which makes them less compatible with MS analysis\n\nMissing values that arise for different reasons can generally be deciphered by \ntheir pattern. For example, peptides that have missing quantitation values for\nbiological reasons tend to be low intensity or completely absent peptides. Hence,\nthese missing values are **missing not at random (MNAR)** and appear in an\nintensity-dependent pattern. By contrast, peptides that do not have quantitation\ndue to technical reasons are **missing completely at random (MCAR)** and appear\nin an intensity-independent manner.\n\n\n### Influence of experimental design  \n\nAll quantitative proteomics datasets will have some number of missing values, \nalthough the extent of data missingness differs between label-free and label-based\nDDA experiments as well as between DDA and DIA label-free experiments. \n\nWhen carrying out a label-free DDA experiment, all samples are analysed via \nindependent MS runs. Since the selection of precursor ions for fragmentation is\nsomewhat stochastic in DDA (e.g., top *N* most abundant precursors are selected)\nexperiments, different peptides may be identified and quantified across the \ndifferent samples. In other words, not all peptides that are analysed in one \nsample will be analysed in the next, thus introducing a high proportion of \nmissing values.\n\nOne of the advantages of using TMT labelling is the ability to multiplex samples\ninto a single MS run. In the use-case, 10 samples were TMT labelled and pooled\ntogether prior to DDA MS analysis. As a result, the same peptides were quantified\nfor all samples and we expect a lower proportion of missing values than if we\nwere to use label-free DDA. \n\nMore recently, DIA MS analysis of label-free samples has increased in popularity.\nHere, instead of selecting a limited number of precursor peptides (typically the\nmost abundance) for subsequent fragmentation and analysis, all precursors within\na selected *m/z* window are selected. The analysis of all precursor ions within\na defined range in every run results in more consistent coverage and accuracy\nthan DDA experiments, hence lower missing values.\n\n\n### Exploration of missing data\n\nThe management of missing data can be considered in three main steps:\n\n1. Exploration of missing data - determine the number and pattern of missing values\n2. Removal of data with high levels of missingness - this could be features with missing values across too many samples or samples with an abnormally high proportion of missingness compared to the average\n3. Imputation (optional)\n\n::: {.callout-note}\n#### Encoding of missing data\nBefore we begin managing the missing data, we first need to know what missing data\nlooks like. In our data, missing values are notated as `NA` values. Alternative \nsoftware may display missing values as being zero, or even infinite if \nnormalisation has been applied during the database search. All functions used for\nthe management of missing data within the `QFeatures` infrastructure use the `NA` \nnotation. If we were dealing with a dataset that had an alternative encoding, we\ncould apply the `zeroIsNA()` or `infIsNA()` functions to convert missing values\ninto `NA` values.\n\n:::\n\nThe main function that facilitates the exploration of missing data in `QFeatures`\nis `nNA`. Let's try to use this function. Again, we use the `i = ` argument to\nspecify which assay within the `QFeatures` object that we wish to look at. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nnNA(cc_qf, i = \"psms_filtered\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$nNA\nDataFrame with 1 row and 3 columns\n          assay       nNA         pNA\n    <character> <integer>   <numeric>\n1 psms_filte...        14 5.44768e-05\n\n$nNArows\nDataFrame with 25699 rows and 4 columns\n              assay        name       nNA       pNA\n        <character> <character> <integer> <numeric>\n1     psms_filte...           7         0         0\n2     psms_filte...           8         0         0\n3     psms_filte...           9         0         0\n4     psms_filte...          16         0         0\n5     psms_filte...          18         0         0\n...             ...         ...       ...       ...\n25695 psms_filte...       45748         0         0\n25696 psms_filte...       45752         0         0\n25697 psms_filte...       45753         0         0\n25698 psms_filte...       45777         0         0\n25699 psms_filte...       45784         0         0\n\n$nNAcols\nDataFrame with 10 rows and 4 columns\n           assay        name       nNA         pNA\n     <character> <character> <integer>   <numeric>\n1  psms_filte...     Control         4 0.000155648\n2  psms_filte...         M_1         0 0.000000000\n3  psms_filte...         M_2         9 0.000350208\n4  psms_filte...         M_3         1 0.000038912\n5  psms_filte...        G1_1         0 0.000000000\n6  psms_filte...        G1_2         0 0.000000000\n7  psms_filte...        G1_3         0 0.000000000\n8  psms_filte...        DS_1         0 0.000000000\n9  psms_filte...        DS_2         0 0.000000000\n10 psms_filte...        DS_3         0 0.000000000\n```\n:::\n:::\n\n\nThe output from this function is a `list` of three `DFrame`s. The first of\nthese (called `nNA`) gives us information about missing data at the global level\n(i.e., for the entire experiment assay). We get information about the absolute number of\nmissing values (`nNA`) and the proportion of the total data set that is missing\nvalues (`pNA`). The next two data frames also give us `nNA` and `pNA` but this\ntime on a per row/feature (`nNArows`) and per column/sample (`nNAcols`) basis.\n\nLet's direct the output of `nNA` on each `experiment assay` to an object,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_raw <- nNA(cc_qf, i = \"psms_raw\")\nmv_filtered <- nNA(cc_qf, i = \"psms_filtered\")\n```\n:::\n\n\nTo access one `DataFrame` within a list we use the standard `$` operator, \nfollowed by another `$` operator if we wish to access specific columns.\n\n**Missing values down columns (sample)**\nPrint information regarding the number of missing values per column in\nthe `\"mv_raw\"` data,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_raw$nNAcols\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDataFrame with 10 rows and 4 columns\n         assay        name       nNA        pNA\n   <character> <character> <integer>  <numeric>\n1     psms_raw     Control       280 0.00611314\n2     psms_raw         M_1       161 0.00351505\n3     psms_raw         M_2       388 0.00847106\n4     psms_raw         M_3       177 0.00386438\n5     psms_raw        G1_1       118 0.00257625\n6     psms_raw        G1_2       123 0.00268541\n7     psms_raw        G1_3        88 0.00192127\n8     psms_raw        DS_1       116 0.00253259\n9     psms_raw        DS_2       143 0.00312207\n10    psms_raw        DS_3       110 0.00240159\n```\n:::\n:::\n\n\nand after filtering,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_filtered$nNAcols\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDataFrame with 10 rows and 4 columns\n           assay        name       nNA         pNA\n     <character> <character> <integer>   <numeric>\n1  psms_filte...     Control         4 0.000155648\n2  psms_filte...         M_1         0 0.000000000\n3  psms_filte...         M_2         9 0.000350208\n4  psms_filte...         M_3         1 0.000038912\n5  psms_filte...        G1_1         0 0.000000000\n6  psms_filte...        G1_2         0 0.000000000\n7  psms_filte...        G1_3         0 0.000000000\n8  psms_filte...        DS_1         0 0.000000000\n9  psms_filte...        DS_2         0 0.000000000\n10 psms_filte...        DS_3         0 0.000000000\n```\n:::\n:::\n\n\nNow, we can extract the proportion of NAs in each sample,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_raw$nNAcols$pNA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.006113137 0.003515054 0.008471061 0.003864376 0.002576250 0.002685414\n [7] 0.001921272 0.002532585 0.003122066 0.002401589\n```\n:::\n:::\n\n\nWe can also pass the output data from `nNA` to `ggplot` to visualise the missing\ndata. This is particularly useful so that we can see whether any of our samples\nhave an abnormally high proportion of missing values compared to the average. This\ncould be the case if something had gone wrong during sample preparation. It is \nalso useful to see whether there is any specific conditions that have a greater\nnumber of missing values.\n\nIn the following code chunk we visualise the proportion of missing values per \nsample and check for sample and condition bias. \n\nIn the raw data,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_raw$nNAcols %>%\n  as_tibble() %>%\n  mutate(condition = colData(cc_qf)$condition) %>%\n  ggplot(aes(x = name, y = pNA, group = condition, fill = condition)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Sample\", y = \"Missing values (%)\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](03_data_processing_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\nIn the filtered data,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_filtered$nNAcols %>%\n  as_tibble() %>%\n  mutate(condition = colData(cc_qf)$condition) %>%\n  ggplot(aes(x = name, y = pNA, group = condition, fill = condition)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Sample\", y = \"Missing values (%)\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](03_data_processing_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n\n::: {.callout-note}\n#### Missing values - expectations\nIn this experiment we expect all samples to have a low proportion of missing \nvalues due to the TMT labelling strategy. We also expect that all samples should\nhave a similar proportion of missing values because we do not expect cell cycle\nstage to have a large impact on the majority of the proteome. Hence, the samples\nhere should be very similar. This is the case in most expression proteomics\nexperiments which aim to identify differential protein abundance upon a cellular\nperturbation. However, in some other MS-based proteomics experiments this would\nnot be the case. For example, proximity labelling and co-immunoprecipitation \n(Co-IP) experiments have control samples that are not expected to have any proteins\nin, although there is always a small amount of unwanted noise. In such cases it \nwould be expected to have control samples with a large proportion of missing\nvalues and experimental samples with a much lower proportion. It is important to\ncheck that the data corresponds to the experimental setup.\n\n:::\n\n\n**Missing values across rows (PSMs)**\nPrint information regarding the number of missing values per row (PSM):\n\nIn the `\"psms_raw\"` data,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_raw$nNArows\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDataFrame with 45803 rows and 4 columns\n            assay        name       nNA       pNA\n      <character> <character> <integer> <numeric>\n1        psms_raw           1         0       0.0\n2        psms_raw           2         0       0.0\n3        psms_raw           3         0       0.0\n4        psms_raw           4         6       0.6\n5        psms_raw           5         1       0.1\n...           ...         ...       ...       ...\n45799    psms_raw       45799         3       0.3\n45800    psms_raw       45800         0       0.0\n45801    psms_raw       45801         3       0.3\n45802    psms_raw       45802         2       0.2\n45803    psms_raw       45803         1       0.1\n```\n:::\n:::\n\n\nThe `\"psms_filtered\"` data,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_filtered$nNArows\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDataFrame with 25699 rows and 4 columns\n              assay        name       nNA       pNA\n        <character> <character> <integer> <numeric>\n1     psms_filte...           7         0         0\n2     psms_filte...           8         0         0\n3     psms_filte...           9         0         0\n4     psms_filte...          16         0         0\n5     psms_filte...          18         0         0\n...             ...         ...       ...       ...\n25695 psms_filte...       45748         0         0\n25696 psms_filte...       45752         0         0\n25697 psms_filte...       45753         0         0\n25698 psms_filte...       45777         0         0\n25699 psms_filte...       45784         0         0\n```\n:::\n:::\n\n\n\n:::{.callout-exercise}\n#### Challenge 3: Analysing missing values\n\n{{< level 2 >}}\n\n\n\nHow many PSMs do we have with (i) 0 missing values, (ii) 1 missing value, (iii) \n2 or more missing values, across samples, before and after filtering?\n\n::: {.callout-answer collapse=true}\n\n\nThe `nNA` column gives information on the number missing values (or we can \nuse `pNA` which gives information on the proportion of missing values). Calling `table` on the\noutput number of missing values we have across samples,\n\nOn the raw data,\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_raw$nNArows$nNA %>% table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n    0     1     2     3     4     5     6     7     8     9    10 \n45263   224    96    58    42    19    17    18    13    11    42 \n```\n:::\n:::\n\n\nOn the filtered data,\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_filtered$nNArows$nNA %>% table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n    0     1     3 \n25687    11     1 \n```\n:::\n:::\n\n\n:::\n:::\n\n\n<!-- **TODO - add second challenge or too tricky?** -->\n<!-- Ideas ... -->\n<!-- Something to do with missing data across rows - prior to filtering based on a  -->\n<!-- feature having >20% missing values. Ask them to work out how many this will be? -->\n<!-- Ask them to work out the max and min number of missing values per feature? -->\n<!-- Ask them to create a plot looking at the number of missing values across the -->\n<!-- intensity distribution (are they intensity dependent or independent?) -->\n\n\n\n### Removing data with high levels of missingness\n\nAlthough the use-case data has only a small number of mssing values it is still\ncommon to remove individual features that have too many missing values across\nsamples. Here, we remove PSMs that have >20% missing values. This is done using\nthe `filterNA` function where the `pNA` argument specifies the maximum proportion\nof missing values to allow per feature.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- cc_qf %>%\n  filterNA(pNA = 0.2, i = \"psms_filtered\")\n```\n:::\n\n\n\nWe already established that none of our samples have an abnormally high \nproportion of missing values (relative to the average). Therefore, we do not\nneed to remove any entire samples/columns.\n\n\n### Imputation of remaining missing values\n\nThe final step in managing our missing data is to consider whether to impute.\nImputation involves the replacement of missing values with probable values.\nUnfortunately, estimating probable values is difficult and requires complex \nassumptions about why a value is missing. For example, if a value is missing \nbecause a peptide is completely absent or present at an abundance below the limit\nof detection then the most suitable replacement value is arguably the lowest\nabundance value recorded in the data set (since this represents the limit of\ndetection). Alternatively, if a value is missing because of stochastic technical\nreasons then it might be more appropriate to replace it with a value derived \nfrom a similar peptide. Overall, left-censored methods such as minimal value and\nlimit of detection approaches work best for data that is MNAR (intensity-dependent\nmissing values). Hot deck methods such as k-nearest neighbors, random forest and \nmaximum likelihood methods work better for data that is MCAR (intensity-independent).\nTo confuse the situation further, most data sets contain missing values that are\na mixture of MNAR and MCAR, so mixed imputation methods can be applied.\n\nGiven that imputation is difficult to get right and can have substantial effects\non the results of downstream analysis, it is generally recommended to avoid\nit where we can. This means that if there is not a large proportion of missing\nvalues in our data, we should not impute. \n\nWe can now check to see how many missing values remain in the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnNA(cc_qf[[\"psms_filtered\"]])$nNA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDataFrame with 1 row and 2 columns\n        nNA         pNA\n  <integer>   <numeric>\n1        11 4.28049e-05\n```\n:::\n:::\n\n\nWe only have 4.2804888\\times 10^{-5}% missing values in our\ndata, so imputation is not really necessary here. We could either remove the \nPSMs that still have missing values or continue our analysis. The latter is \npossible since missing values are often lost during aggregation and there are\nnow aggregation methods that are able to deal with missing data @Goeminne2020 @Sticker2020.\n\nFor demonstration purposes we will carry out imputation anyway. Since we are \nonly imputing 11 values we do not expect\na large effect on the data structure or downstream analysis.\n\nImputation within the `QFeatures` infrastructure is completed using the `impute`\nfunction. To see what imputation methods this function facilitates we can use\n`MsCoreUtils::imputeMethods()`\n\nTo see what imputation methods are available,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMsCoreUtils::imputeMethods()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"bpca\"    \"knn\"     \"QRILC\"   \"MLE\"     \"MLE2\"    \"MinDet\"  \"MinProb\"\n [8] \"min\"     \"zero\"    \"mixed\"   \"nbavg\"   \"with\"    \"RF\"      \"none\"   \n```\n:::\n:::\n\n\n\nHere we will use the baseline k-nearest neighbors (k-NN),\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- impute(object = cc_qf,\n                method = \"knn\", \n                i = \"psms_filtered\",\n                name = \"psms_imputed\")\n\ncc_qf\n```\n:::\n\n\n:::{.callout-exercise}\n#### Challenge 4: Imputation\n\n{{< level 2 >}}\n\n\n\nUse the `nNA` function to check that the `impute` function has worked.\n\n::: {.callout-answer collapse=true}\n\nCall `nNA` on the `\"psms_imputed\"` assay.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_imputed <- nNA(cc_qf[[\"psms_imputed\"]])\n\n## View object\nmv_imputed\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$nNA\nDataFrame with 1 row and 2 columns\n        nNA       pNA\n  <integer> <numeric>\n1         0         0\n\n$nNArows\nDataFrame with 25698 rows and 3 columns\n             name       nNA       pNA\n      <character> <integer> <numeric>\n1               7         0         0\n2               8         0         0\n3               9         0         0\n4              16         0         0\n5              18         0         0\n...           ...       ...       ...\n25694       45748         0         0\n25695       45752         0         0\n25696       45753         0         0\n25697       45777         0         0\n25698       45784         0         0\n\n$nNAcols\nDataFrame with 10 rows and 3 columns\n          name       nNA       pNA\n   <character> <integer> <numeric>\n1      Control         0         0\n2          M_1         0         0\n3          M_2         0         0\n4          M_3         0         0\n5         G1_1         0         0\n6         G1_2         0         0\n7         G1_3         0         0\n8         DS_1         0         0\n9         DS_2         0         0\n10        DS_3         0         0\n```\n:::\n:::\n\n\nExamine the number of NAs across the rows (PSMs).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_imputed$nNArows$nNA %>% table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n    0 \n25698 \n```\n:::\n:::\n\n\nNow down the columns (samples).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmv_imputed$nNAcols$nNA %>% table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n 0 \n10 \n```\n:::\n:::\n\n\n:::\n:::\n\n\n\n\n\n\n::: {.callout-tip}\n#### Key Points\n\n- The `filterFeatures` function can be used to remove data from a `QFeatures` object (or an `experiment assay` within a `QFeatures` object) based on filtering parameters within the `rowData`.\n- Data processing includes (i) standard proteomics data cleaning steps e.g., removal of contaminants, and (ii) data-specific quality control filtering e.g., co-isolation interference thresholding for TMT data.\n- The management of missing quantitative data in expression proteomics data is complex. The `nNA` function can be used to explore missing data and the `filterNA` function can be used to remove features with undesirably high levels of missing data. Where imputation is absolutely necessary, the `impute` function exists within the `QFeatures` infrastructure.\n- Protein level thresholding on false discovery rate is required to ensure confident identifications.\n\n:::\n\n## References {-}\n",
    "supporting": [
      "03_data_processing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}