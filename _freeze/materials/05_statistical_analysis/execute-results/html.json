{
  "hash": "765921080d931b6c10c2b995e7406dea",
  "result": {
    "markdown": "---\ntitle: Statistical analysis\nbibliography: course_refs.bib\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.callout-tip}\n#### Learning Objectives\n\n* Acknowledge the availability of different R/Bioconductor packages for carrying out differential expression (abundance) analyses\n* Using the `limma` package, design a statistical model to test for differentially abundant proteins between two conditions\n* Be able to interpret the output of a statistical model and annotate the results with user-defined significance thresholds\n* Produce volcano plots to visualise the results of differential expression analyses\n\n:::\n\n\n\n\n\n\n## Differential expression analysis \n\nHaving cleaned our data, aggregated from PSM to protein level, completed a\nlog2 transformation and normalised the data, we are now ready to carry out\nstatistical analysis. The aim of this section is to answer the question:\n*\"Which proteins show a significant change in abundance between cell cycle stages?\"*.\n\nOur null hypothesis is:\n**(H0)** The change in abundance for a protein between cell cycle stages is 0.\n\nOur alternative hypothesis is:\n**(H1)** The change in abundance for a protein between cell cycle stages is greater than 0.\n\n\n## Selecting a statistical test\n\nThere are a few aspects of our data that we need to consider prior to deciding\nwhich statistical test to apply.\n\n* The protein abundances in this data are not normally distributed (i.e., they\ndo not follow a Gaussian distribution). However, they are approximately normal \nfollowing a log2 transformation.\n* The cell cycle is not expected to have a large impact on biological \nvariability. We can assume that the majority of the proteome is the same between \nsamples.\n* The samples are independent not paired. For example, M_1 is not derived from \nthe same cells as G1_1 and DS_1.\n\nThe first two points relate to two key assumptions that are made when carrying out \n**parametric** statistical tests. Parametric tests provide greater statistical \npower but assume that the input data has a normal distribution and equal variance.\nIf these two assumptions are not met then it is not appropriate to use parametric \ntesting. If we wanted to check whether the log2 protein abundances were truly \nGaussian we could have applied a Shapiro-Wilk test or Kolmogorov-Smirnov test.\nSimilarly, to check for equal variance a Levene test could be used. All of these\ntests are easily done within R but will not be covered in this course. Here, we\nwill use a form of t-test since we know that these assumptions have been met.\n\nMany different R packages can be used to carry out differential expression\n(abundance) analysis on proteomics data. Here we will use `limma`, a package\nthat is widely used for omics analysis and has several models that allow\ndifferential abundance to be assessed in multifactorial experiments.\nSpecifically, we are going to apply `limma`'s **empirical Bayes moderated t-test**.\n\n\n### What is a t-test?\n\nA t-test is a parametric statistical test used to compare the mean values of two\ngroups, essentially asking whether the difference between means is significantly\ngreater than 0. The output of such a test includes several parameters:\n\n* **t-value** = provides a ratio between the size of the difference between means and the variation between samples within condition. The further away from 0 that a t-value lies, the more likely it is to represent a significant difference between means (large difference between conditions, small variation within conditions)\n* **degrees of freedom** = the number of observations minus the number of independent variables (*n* - 1)\n* **p-value** = the probability of achieving the t-value under the null hypothesis i.e., by chance\n\nHere, we will apply a  t-test to each of our proteins to ask whether the\ndifference in the mean abundance of a protein between cell cycle stages is \nsignificantly different from 0.\n\n\n### What does the empirical Bayes part mean?\n\nWhen carrying out high throughput omics experiments we not only have a\npopulation of samples but also a population of features - here we have several\nthousand proteins. Whilst we do not have time to go into detail about this,\nconsidering our parameters of interest (mean, variation and difference in means)\nacross the entire population of proteins provides us with some prior knowledge\nof what to expect. This prior knowledge facilitates empirical Bayesian methods\n(a mixture between frequentist and Bayesian statistics), a much more powerful\napproach than looking at the data one protein at a time.\n\nEssentially, the empirical Bayes method borrows information across features\n(proteins) and shifts the per-protein variance estimates towards an expected\nvalue based on the variance estimates of other proteins with a similar\nabundance. This results in greater statistical power for detecting significant\nabundance changes for proteins with higher variation and reduces the number of\nfalse positives that arise from proteins with small variances (where normally\neven a small abundance change could be considered significant). For more detail\nabout empirical Bayes methods see\n[here](https://online.stat.psu.edu/stat555/node/40/).\n\nOverall, empirical Bayes provides a way to increase the statistical power and\nreduce false positives within our differential abundance analysis.\n\n\n## Defining the statistical model \n\nBefore we apply our empirical Bayes moderated t-test, we first need to set up a\nmodel. To define the model design we use `model.matrix`. A **model matrix**,\nalso called a design matrix, is a matrix in which rows represent individual\nsamples and columns correspond to explanatory variables, in our case the cell\ncycle stages. Simply put, the model design is determined by how samples are\ndistributed across conditions.\n\n\n### With or without an intercept\n\nWhen investigating the effect of a single explanatory variable, a design matrix\ncan be created using either `model.matrix(~variable)` or `model.matrix(~0 + variable)`.\nThe difference between these two options is that the first will create a model \nthat includes an intercept term whilst the second will exclude any intercept\nterm. If the explantory variable is a factor, both models with and without an\nintercept are equivalent. If, however, the explanatory variable is a covariate, \nthe two models are then fundamentally different. \n\nIn this experiment we consider our explanatory variable (cell cycle stage) to \nbe categorical, making it of `factor` class in R. When modelling factor\nexplanatory variables, models with and without an intercept are equivalent. \nEither option is appropriate for factor explanatory variables, but design matrices\nwithout an intercept value tend to be easier to interpret. For further guidance\non generating design matrices for covariates or continuous explanatory \nvariables, see [A guide to creating design matrices for gene expression experiments](https://bioconductor.org/packages/devel/workflows/vignettes/RNAseq123/inst/doc/designmatrices.html#design-and-contrast-matrices).\n\nWe subset our log2 normalised protein level data since this will be the\ninput for our statistical test. For simplicity we also remove the 1st sample, \nwhich was a single pre-treatment control. Without any replicates this condition\ncannot be considered in a statistical framework.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Extract protein list from our QFeatures object - remove sample 1\nall_proteins <- cc_qf[[\"log_norm_proteins\"]][, -1]\n\n## Ensure that conditions are stored as levels of a factor \n## Explicitly define level order by cell cycle stage\nall_proteins$condition <- factor(all_proteins$condition, \n                                 levels = c(\"Desynch\", \"M\", \"G1\"))\n```\n:::\n\n\nNext, we define the model matrix without any intercept term.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Design a matrix containing all factors that we wish to model\nm_design <- model.matrix(~ 0 + all_proteins$condition)\ncolnames(m_design) <- levels(all_proteins$condition)\n\n## Verify\nm_design\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Desynch M G1\n1       0 1  0\n2       0 1  0\n3       0 1  0\n4       0 0  1\n5       0 0  1\n6       0 0  1\n7       1 0  0\n8       1 0  0\n9       1 0  0\nattr(,\"assign\")\n[1] 1 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$`all_proteins$condition`\n[1] \"contr.treatment\"\n```\n:::\n:::\n\n\nWe also define **contrasts**. The contrasts represent which comparisons or \nquestions are of interest to us. This is important since we are not directly \ninterested in the parameter (mean) estimates for each group but rather the differences\nin these parameter (mean) estimates *between* groups. The `makeContrasts` function\nis used by passing the name we wish to give each contrast and how this contrast\nshould be calculated using column names from the design matrix. We also pass the\n`levels` argument to tell R where the column names come from i.e., which design\nmatrix the contrasts are being applied to.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Specify contrasts of interest\ncontrasts <- makeContrasts(M_G1 = G1 - M, \n                           M_Des = M - Desynch, \n                           G1_Des = G1 - Desynch,\n                           levels = m_design)\n\n## Verify\ncontrasts\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Contrasts\nLevels    M_G1 M_Des G1_Des\n  Desynch    0    -1     -1\n  M         -1     1      0\n  G1         1     0      1\n```\n:::\n:::\n\n\n\n## Running an empirical Bayes moderated t-test using `limma`\n\nAfter we have specified the design matrix and contrasts we wish to make, the \nnext step is to apply the statistical model. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Fit linear model using the design matrix and desired contrasts\nfit_model <- lmFit(assay(all_proteins), m_design)\nfit_contrasts <- contrasts.fit(fit_model, contrasts)\n```\n:::\n\n\nThe initial model has now been applied to each of the proteins in our data. \nWe now update the model using the `eBayes` function. When we do this we include\ntwo other arguments: `trend = TRUE` and `robust = TRUE` @Phipson2016 @Smyth2004.\n\n* `trend` - takes a logical value of `TRUE` or `FALSE` to indicate whether an \nintensity-dependent trend should be allowed for the prior variance (i.e., the \npopulation level variance prior to empirical Bayes moderation). This means that \nwhen the empirical Bayes moderation is applied the protein variances are not \nsqueezed towards a global mean but rather towards an intensity-dependent trend.\n* `robust` - takes a logical value of `TRUE` or `FALSE` to indicate whether the \nparameter estimation of the priors should be robust against outlier sample \nvariances.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Update the model using the limma eBayes algorithm\nfit_contrasts <- eBayes(fit_contrasts, \n                        trend = TRUE,\n                        robust = TRUE)\n```\n:::\n\n\nFinally, we can take a look out the output of our differential abundance testing.\nThe `topTable` function allows us to look at the results of our linear model. \nThis includes a result of the test for each individual protein.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Format results\nlimma_results <- topTable(fit_contrasts,\n                          adjust.method = \"BH\",\n                          number = Inf) %>%\n  rownames_to_column(\"Protein\") \n\n## Verify\nhead(limma_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Protein      M_G1      M_Des     G1_Des     AveExpr        F      P.Value\n1  Q9ULW0 -2.196302  0.8286154 -1.3676866  0.37120023 556.8677 4.925616e-11\n2  Q9NQW6 -2.007405  0.6700307 -1.3373743 -0.05658671 551.8195 5.154527e-11\n3  Q15004 -1.570234 -0.9766029 -2.5468366  0.06394366 509.7658 7.653217e-11\n4  O14965 -2.184708  0.8973014 -1.2874065 -0.28476604 434.9508 1.687067e-10\n5  Q9BW19 -2.316607  1.0241676 -1.2924396 -0.48687563 395.9382 2.692154e-10\n6  P53350 -1.521376  0.9034441 -0.6179315  0.04114047 389.3868 2.924908e-10\n     adj.P.Val\n1 9.979795e-08\n2 9.979795e-08\n3 9.979795e-08\n4 1.649951e-07\n5 1.831385e-07\n6 1.831385e-07\n```\n:::\n:::\n\n\n### Multiple hypothesis testing and correction\n\nHere we see another argument appear, the `adjust.method = \"BH`. This refers to \np-value adjustment that must be done following multiple hypothesis testing. \n\nMultiple testing describes the process of separately testing each null\nhypothesis i.e., carrying out many statistical tests at a time each to test a\ndifferent hypothesis. Here we have carried out 3912\nhypothesis tests. If we were to use the typical p < 0.05 significance threshold\nfor each test we would accept a 5% chance of incorrectly rejecting the null\nhypothesis *per test*. Therefore, for every 100 tests that we carry out we\nexpect an average of 5 false positives.\n\nIf we do not account for the fact that we have carried out multiple hypothesis\nthen we risk including false positives in our data. Many methods exist to\ncorrect for multiple hypothesis testing and these mainly fall into two\ncategories:\n\n1. Control of the Family-Wise Error Rate (FWER)\n2. Control of the False Discovery Rate (FDR)\n\nAbove we used the \"BH\", or Benjamini-Hochberg procedure, to control the FDR. We\nwill later use the FDR-adjusted p-value to define statistical significance in\nour data.\n\n\n### Diagnostic plots to verify suitability of our statistical model\n\nAs with all statistical analysis, it is crucial to do some quality control and\nto check that the statistical test that has been applied was indeed appropriate\nfor the data. As mentioned above, statistical tests typically come with several\nassumptions. To check that these assumptions were met and that our model was\nsuitable, we create some diagnostic plots.\n\nFirst we plot a histogram of the raw p-values (not the BH-adjusted p-values).\nThis can be done by passing our results data into standard `ggplot2` plotting\nfunctions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlimma_results %>%\n  as_tibble() %>%\n  ggplot(aes(x = P.Value)) + \n  geom_histogram()\n```\n\n::: {.cell-output-display}\n![](05_statistical_analysis_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nThe histogram we have plotted shows an anti-conservative distribution, which is\ngood. The flat distribution across the bottom corresponds to null p-values which\nare distributed approximately uniformly between 0 and 1. The peak close to 0 \ncontains our significantly changing proteins, a combination of true positives \nand false positives.\n\nOther examples of how a p-value histogram could look are shown below. Whilst in\nsome experiments a uniform p-value distribution may arise due to an absence of\nsignificant alternative hypotheses, other distribution shapes can indicate that\nsomething was wrong with the model design or statistical test. For more detail on\nhow to interpret p-value histograms there is a great [blog](http://varianceexplained.org/statistics/interpreting-pvalue-histogram/) \nby David Robinson.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Examples of p-value histograms.](figs/phist_shapes.png){fig-align='center' width=100%}\n:::\n:::\n\n\nThe second plot that we generate is an SA plot to display the residual standard\ndeviation (sigma) versus log abundance for each protein to which our model was\nfitted. We can use the `plotSA` function to do this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotSA(fit_contrasts,\n       cex = 0.5,\n       xlab = \"Average log2 abundance\")\n```\n\n::: {.cell-output-display}\n![](05_statistical_analysis_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nIt is recommended that an SA plot be used as a routine diagnostic plot when\napplying a limma-trend pipeline. From the SA plot we can visualise the\nintensity- dependent trend that has been incorporated into our linear model. It\nis important to verify that the trend line fits the data well. If we had not\nincluded the `trend = TRUE` argument in our `eBayes` function, then we would\ninstead see a straight horizontal line that does not follow the trend of the\ndata. Further, the plot also colours any outliers in red. These are the outliers\nthat are only detected and excluded when using the `robust = TRUE` argument.\n\n\n### Interpreting the output of our statisical model\n\nHaving checked that the model we fitted was appropriate for the data, we can now\ntake a look at the results of our test using the `decideTests` function.\nSpecifically, if we look at a `summary` of the output by `decideTests` we can\nsee how many proteins were found to be significantly up and downregulated in\neach comparison.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndecideTests(fit_contrasts, adjust.method = \"BH\", p.value = 0.01) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       M_G1 M_Des G1_Des\nDown    376   434     71\nNotSig 3257  3010   3812\nUp      279   468     29\n```\n:::\n:::\n\n\n\nFor the remainder of the workshop we will focus on the statistical comparison \nbetween M-phase and the desynchronised cells. We use the `topTable` function to\nget the results of the `\"M_Des\"` contrast.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM_Desynch_results <- topTable(fit_contrasts, coef = \"M_Des\", \n                              number = Inf, adjust.method = \"BH\") %>%\n  rownames_to_column(\"protein\")\n\n## Verify\nhead(M_Desynch_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  protein     logFC    AveExpr         t      P.Value    adj.P.Val        B\n1  P31350 -3.047366 -0.5547497 -24.07756 3.123327e-10 1.221845e-06 13.86700\n2  O60732 -2.060689  0.3760922 -21.33485 1.032811e-09 2.020178e-06 12.83045\n3  O43583 -1.598586  0.2417345 -18.64452 3.889944e-09 4.170287e-06 11.62569\n4  O00622  1.296573 -0.6273396  18.47070 4.264097e-09 4.170287e-06 11.54034\n5  Q96PU5 -1.582445 -0.1394537 -16.87384 1.032262e-08 6.371215e-06 10.70724\n6  O43663  1.069033  0.1756289  16.75719 1.104487e-08 6.371215e-06 10.64271\n```\n:::\n:::\n\n\nInterpreting the output of `topTable`:\n\n* `logFC` = the fold change between the mean log abundance in group A and the mean log abundance in group B\n* `AveExpr` = the average log abundance of the protein across samples\n* `t` = eBayes moderated t-statistic. Interpreted in the same way as a normal t-statistic (see above).\n* `P.Value` = Unadjusted p-value\n* `adj.P.Val` = FDR-adjusted p-value \n* `B` = B-statistic representing the log-odds that a protein is differentially abundant between conditions\n\n\n#### Adding user-defined significance thresholds \n\nThe output of out statistical test will provide us with key information for\neach protein, including its p-value, BH-adjusted p-value and logFC. However, it\nis up to us to decide what we consider to be significant. The first parameter \nto consider is the `adj.P.Val` threshold that we wish to apply - 0.05 and 0.01 \nare both common in proteomics. The second parameter which is sometimes used to\ndefine significance is the `logFC`. This is mainly for the purpose of deciding\non hits to follow-up, since it is easier to validate larger abundance changes\nthan those which are consistent but subtle. \n\nHere we are going to define significance based on an `adj.P.Val` < 0.01. We can\nadd a column to our results to indicate significance as well as the direction of\nchange. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Add direction and significance information\nM_Desynch_results <- \n  M_Desynch_results %>%\n  as_tibble() %>%\n  mutate(direction = ifelse(logFC > 0, \"up\", \"down\"),\n         significance = ifelse(adj.P.Val < 0.01, \"sig\", \"not.sig\"))\n\n\n## Verify\nhead(M_Desynch_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 9\n  protein logFC AveExpr     t  P.Value  adj.P.Val     B direction significance\n  <chr>   <dbl>   <dbl> <dbl>    <dbl>      <dbl> <dbl> <chr>     <chr>       \n1 P31350  -3.05  -0.555 -24.1 3.12e-10 0.00000122  13.9 down      sig         \n2 O60732  -2.06   0.376 -21.3 1.03e- 9 0.00000202  12.8 down      sig         \n3 O43583  -1.60   0.242 -18.6 3.89e- 9 0.00000417  11.6 down      sig         \n4 O00622   1.30  -0.627  18.5 4.26e- 9 0.00000417  11.5 up        sig         \n5 Q96PU5  -1.58  -0.139 -16.9 1.03e- 8 0.00000637  10.7 down      sig         \n6 O43663   1.07   0.176  16.8 1.10e- 8 0.00000637  10.6 up        sig         \n```\n:::\n:::\n\n\n\n\n\n### Visualising the results of our statistical model\n\nThe final step in any statistical analysis is to visualise the results. This is\nimportant for ourselves as it allows us to check that the data looks as \nexpected. \n\nThe most common visualisation used to display the results of expression\nproteomics experiments is a volcano plot. This is a scatterplot that shows\nstatistical significance (p-values) against the magnitude of fold change.\nOf note, when we plot the statistical significance we use the raw unadjusted\np-value (`-log10(P.Value)`). This is because it is better to plot the basic\ndata in its raw form than any derived value (the adjusted p-value is derived\nfrom each p-value using the BH-method of correction). The process of FDR\ncorrection can result in some points that previously had distinct p-values \nhaving the same adjusted p-value. Further, different methods of correction will\ngenerate different adjusted p-values, making the comparison and interpretation\nof values more difficult.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nM_Desynch_results %>%\n  ggplot(aes(x = logFC, y = -log10(P.Value), fill = significance)) +\n  geom_point(shape = 21, stroke = 0.25, size = 3) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](05_statistical_analysis_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n:::{.callout-exercise}\n#### Challenge: Volcano plots\n\n{{< level 2 >}}\n\n\nRe-generate your table of results defining significance based on an adjusted \nP-value < 0.05 and a log2 fold-change of > 1.\n\n::: {.callout-answer collapse=true}\n\nFirst let's regenerate the results adding a column for the log2 fold change\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_results <- \n  M_Desynch_results %>%\n  as_tibble() %>%\n  mutate(direction = ifelse(logFC > 0, \"up\", \"down\"),\n         significance = ifelse(adj.P.Val < 0.05, \"sig\", \"not.sig\"),\n         lfc = ifelse(logFC > 1 | logFC < -1, \"sig\", \"not.sig\"),\n         result = ifelse(significance == \"sig\" & lfc == \"sig\", \"sig\", \"not.sig\"))\n```\n:::\n\n\nNow let's plot the results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_results %>%\n  ggplot(aes(x = logFC, y = -log10(P.Value), fill = result)) +\n  geom_point(shape = 21, stroke = 0.25, size = 3) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](05_statistical_analysis_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n:::\n:::\n\n::: {.callout-tip}\n#### Key Points\n\n- The `limma` package provides a statistical pipeline for the analysis of differential expression (abundance) experiments\n- Empirical Bayes moderation involves borrowing information across proteins to squeeze the per-protein variance estimates towards an expected value based on the behaviour of other proteins with similar abundances. This method increases the statistical power and reduces the number of false positives. \n- Since proteomics data typically shows an intensity-dependent trend, it is recommended to apply empirical Bayes moderation with `trend = TRUE` and `robust = TRUE`. This approach can be validated by plotting an SA plot.\n- Significance thresholds are somewhat arbitary and must be selected by the user. However, correction must be carried out for multiple hypothesis testing so significance thresholds should be based on adjusted p-values rather than raw p-values. Users may also threshold significance based on a log fold-change value too.\n- The results of differential expression and abundance analyses are often summarised on volcano plots.\n:::\n\n\n\n## References {-}\n",
    "supporting": [
      "05_statistical_analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}