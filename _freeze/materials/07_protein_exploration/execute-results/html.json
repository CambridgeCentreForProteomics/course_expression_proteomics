{
  "hash": "0b2b04970144b7467c7d569d7c5a1259",
  "result": {
    "markdown": "---\ntitle: Exploration and visualisation of protein data\nbibliography: course_refs.bib\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.callout-tip}\n#### Learning Objectives\n\n* Know how to determine the number of PSMs, peptides, proteins and protein groups (i.e., master proteins) in an assay of a `QFeatures` object\n* Understand what the `.n` column corresponds to when using the `aggregateFeatures` function to aggregate features\n* Be able to use the `subsetByFeature` function to get data across all levels for a feature of interest\n* Appreciate the use of Principal Component Analysis (PCA) for visualising key factors that contribute to sample variation \n* Complete PCA using the `prcomp` function from the `stats` package\n\n:::\n\n\n\n\n\n\n\nBefore we carry out statistical analysis to determine which of our proteins \nshow significantly differential abundance across conditions (cell cycle stages),\nwe first want to do some exploration of the protein level data. This includes\ndetermining some information that may be required for reporting and publication\npurposes as well as information corresponding to quality control.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/flow_chart/flow_chart.009.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## Determining the dimensions of our final protein data\n\nGiven that we started from the PSM level and did extensive data cleaning, \nfiltering and management of missing data, it would be useful to know how much \ndata we have left. We may want to know how many PSMs, peptides and proteins\nthe `log_norm_proteins` assay contains, given that this is the data to which\nstatistical analysis will be applied.\n\nWe can easily find the number master proteins by printing our `QFeatures` object\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAn instance of class QFeatures containing 9 assays:\n [1] psms_raw: SummarizedExperiment with 45803 rows and 10 columns \n [2] psms_filtered: SummarizedExperiment with 25698 rows and 10 columns \n [3] psms_imputed: SummarizedExperiment with 25698 rows and 10 columns \n ...\n [7] proteins_direct: SummarizedExperiment with 3825 rows and 10 columns \n [8] log_proteins_direct: SummarizedExperiment with 3825 rows and 10 columns \n [9] log_norm_proteins: SummarizedExperiment with 3825 rows and 10 columns \n```\n:::\n:::\n\n\nWe can see we have 3825 master proteins, each\nrepresenting a protein group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"log_norm_proteins\"]] %>%\n  nrow()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3825\n```\n:::\n:::\n\n\n\n:::{.callout-exercise}\n#### Challenge 1: Final PSM, peptide and protein count\n\n{{< level 2 >}}\n\n\n\nDetermine how many PSMs, peptides and proteins were lost during processing of\nthe raw data to our final protein list?\n\n::: {.callout-answer collapse=true}\n\nWe started with,\n\n\n::: {.cell}\n\n```{.r .cell-code}\npsm_count <- cc_qf[[\"psms_raw\"]] %>% nrow()\n\npeptide_count <- \n  cc_qf[[\"psms_raw\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(Sequence) %>%\n  unique() %>%\n  length() \n\nprot_count <- \n  cc_qf[[\"psms_raw\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(Master.Protein.Accessions) %>%\n  unique() %>%\n  length() \n\nmessage(psm_count, \" PSMs, \", \n        peptide_count, \" peptides and \", \n        prot_count, \" proteins\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n45803 PSMs, 26738 peptides and 5267 proteins\n```\n:::\n:::\n\n\nAfter filtering we have,\n\n\n::: {.cell}\n\n```{.r .cell-code}\npsm_final <- cc_qf[[\"psms_filtered\"]] %>% nrow()\n\npeptide_final <- \n  cc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(Sequence) %>%\n  unique() %>%\n  length() \n\nprot_final <- \n  cc_qf[[\"psms_filtered\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(Master.Protein.Accessions) %>%\n  unique() %>%\n  length() \n\nmessage(psm_final, \" PSMs, \", \n        peptide_final, \" peptides and \", \n        prot_final, \" proteins\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n25698 PSMs, 17236 peptides and 3825 proteins\n```\n:::\n:::\n\n\nDuring the course of data processing we have lost,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessage(psm_count - psm_final, \" PSMs, \", \n        peptide_count - peptide_final, \" peptides and \", \n        prot_count - prot_final, \" proteins\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n20105 PSMs, 9502 peptides and 1442 proteins\n```\n:::\n:::\n\n\n:::\n:::\n\n## The `.n` column created by `aggregateFeatures`\n\nIf we look at the names of the columns within our `\"log_proteins\"` and \n`\"log_norm_proteins\"` assays we see that there is a column called `.n`. This \ncolumn was not present in the PSM level assays.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Check columns in the log normalised protein assay\ncc_qf[[\"log_norm_proteins\"]] %>%\n  rowData() %>%\n  names()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Checked\"                     \"Tags\"                       \n [3] \"Confidence\"                  \"Identifying.Node.Type\"      \n [5] \"Identifying.Node\"            \"Search.ID\"                  \n [7] \"Identifying.Node.No\"         \"PSM.Ambiguity\"              \n [9] \"Master.Protein.Accessions\"   \"Master.Protein.Descriptions\"\n[11] \"Delta.Cn\"                    \"Rank\"                       \n[13] \"Search.Engine.Rank\"          \"Ions.Matched\"               \n[15] \"Matched.Ions\"                \"Total.Ions\"                 \n[17] \"Quan.Info\"                   \"Number.of.Protein.Groups\"   \n[19] \"Contaminant\"                 \"Protein.FDR.Confidence\"     \n[21] \".n\"                         \n```\n:::\n:::\n\n\nThe `.n` column is created during the aggregation process that is completed via\nthe `aggregateFeatures` function. This column stores information about how many\nchild features (PSMs) were aggregated into each parent (protein) feature. Since we aggregated\ndirectly from the PSMs to protein, the `.n` column tells us how\nmany PSMs we have in support of each protein in the final dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"log_norm_proteins\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(.n) %>%\n  table()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n.\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n1229  711  449  312  233  162  149  109   68   54   58   53   33   26   20   25 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n  19   12    8   14    9    8    7    5    6    2    1    2    1    3    1    1 \n  33   34   35   36   40   41   44   45   48   49   52   54   59   60   69   86 \n   5    3    2    4    2    2    1    2    1    1    1    3    1    1    1    1 \n  87   90  173  223 \n   1    1    1    1 \n```\n:::\n:::\n\n\n\n\nThe output tells us that we have 1229 proteins with 1 \nPSMs (single peptide hits), 711 proteins with support from \n2 PSMs, and so forth.\n\n:::{.callout-exercise}\n#### Challenge 2: Examining PSM support\n\n{{< level 2 >}}\n\n\n\n1. Using the information we have in the `.n` column create a graph to visualise\nPSM support. \n\n<details><summary>Inspiration</summary> The [\"from Data to Viz project\"](https://www.data-to-viz.com)\nprovides some great ideas for visualisation in R and a brilliant platform for \nexploring your data. The [R Graph Gallery](https://r-graph-gallery.com/ggplot2-package.html)\nis another great source of inspiration with coded examples to follow.</details>\n\n2. What is,\n\n(i) the *maximum* number of PSMs we have available for one given protein? \n(ii) the *most common* number of PSMs available for any given protein?\n(iii) the *median* number of PSMs available for any given protein?\n\n<details><summary>Hint</summary> The functions `frequency` and `summary`\nmay help. </details>\n\n\n::: {.callout-answer collapse=true}\n\n**Task 1: Graph to visualise PSM support**\n\nThere are many ways we can visualise PSM support. The first thing we could do\nis plot a histogram. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf[[\"log_norm_proteins\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  ggplot(aes(x = .n)) +\n  geom_histogram(binwidth = 1)\n```\n\n::: {.cell-output-display}\n![](07_protein_exploration_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nIs this a good visualisation for our dataset? It is perhaps not the easiest\nplot to read if the aim is to get an overview of how many PSMs are available per \nprotein group. \n\nLet's bin PSMs with > 8 PSMs per protein group into one category and then plot\nthe data.\n\nIn the next code chunk we create a new `tibble` which tells us how many\nproteins we have which have `n` number of PSMs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Summarise the number of PSMs per protein if we have greater than 8  \npsm_df <- cc_qf[[\"log_norm_proteins\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  select(.n) %>% \n  mutate(psm_n = ifelse(.n <= 7, .n, \"8+\")) %>% \n  count(psm_n) \n\npsm_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 Ã— 2\n  psm_n     n\n  <chr> <int>\n1 1      1229\n2 2       711\n3 3       449\n4 4       312\n5 5       233\n6 6       162\n7 7       149\n8 8+      580\n```\n:::\n:::\n\n\nNow let's plot this data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Plot the data using a lollipop\nggplot(psm_df, aes(x = psm_n, y = n)) +\n  geom_segment(aes(x = psm_n, xend = psm_n, y=0, yend = n)) +\n  geom_point(color = \"red\", size = 4) +\n  ylab(\"Frequency\") +\n  xlab(\"Number of PSMs per protein group\") +\n  theme_light() \n```\n\n::: {.cell-output-display}\n![](07_protein_exploration_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nWe can also plot as a percentage.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Plot the data using a lollipop\npsm_df %>% \n  mutate(n, n_percent = n/sum(n)*100) %>% \n  ggplot(aes(x = psm_n, y = n_percent)) +\n  geom_segment(aes(x = psm_n, xend = psm_n, y = 0, yend = n_percent)) +\n  geom_point(color=\"red\", size=4) +\n  ylab(\"Frequency (%)\") +\n  xlab(\"Number of PSMs per protein group\") +\n  theme_light()\n```\n\n::: {.cell-output-display}\n![](07_protein_exploration_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n**Task 2: PSM support extremes**\n\n\n::: {.cell}\n\n```{.r .cell-code}\npsm_df <- cc_qf[[\"log_norm_proteins\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(.n) %>% \n  frequency()\n\npsm_df <- cc_qf[[\"log_norm_proteins\"]] %>%\n  rowData() %>%\n  as_tibble() %>%\n  pull(.n) %>% \n  summary()\n```\n:::\n\n\n* (i) We have one instance which has 413 PSMs for one given protein.\n* (ii) From the above output we see the most common number of PSMs available to support\na given protein is 1. Single peptide hits most frequently occur in the data. \n* (iii) The median number of PSMs is 3.\n\n:::\n:::\n\n<!-- We may wish to examine PSM support in the context of peptides, and peptide -->\n<!-- support for protein groups.  -->\n\n<!-- **Challenge** -->\n<!-- Now we know how many master proteins are in our final dataset and how many PSMs -->\n<!-- support the quantification of these proteins. Determine how many peptide  -->\n<!-- sequences are in support of the final master proteins. -->\n\n<!-- 1. Use the `aggregateFeatures` function to aggregate from log imputed PSM level to log peptide and then log peptide to log protein -->\n<!-- 2. Calculate the sum of the `.n` column in the log peptide and log protein assays - think about what these values mean in each instance -->\n\n<!-- **Below is the solution - change to eval=TRUE, include=FALSE** -->\n\n<!-- ```{r, warning = FALSE} -->\n<!-- ## Aggregate from PSM to peptide -->\n<!-- cc_qf <- aggregateFeatures(cc_qf,  -->\n<!--                            i = \"log_imputed_psms\",  -->\n<!--                            fcol = \"Sequence\", -->\n<!--                            name = \"log_peptides\", -->\n<!--                            fun = MsCoreUtils::robustSummary, -->\n<!--                            na.rm = TRUE) -->\n\n<!-- ## Aggregate from peptide to protein -->\n<!-- cc_qf <- aggregateFeatures(cc_qf,  -->\n<!--                            i = \"log_peptides\",  -->\n<!--                            fcol = \"Master.Protein.Accessions\", -->\n<!--                            name = \"log_proteins_2\", -->\n<!--                            fun = MsCoreUtils::robustSummary, -->\n<!--                            na.rm = TRUE) -->\n\n<!-- ## Sum of .n in peptide-level (i.e., total PSMs) -->\n<!-- cc_qf[[\"log_peptides\"]] %>% -->\n<!--   rowData() %>% -->\n<!--   as_tibble() %>% -->\n<!--   pull(.n) %>% -->\n<!--   sum() -->\n\n<!-- ## Sum of .n in protein level (i.e., total peptides) -->\n<!-- cc_qf[[\"log_proteins_2\"]] %>% -->\n<!--   rowData() %>% -->\n<!--   as_tibble() %>% -->\n<!--   pull(.n) %>% -->\n<!--   sum() -->\n<!-- ``` -->\n\n\n<!-- **Challenge**  -->\n<!-- Sometimes we also want to know the dimensions of the raw data. For example, if  -->\n<!-- we want to report how many PSMs or peptides were in support of a protein's -->\n<!-- *identification* rather than its *quantitation* then using the raw data is  -->\n<!-- more appropriate.  -->\n\n<!-- Look at the names of the `rowData` colums in the `\"psms_raw\"` assay. Using the -->\n<!-- `unique()` function, determine how many PSMs, peptide sequences and master -->\n<!-- protein accessions were identified from the raw data. -->\n\n<!-- **Below is the solution! need to hide** -->\n\n<!-- ```{r} -->\n<!-- cc_qf[[\"psms_raw\"]] %>%  -->\n<!--   nrow() -->\n\n<!-- cc_qf[[\"psms_raw\"]] %>%  -->\n<!--   rowData() %>% -->\n<!--   as_tibble() %>% -->\n<!--   pull(Sequence) %>% -->\n<!--   unique() %>% -->\n<!--   length() -->\n\n<!-- cc_qf[[\"psms_raw\"]] %>%  -->\n<!--   rowData() %>% -->\n<!--   as_tibble() %>% -->\n<!--   pull(Master.Protein.Accessions) %>% -->\n<!--   unique() %>% -->\n<!--   length() -->\n<!-- ``` -->\n\n\n## The `subsetByFeature` function\n\nAs well as determining the dimensions of our entire dataset, both in its raw\nstate and its final state, sometimes we may wish to find out information about \na specific feature e.g., a protein of interest. The `QFeatures` infrastructure\nprovides a convenient function called `subsetByFeature` to extract all data \nlevels corresponding to a particular feature.\n\nThe `subsetByFeature` function take a `QFeatures` object as its input and an \nadditional argument specifying one or more features of interest. The output is\na new `QFeatures` object with only data corresponding to the specified features.\n\nLet's take a look at O43583, the human density-regulated protein.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nO43583 <- subsetByFeature(cc_qf, \"O43583\")\n\nO43583@ExperimentList\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nExperimentList class object of length 9:\n [1] psms_raw: SummarizedExperiment with 0 rows and 10 columns\n [2] psms_filtered: SummarizedExperiment with 5 rows and 10 columns\n [3] psms_imputed: SummarizedExperiment with 5 rows and 10 columns\n [4] log_psms_imputed: SummarizedExperiment with 5 rows and 10 columns\n [5] log_peptides: SummarizedExperiment with 4 rows and 10 columns\n [6] log_proteins: SummarizedExperiment with 1 rows and 10 columns\n [7] proteins_direct: SummarizedExperiment with 1 rows and 10 columns\n [8] log_proteins_direct: SummarizedExperiment with 1 rows and 10 columns\n [9] log_norm_proteins: SummarizedExperiment with 1 rows and 10 columns\n```\n:::\n:::\n\n\nFrom this we can see that the O43583 protein is supported by 4 peptides derived\nfrom 5 PSMs.\n\nWe can use our new `QFeatures` object to create a plot which displays how the\nPSM data was aggregated to protein for this particular feature. To do so, we\nextract the assays of interest from our `\"O43583\"` `QFeatures` object and pass\nto the `longFormat` function which will covert the subset `QFeatures` object\nto a long format `DataFrame`. We can then use the standard `ggplot2` functions\nto visualise the processing of this protein.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nO43583[, , c(\"log_psms_imputed\", \"log_peptides\", \"log_proteins\")] %>%\n  longFormat() %>%\n  as_tibble() %>%\n  mutate(assay_order = factor(assay, \n                              levels = c(\"log_psms_imputed\", \n                                         \"log_peptides\", \n                                         \"log_proteins\"))) %>%\n  ggplot(aes(x = colname, y = value, colour = assay)) + \n  geom_point() +\n  geom_line(aes(group = rowname)) +\n  theme(axis.text.x = element_text(angle = 45, size = 7)) +\n  facet_wrap(~ assay_order)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nharmonizing input:\n  removing 60 sampleMap rows not in names(experiments)\n```\n:::\n\n::: {.cell-output-display}\n![](07_protein_exploration_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nOther useful functions that we do not have time to cover today include\n`subsetByAssay`, `subsetByColData`, `subsetByColumn`, `subsetByFilter`, \n`subsetByRow`, `subsetByOverlap`, and many more. To find out more about these \nfunctions you can execute a single question mark (`?`) followed by the function name. \nIf you have the `QFeatures` package installed you should be able to access a help\nand information page for the function of interest.\n\nFor example: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n?subsetByAssay\n```\n:::\n\n\n\n## Principal Component Analysis (PCA)\n\nThe final protein level exploration that we will do is Principal Component\nAnalysis (PCA).\n\nPCA is a statistical method that can be applied to condense complex data from\nlarge data tables into a smaller set of summary indices, termed principal \ncomponents. This process of dimensionality reduction makes it easier to \nunderstand the variation observed in a dataset, both how much variation there is\nand what the primary factors driving the variation are. This is particularly \nimportant for multivariate datasets in which experimental factors can contribute\ndifferentially or cumulatively to variation in the observed data. PCA allows us\nto observe any trends, clusters and outliers within the data thereby helping to\nuncover the relationships between observations and variables.\n\n\n### The process of PCA\n\nThe process of PCA can be considered in several parts:\n\n1. Scaling and centering the data\n\nFirstly, all continuous variables are standardized into the same range so that \nthey can contribute equally to the analysis. This is done by centering each\nvariable to have a mean of 0 and scaling its standard deviation to 1.\n\n\n2. Generation of a covariance matrix\n\nAfter the data has been standardized, the next step is to calculate a covariance\nmatrix. The term covariance refers to a measure of how much two variables vary\ntogether. For example, the height and weight of a person in a population will \nbe somewhat correlated, thereby resulting in covariance within the population.\nA covariance matrix is a square matrix of dimensions *p* x *p* (where *p* is \nthe number of dimensions in the original dataset i.e., the number of variables).\nThe matrix contains an entry for every possible pair of variables and describes\nhow the variables are varying with respect to each other.\n\nOverall, the covariance matrix is essentially a table which summarises the \ncorrelation between all possible pairs of variables in the data. If the covariance\nof a pair is positive, the two variables are correlated in some direction (increase\nor decrease together). If the covariance is negative, the variables are inversely\ncorrelated with one increasing when the other decreases. If the covariance is \nnear-zero, the two variables are not expected to have any relationship.\n\n\n3. Eigendecomposition - calculating eigenvalues and eigenvectors\n\nEigendecomposition is a concept in linear algebra whereby a data matrix is \nrepresented in terms of **eigenvalues** and **eigenvectors**. In this case, the\nthe eigenvalues and eigenvectors are calculated based on the covariance matrix\nand will inform us about the magnitude and direction of our data. Each eigenvectoor\nrepresents a direction in the data with a corresponding eigenvalue telling us how \nmuch variation in our data occurs in that direction.\n\n* Eigenvector = informs about the direction of variation\n* Eigenvalue = informs about the magnitude of variation \n\nThe number of eigenvectors and eigenvalues will always be the same as the \nnumber of dimensions (variables) in the initial dataset. In our use-case, we \nhave 10 samples, so we will have a covariance matrix of dimensions 10 x 10, and\nthis will give rise to 10 eigenvectors and 10 associated eigenvalues.\n\n\n4. The calculation of principal components\n\nPrincipal components are calculated by multiplying the original data by a \ncorresponding eigenvector. As a result, the principal components themselves\nrepresent directionality of data. The order of the principal components is\ndetermined by the corresponding eigenvector such that the first principal \ncomponent is that which explains the most variation in the data (i.e., has the\nlargest eigenvalue).\n\nBy having the first principal components explain the largest proportion of \nvariation in the data, the dimension of the data can be reduced by focusing\non these principal components and ignoring those which explain very little in \nthe data.\n\n\n### Completing PCA with `prcomp`\n\nTo carry out PCA on our data we will use the `prcomp` function from the `stats`\npackage. We first extract the quantitative matrix (assay) corresponding to the\nlog normalised protein level data. To make this matrix compatible with `prcomp`\nwe also need to transpose the data such that the samples become rows and \nproteins become columns. This is easily achieved using the `t` function. \n\nOur protein data does not contain due to the decision to impute. However, if\nthere were any missing values in the data, these would need to be removed using \n`filterNA` to facilitate compatibility with PCA.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprotein_pca <- cc_qf[[\"log_norm_proteins\"]] %>%\n  assay() %>%\n# filterNA() %>%\n  t() %>%\n  prcomp(scale = TRUE, center = TRUE)\n\nsummary(protein_pca)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nImportance of components:\n                           PC1     PC2     PC3     PC4      PC5      PC6\nStandard deviation     36.3991 26.3432 21.6028 19.8613 17.41989 14.40867\nProportion of Variance  0.3464  0.1814  0.1220  0.1031  0.07933  0.05428\nCumulative Proportion   0.3464  0.5278  0.6498  0.7529  0.83228  0.88655\n                            PC7      PC8      PC9      PC10\nStandard deviation     12.53704 11.85260 11.67329 4.657e-14\nProportion of Variance  0.04109  0.03673  0.03563 0.000e+00\nCumulative Proportion   0.92765  0.96437  1.00000 1.000e+00\n```\n:::\n:::\n\n\n\nWe now have a simplified representation of our quantitative data in the form\nof principle components (PC). The `prcomp` function outputs a list of 5 different\ninformation sources, each of which can be accessed using the `$` sign nomenclature.\n\n1. `sdev` - holds the standard deviation values for each of the principle components\n2. `rotation` - a matrix which contains each of our proteins as a row and the corresponding PC values as columns\n3. `x` - a matrix which contains each of our samples as a row and the corresponding PC values as columns\n4. `center` - if `center = TRUE` then contains the centering values, otherwise `FALSE`\n5. `scale` - if `scale = TRUE` then contains the scaling values, otherwise `FALSE`\n\n\nTo visualise the resulting PCs and how much of the data variation they explain\nwe can plot a scree plot using the `fviz_screeplot` function. The resulting plot\ndisplays the proportion of total data variation explained by each of PC.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_screeplot(protein_pca)\n```\n\n::: {.cell-output-display}\n![](07_protein_exploration_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\nLooking at a scree plot can be useful when deciding which principle components\nto plot and investigate further. We now want to plot each of our samples in PCA \nspace. To do this we will use the `protein_pca$x` data. Typically a 2D PCA plot\nwill display PC1 and PC2, since these are the PCs that explain the most variation \nwithin the dataset, but it can also be useful to plot later PCs if they also \nexplain a large proportion of variation.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprotein_pca$x %>%\n  as_tibble() %>%\n  ggplot(aes(x = PC1, y = PC2)) +\n  geom_point(size = 3) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](07_protein_exploration_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\nIt is generally advisable to colour each point based on all possible explanatory\nvariables that may have contributed to the observed variation. In our case we\nonly have one - the cell cycle stage. To colour the points based on this condition\nwe can use the tidyverse `mutate` function to add a column defining the condition\nof each sample and then use `colour = condition` within our ggplot aesthetics.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprotein_pca$x %>%\n  as_tibble() %>%\n  mutate(condition = cc_qf[[\"log_norm_proteins\"]]$condition) %>%\n  ggplot(aes(x = PC1, y = PC2, colour = condition)) +\n  geom_point(size = 3) + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](07_protein_exploration_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nThis PCA plot shows clear clustering of samples based on their condition, which\nis what we would hope to see. This indicates that the observed variation could \nindeed be explained by cell cycle stage.\n\nFor more complicated multivariate experiments all possible explanatory \nvariables should be visualised. For example, if multiple batches of samples \nhave been prepared separately or several TMTplexes were used, these factors\nshould be visualised (e.g., by colour) on the PCA plot to see whether they \nare contributing the the observed variation. If the samples do cluster based on\nunwanted factors such as batch or TMTplex, additional normalisation may be \nrequired.\n\n\n::: {.callout-tip}\n#### Key Points\n\n- The `.n` column created by `aggregateFeatures` is a useful way to trace how many child features have been aggregated into a single parent feature\n- The `subsetByFeature` function can be used to generate a `QFeatures` object with all levels of data corresponding to one or more features of interest\n- Principal Component Analysis (PCA) is a dimensionality reduction method that can be used to visualise the relationship between explanatory variables and observed data. If samples cluster together based on a particular factor, this indicates that the factor\n\n:::\n\n## References {-}\n",
    "supporting": [
      "07_protein_exploration_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}