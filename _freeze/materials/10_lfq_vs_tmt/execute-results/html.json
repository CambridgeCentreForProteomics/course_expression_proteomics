{
  "hash": "f42d618ee383ce65f1a6603e0fd2b4fe",
  "result": {
    "markdown": "---\ntitle: Adapting this workflow to label-free proteomics data\nnumber-sections: true\nbibliography: course_refs.bib\neditor_options: \n  chunk_output_type: console\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n::: callout-tip\n#### Learning Objectives\n\n-   Understand how experimental design influences data structure and the required \nprocessing steps. In particular, how the analysis of label-free data could differ\nfrom that of the TMT use-case data.\n:::\n\n\n\n\n\n\nThe processing and analysis of label-free quantitative proteomics data to discover\ndifferentially abundant proteins follows the same overall workflow presented in \nthis course for our TMT use-case.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](figs/overall_flow_chart.png){fig-align='center' width=90%}\n:::\n:::\n\n\nHowever, some of the decisions made and exact approaches to each stage may differ\nwhen considering label-free data. These decisions are discussed below and \nsummarised in @tbl-comparison.\n\n\n::: {#tbl-comparison .cell tbl-cap='Main differences between processing workflow for TMT and label-free quantitative proteomics data prior to differential expression analyses'}\n::: {.cell-output-display}\n|Data processing step      |TMT                                                                                                         |Label-free                                                                                                                                  |\n|:-------------------------|:-----------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------|\n|Import                    |Import PSM-level data                                                                                       |Import PSM- or peptide-level data, depending on how software outputs quantification data                                                    |\n|Data cleaning             |Standard data cleaning steps                                                                                |Standard data cleaning steps                                                                                                                |\n|Quality control filtering |Additional thresholds on reporter ion signal-to-noise ratio, co-isolation interference and SPS mass matches |Additional quality control filters are software-specific and optional                                                                       |\n|Managing missing data     |Low proportion of missing values - remove with minimal data loss                                            |Higher proportion of missing values - Don't impute and use robustSummary summarisation to protein; If required, impute at lowest data level |\n|Transformation            |Log                                                                                                         |Log                                                                                                                                         |\n|Summarisation to protein  |Summarisation using sum or robustSummary method                                                             |Summarisation using robustSummary method                                                                                                    |\n|Normalisation             |Median-based normalisation                                                                                  |Median-based normalisation                                                                                                                  |\n|Statistics                |Linear model                                                                                                |Linear model                                                                                                                                |\n:::\n:::\n\n\n\n## Data import\n\n::: callout-note\nThese notes on data import are an adjunct to the [Import and infrastructure](./02_import_and_infrastructure.html)\nsection. Please first read through that material, since it includes background\nand clarifications which are not repeated here.\n:::\n\n\nAs outlined in [Import and infrastructure](./02_import_and_infrastructure.html),\nwe prefer to import the data into R at the lowest possible level. This allows us\nto have more control over and understanding of our data processing and analysis.\nFor the TMT-labelled use-case data, the lowest possible level of data for import\nwas the PSM-level. However, the analysis of label-free data often requires us to\nstart one level up at the peptide-level. This is because most identification \nsearches carried out on label-free MS data utilise an algorithm called retention\ntime (RT) alignment, which uses the match between runs (MBR) function. \n\n**What problem does retention time alignment address?**\n\nRetention time alignment aims to deal with the problem of missing values in \nlabel-free data-dependent acquisition (DDA) MS data. Since label-free samples \nare all analysed by independent MS runs, the stochastic nature of DDA means \nthat different peptides are identified and quantified between samples, hence\nthere are a high number of missing values. \n\n**How does retention time alignment work?**\n\nQuantification of label-free samples is achieved at the MS1 level. This means \nthat we have potentially useful quantitative information before we have any\npeptide identification (MS1 before MS2). In cases where a peptide is identified\nin some samples but not others, it is possible to align the retention times of\neach sample run and then compare the MS1 spectra. In this way, information can\nbe shared across runs and a peptide identification made in one run can be \nassigned to an MS1 spectra from a completely independent run, even if this\nspectrum does not have a corresponding MS2 spectrum.\n\n**Why does retention time alignment prevent analysis from PSM level?**\n\nThe process of RT alignment and MBRs occurs after the process of peptide\nspectrum matching. First, PSMs are derived from an identification search. This\nis done independently for each sample. The remaining spectra for which no PSM\nwas identified are then included in the RT alignment algorithm in an attempt to\nassign an identification. If successful, this means that there may be peptide\nlevel data in the absence of PSM level data. Hence, if we used PSM level data \nfor the processing and analysis of label-free data then we would lose out on \nthe benefit of RT alignment. \n\n**When to use peptide-level data for label-free analysis?**\n\nLabel-free data processed using Proteome Discoverer software should be processed\nfrom the peptide level. This means that we would use the file called \n`cell_cycle_total_proteome_analysis_PeptideGroups.txt` and import using \n`readQFeatures`, as outlined in [Import and infrastructure](./02_import_and_infrastructure.html).\nOther third party software, however, may still allow for label-free data to be\nprocessed from the PSM level. For example, MaxQuant users can still use the\n`evidence.txt` file. \n\n\n## Data cleaning, quality control filtering and FDR control\n\n::: callout-note\nThese notes on data import are an adjunct to the [Data processing](./03_data_processing.html)\nsection. Please first read through that material, since it includes background\nand clarifications which are not repeated here.\n:::\n\nMany of the basic data cleaning steps that we apply to TMT-labelled quantitative\nproteomics data are still applicable to label-free data. The following steps \nshould still be completed using the `filterFeatures` function, as demonstrated\nin the [Data processing](./03_data_processing.html) section.\n\nRemoval of features: \n\n1. Without a master protein accession = `filterFeatures(~ Master.Protein.Accessions != \"\")`\n2. Associated with contaminant accessions = `filterFeatures(~ Contaminant == \"False\")`\n3. Lacking quantitative data = `filterFeatures(~ Quan.Info != \"NoQuanValues\")`\n4. Which are not unique (based on user's definition) = `filterFeatures(~ Number.of.Protein.Groups == 1)`\n5. Which are not allocated as rank 1 = `filterFeatures(~ Rank == 1)` and `filterFeatures(~ Search.Engine.Rank == 1)`\n6. Which are not unambiguous matches = `filterFeatures(~ PSM.Ambiguity == \"Unambiguous\")`\n\nIn addition to these data cleaning steps, users may wish to remove features\n(peptides) which were not quantified based on a monoisotopic peak from their \nlabel-free dataset. This can be achieved using `filterFeatures(~ Quan.Info != \"NoneMonoisotopic\")`.\n\nThe three quality control filters applied to the TMT use-case data (`Isolation.Interference.in.Percent`,\n`Average.Reporter.SN` and `SPS.Mass.Matches.in.Percent`) are TMT-specific and\ncannot be applied to label-free data.\n\nProtein-level FDR control should be carried out on label-free data in the same\nway as was demonstrated in the main course materials.\n\n\n## Managing missing data\n\n::: callout-note\nThese notes on management of missing data are an adjunct to the [Data processing](./03_data_processing.html)\nsection which demonstrates the exploration of missing values within `QFeatures`.\nPlease first read through that material, since it includes background\nand clarifications which are not repeated here.\n:::\n\nLabel-free DDA proteomics data suffers from a greater number of missing values \nthan multiplexed label-based approaches (e.g., TMT). Indeed, this is one of the\nadvantages of multi-plexing samples using TMT as multiple samples (10 in\nthe use-case) can be run simultaneously on the MS and, therefore, the same peptides are\nselected for analysis across all samples. Since label-free samples are each\nanalysed via independent MS runs, the stochastic nature of DDA MS means that\ndifferent peptides may be identified and quantified across different runs, thus\nleading to a higher percentage of missing values.\n\nManagement of missing data should still follow the same three steps as discussed\nin the [Data processing](./03_data_processing.html) section: \n\n1. Explore the presence and distribution of missing values\n2. Filter data to remove features (rows) or samples (columns) with excessive missing values\n3. Consider the use of imputation\n\nSteps 1 and 2 were outlined in the main course content. For the use-case TMT \ndata we decided to remove all missing values rather than impute, since this would\nnot represent a drastic data loss. For datasets with a higher proportion\nof missing data, imputation can be considered. However, protein summarisation using an\napproach that can handle missing values appropriately is likely to be the optimal\napproach (see @sec-robust).\n\n\n**How can I impute using QFeatures?**\n\nImputation can be achieved within the `QFeatures` infrastructure using the \n`impute` function. To see what imputation methods this function facilitates we\ncan use `MsCoreUtils::imputeMethods()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMsCoreUtils::imputeMethods()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"bpca\"    \"knn\"     \"QRILC\"   \"MLE\"     \"MLE2\"    \"MinDet\"  \"MinProb\"\n [8] \"min\"     \"zero\"    \"mixed\"   \"nbavg\"   \"with\"    \"RF\"      \"none\"   \n```\n:::\n:::\n\n\nFor example, to impute using a k-NN method, we would use the following code,\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncc_qf <- impute(object = cc_qf,\n                method = \"knn\", \n                i = \"psms_filtered\",\n                name = \"psms_imputed\")\n\ncc_qf\n```\n:::\n\n\n\n**Which imputation method should I use for my data?**\n\nMissing values exist in the data for different reasons and these reasons dictate\nthe best way in which to impute. For example, if a value is missing \nbecause a peptide is completely absent or present at an abundance below the limit\nof detection then the most suitable replacement value is arguably the lowest\nabundance value recorded in the data set (since this represents the limit of\ndetection). Alternatively, if a value is missing because of stochastic technical\nreasons then it might be more appropriate to replace it with a value derived \nfrom a similar peptide. Overall, left-censored methods such as minimal value and\nlimit of detection approaches work best for data that is MNAR (intensity-dependent\nmissing values). Hot deck methods such as k-nearest neighbors, random forest and \nmaximum likelihood methods work better for data that is MCAR (intensity-independent).\nTo confuse the situation further, most data sets contain missing values that are\na mixture of MNAR and MCAR, so mixed imputation methods can be applied.\n\n\n**At what stage of the workflow should I impute?**\n\nThere are two aspects to consider when deciding when to impute: \n\n1. Which data level should be imputed - PSM, peptide or protein\n2. Whether the selected imputation method requires raw or log transformed quantitation data\n\nMissing values can be imputed at any data level e.g., PSM, peptide or protein.\nHowever, if missing values are not imputed in lower data levels then users should\nbe aware of how their missing values are treated during summarisation. Data summarisation\nmethods deal with missing values in different ways, either ignoring them, removing\nthem, considering missing values to be zero, or propagating them.\nThus, a combined strategy for imputation and summarisation must be arrived at. In general,\nwe advise that where imputation is necessary, it should be completed at the lowest \npossible data level to maintain transparency and allow users to check that the data \nstructure has not been drastically altered (e.g., by checking summary statistics or \nplotting density plots pre- and post-imputation). For LFQ, we advise summarisation \nusing the `robustSummary` method (see @sec-robust), which negates the need to\nimpute missing values.\n\n\n## Summarisation to protein level {#sec-robust}\n\nSummarisation of label-free data can still be achieved using `aggregateFeatures`.\nIf imputation has been completed, there should be no missing values left to \ninfluence summarisation. \n\nHere we will use `robustSummary`, a state-of-the art summarisation method that is able to summarise\neffectively even in the presence of missing values @Sticker2020. `robustSummary` directly models the\n**log**-transformed peptide-level quantification as being dependent upon the protein-level abundance of the sample plus\na peptide-level effect. Thus `robustSummary` estimates the protein-level abundances within the modelling. \nThis modelling-based approach to protein summarisation can handle relatively sparse data as\nit only considers the finite data. The only requirement for a peptide to be informative for\nestimating protein-level abundances using `robustSummary` is that the peptide be quantified in at least two samples.\n\nSince the `robustSummary` can handle missing values, it negates the need to impute missing values.\nIndeed, for LFQ experiments, we recommend not imputing and using `robustSummary` to \nsummarise to protein-level abundance. As expected, protein-level abundance estimates\nare less accurate the more sparse the data is, so removal of peptides with excessive \nmissing values may be worthwhile.\n\n\n## Logarithmic transformation\n\nAs discussed in the [Normalisation and data aggregation](./04_normalisation_aggregation.html) section, logarithmic\ntransformation of the data is required to give our data a Gaussian\ndistribution, as required for downstream differential abundance analysis. This \nstep can happen at any stage of the workflow, depending upon which imputation \nand summarisation methods are selected. If you impute or summarise the data using a method which\nrequires log transformation, then this step should have been done above. If not,\nlog2 transformation can be completed now.\n\n## Normalisation\n\nThe rules when normalising label-free data are the same as the use-case TMT data.\nSee [Data normalisation and data aggregation](./04_normalisation_aggregation.html) \nand [Using NormalyzerDE to explore normalisation methods](./09_normalyzer.html)\nfor more discussion.\n",
    "supporting": [
      "10_lfq_vs_tmt_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}