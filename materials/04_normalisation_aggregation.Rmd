---
title: Data normalisation and data aggregation
bibliography: course_refs.bib
editor_options: 
  chunk_output_type: console
---

::: {.callout-tip}
#### Learning Objectives

* Be able to aggregate peptide-level information to protein-level using the `aggregateFeatures` function in the `QFeatures` infrastructure
* Recognise the importance of log transformation (`logTransform`) 
* Know how to normalise your data (using `normalize`) and explore the most appropriate methods for expression proteomics data 

:::



```{r, eval=TRUE, include=FALSE}
library("QFeatures")
library("NormalyzerDE")
library("limma")
library("factoextra")
library("org.Hs.eg.db")
library("clusterProfiler")
library("enrichplot")
library("patchwork")
library("tidyverse")
library("here")

load(here("course_files/preprocessed//lesson03.rda"), verbose = TRUE)
```

Let's start by recapping which stage we have reached in the processing of our 
quantitative proteomics data. In the previous two lessons we have so far learnt,

* how to import our data into R and store it in a `QFeatures` object
* work with the structure of `QFeatures` objects
* clean data using a series of non-specific and data-dependent filters

In this next lesson we will continue processing the PSM level data, explore log
transformation, normalisation and then aggregate our data to protein-level
intensities.

```{r, echo = FALSE, fig.align = "center", out.width = "90%"}
knitr::include_graphics("figs/flow_chart/flow_chart.006.png", error = FALSE)
```


## Logarithmic transformation

Let's recap our data,

```{r}
cc_qf
```

Now that we are satisfied with our PSM quality, we need to log2 transform the
quantitative data. If we take a look at our current (raw) quantitative data we will 
see that our abundance values are dramatically skewed towards zero.


```{r, warning = FALSE, message=FALSE}
## Look at distribution of abundance values in untransformed data
cc_qf[["psms_imputed"]] %>%
  assay() %>%
  longFormat() %>%
  ggplot(aes(x = value)) +
  geom_histogram() + 
  theme_bw() +
  xlab("Abundance (raw)")
```


This is to be expected since the majority of proteins exist at low abundances
within the cell and only a few proteins are highly abundant. However, if we 
leave the quantitative data in a non-Gaussian distribution then we will not be
able to apply parametric statistical tests later on. Consider the case where
we have a protein with abundance values across three samples A, B and C. If the
abundance values were 0.1, 1 and 10, we can tell from just looking at the numbers
that the protein is 10-fold more abundant in sample B compared to sample A, and
10-fold more abundant in sample C than sample B. However, even though the fold-
changes are equal, the abundance values in A and B are much closer together on 
a linear scale than those of B and C. A parametric test would not account for 
this bias and would not consider A and B to be as equally different as B and C.
**By applying a logarithmic transformation we can convert our skewed asymmetrical data distribution into a symmetrical, Gaussian distribution.**

::: {.callout-note}
#### Why use base-2?
Although there is no mathematical reason for applying a log2 transformation
rather than using a higher base such as log10, the log2 scale provides an easy
visualisation tool. Any protein that halves in abundance between conditions will
have a 0.5 fold change, which translates into a log2 fold change of -1. Any
protein that doubles in abundance will have a fold change of 2 and a log2 fold
change of +1.
:::


::: {.callout-note}
#### At which stage of the processing should I perform log transformation?
Logarithmic transformation can be applied at any stage of the data processing.
We have chosen to log transform the data in this example prior to protein
aggregation as we will use the `robust` method for summarisation and this method
requires the data to be log transformed.

:::


```{r, warning = FALSE, message=FALSE}
## Look at distribution of abundance values in untransformed data
cc_qf[["psms_imputed"]] %>%
  assay() %>%
  longFormat() %>%
  ggplot(aes(x = log2(value))) +
  geom_histogram() + 
  theme_bw() +
  xlab("(Log2) Abundance")
```

To apply this log2 transformation to our data we use the `logTransform` function
and specify `base = 2`.

```{r}
cc_qf <- logTransform(object = cc_qf, 
                      base = 2, 
                      i = "psms_imputed", 
                      name = "log_psms_imputed")
```

Let's take a look again at our `QFeatures` object,

```{r}
cc_qf
```


## Feature aggregation 

```{r, echo = FALSE, fig.align = "center", out.width = "90%"}
knitr::include_graphics("figs/flow_chart/flow_chart.007.png", error = FALSE)
```


We have now reached the point where we are ready to aggregate our PSM level data
upward to the protein level. In a bottom-up MS experiment we initially identify
and quantify peptides. Further, each peptide can be identified and quantified on 
the basis of multiple matched spectra (the peptide spectrum matches, PSMs). We 
now want to group information from all PSMs that correspond to the same master
protein accession. 

To aggregate upwards from PSM to proteins we can either do this (i) directly
(from PSM straight to protein, if we are not interested in peptide level
information) or (ii) include an intermediate step of aggregating from PSM to
peptides, and then from the peptide level to proteins. Which you do will depend
on your biological question. For the purpose of demonstration, let's perform
the explicit step of PSM to peptide aggregation.

### Step 1: Aggregation of PSMs to peptides

In your console run the `aggregateFeatures` function on your `QFeatures` object.
We wish to aggregate from PSM to peptide level so pass the argument 
`i = "log_imputed_psms"` to specify we wish to aggregate the log transformed PSM
data, and then pass `fcol = "Sequence"` to specify we wish to
group by the peptide amino acid sequence.

```{r, warning = FALSE, message=FALSE}
cc_qf <- aggregateFeatures(cc_qf, 
                           i = "log_psms_imputed", 
                           fcol = "Sequence",
                           name = "log_peptides",
                           fun = MsCoreUtils::robustSummary,
                           na.rm = TRUE)

cc_qf
```

We see we have created a new assay called `log_peptides` and summarised 
`r nrow(cc_qf[["log_psms_imputed"]])` PSMs into `r nrow(cc_qf[["log_peptides"]])`
peptides.

There are many ways in which we can combine the quantitative values from each of
the contributing PSMs into a single consensus peptide or protein quantitation.
Simple methods for doing this include calculating the peptide or master protein
quantitation based on the mean, median or sum PSM quantitation. Although the use
of these simple mathematical functions can be effective, using `colMeans` or
`colMedians` can become difficult for data sets that still contain missing
values. Similarly, using `colSums` can result in protein quantitation values
being biased by the presence of missing values. Here we will use
`robustSummary`, a state-of-the art aggregation method that is able to aggregate
effectively even in the presence of missing values @Sticker2020.

### Step 2: Aggregation of peptides to proteins


Let's complete our aggregation by now aggregating our peptide level data to 
protein level data. Let's again use the `aggregateFeatures` function and pass
`fcol = "Master.Protein.Accessions"` to specify we wish to
group by `"Master.Protein.Accessions"`. 

```{r, warning = FALSE, message=FALSE}
cc_qf <- aggregateFeatures(cc_qf, 
                           i = "log_peptides", 
                           fcol = "Master.Protein.Accessions",
                           name = "log_proteins",
                           fun = MsCoreUtils::robustSummary,
                           na.rm = TRUE)

cc_qf
```

We see we have now created a new assay with `r nrow(cc_qf[["log_proteins"]])` 
protein groups. 


::: {.callout-note}
#### Protein groups
Since we are aggregating all PSMs that are assigned to the same master protein
accession, the downstream statistical analysis will be carried out at the 
level of protein groups. This is important to consider since most people will 
report "proteins" as displaying significantly different abundances across 
conditions, when in reality they are referring to protein groups.

:::

## Normalisation of quantitative data 

```{r, echo = FALSE, fig.align = "center", out.width = "90%"}
knitr::include_graphics("figs/flow_chart/flow_chart.008.png", error = FALSE)
```


We now have log protein level abundance data to which we could apply a parametric
statistical test. However, to perform a statistical test and discover whether any 
proteins differ in abundance between conditions (here cell cycle stages), we first
need to account for non-biological variance that may contribute to any differential
abundance. Such variance can arise from experimental error or technical variation,
although the latter is much more prominent when dealing with label-free DDA data.

Normalisation is the process by which we account for non-biological variation in
protein abundance between samples and attempt to return our quantitative data 
back to its 'normal' condition i.e., representative of how it was in the original
biological system. There are various methods that exist to normalise expression
proteomics data and it is necessary to consider which of these to apply on a 
case-by-case basis.

Unfortunately, there is not currently a single normalization method which
performs best for all quantitative proteomics datasets. Within the R Bioconductor
packages, however, exists [`NormalyzerDE`](https://bioconductor.org/packages/release/bioc/html/NormalyzerDE.html) @Willforss2018, a tool for evaluating different
normalisation methods.

:::{.callout-exercise}
#### Challenge 1: Exploring normalisation methods using NormalyzerDE
{{< level 1 >}}

The `NormalyzerDE` package provides a function called `normalyzer` which is 
useful for getting an overview of how different normalisation methods perform
on a dataset. The `normalyzer` function however **requires a raw intensity matrix
as input, prior to any log transformation.** 

1. Create a copy of your `cc_qf` dataset for testing normalisation methods.
Let's call this `norm_qf`.

```{r}
norm_qf <- cc_qf

norm_qf
```

2. Take the your data from the `psms_imputed` level and create a new assay in
your `QFeatures` object (`norm_qf`) that aggregates the data from this level 
directly to protein level. Call this assay `"proteins_direct"`.

```{r, message=FALSE, warning=FALSE, include=FALSE, eval=TRUE}
norm_qf <- aggregateFeatures(norm_qf,
                           i = "psms_imputed", 
                           fcol = "Master.Protein.Accessions",
                           name = "proteins_direct",
                           fun = MsCoreUtils::robustSummary,
                           na.rm = TRUE)

## Verify
experiments(norm_qf)
```

2. Run the `normalyzer` function on the newly created (un-transformed) 
protein level data using the below code,

```{r, eval=FALSE}
normalyzer(jobName = "normalyzer",
           experimentObj = norm_qf[["proteins_direct"]],
           sampleColName = "sample",
           groupColName = "condition",
           outputDir = "normalyzer_output",
           requireReplicates = FALSE)
```

If your job is successful a new folder will be created in your working directory
under `outputs` called `normalyzer`. Take a look at the PDF report. 

What method do you think is appropriate?

::: {.callout-answer collapse=true}

**Task 1** Create a new protein level assay that takes the imputed PSMs and 
aggregates directly to protein level.

```{r, message=FALSE, warning=FALSE, eval=FALSE}
cc_qf <- aggregateFeatures(cc_qf,
                           i = "psms_imputed", 
                           fcol = "Master.Protein.Accessions",
                           name = "proteins_direct",
                           fun = MsCoreUtils::robustSummary,
                           na.rm = TRUE)

## Verify
cc_qf
```

**Task 2** Running `normalyzer` on your assay.

```{r, eval=FALSE}
normalyzer(jobName = "normalyzer",
           experimentObj = cc_qf[["proteins_direct"]],
           sampleColName = "sample",
           groupColName = "condition",
           outputDir = "output",
           requireReplicates = FALSE)
```

Note: To run `normalyzer` on this data we need to pass `requireReplicates =
FALSE` as we have only one sample of the control. We pass the un-transformed
data as the `normalyzer` function does an internal log2 transformation as part
of its pipeline. For more details on using the `NormalyzerDE` package take a
look at the [package vignette](https://bioconductor.org/packages/release/bioc/vignettes/NormalyzerDE/inst/doc/vignette.html).

:::
:::


In the above challenge we used the `normalyzer` function to execute the `normalyzerDE` pipeline 
and produce an output PDF report. We passed the un-transformed protein level data
as the `normalyzer` function does its own log2 transformation prior to testing
any normalisation methods. A range of normalisations are tested on the data and
performance measures and visualisations are calculated to facilitate comparison
between different methods. 

The output report contains:

- Total intensity plot: Barplot showing the summed intensity in each sample for the log2-transformed data
- Total missing plot: Barplot showing the number of missing values found in each sample for the log2-transformed data
- Log2-MDS plot: MDS plot where data is reduced to two dimensions allowing inspection of the main global changes in the data
- Scatterplots: The first two samples from each dataset are plotted.
- Q-Q plots: QQ-plots are plotted for the first sample in each normalized dataset.
- Boxplots: Boxplots for all samples are plotted and colored according to the replicate grouping.
- Relative Log Expression (RLE) plots: Relative log expression value plots. Ratio between the expression of the variable and the median expression of this variable across all samples. The samples should be aligned around zero. Any deviation would indicate discrepancies in the data.
- Density plots: Density distributions for each sample using the density function. Can capture outliers (if single densities lies far from the others) and see if there is batch effects in the dataset (if for instance there is two clear collections of lines in the data).
- MDS plots: Multidimensional scaling plot using the `cmdscale()` function from the `stats` package. Is often able to show whether replicates group together, and whether there are any clear outliers in the data.
- Dendograms: Generated using the `hclust` function. Data is centered and scaled prior to analysis. Coloring of replicates is done using `as.phylo` from the `ape` package.

When interpreting our `normalyzer` output we need to consider our experimental
design. If all samples come from the same cells and we don't expect the treatment/conditions
to cause huge changes to the proteome, we expect the distributions of the
intensities to be roughly the same. We can compare across samples by plotting
the distribution in each sample together. When doing this you should get an idea
of where the majority of the intensities lie. We expect samples from the same
condition to have intensities that lie in the same range and if they do not then we
can assume that this is due to technical noise, and we want to normalise for this
technical variability. 

```{r fig-density, echo = FALSE, fig.align = "center", out.width = "90%"}
knitr::include_graphics("figs/density_plots_example.png", error = FALSE)
```

@fig-density shows a screenshot of the PDF report output from running the
`normalyzer` pipeline. We see that the data before normalisation (log2, topleft)
has curves/peaks at different locations and what we want to do is try and
register the curves at the same location and shift them according to their
median so all peaks of samples are overlapping. Which method to choose? Really
you need to look at the underlying summary statistics. For example, the mean is
very sensitive to outliers and in proteomics we often have outliers, so this is
not a method we would choose. The median (or median-based methods) are a good
choice for most quantitative proteomics data. Quantile normalisation is not
recommended for quantitative proteomics data. Quantile methods will not change
the median but will change all quantiles of the distribution so that all
distributions coincide. We could do this but this often causes problems due to
the fact that we have missing data in proteomics. This makes the normalisation
even more challenging than in other omics types of data.

The median method looks reasonable so we proceed to normalise our
data with this method. In `QFeatures` we can use the `normalize` function.
To see which other normalisation methods are supported within this function,
type `?normalize` to access the function's help page. 

```{r}
cc_qf <- normalize(cc_qf, 
                   i = "log_proteins", 
                   name = "log_norm_proteins",
                   method = "center.median")
```

Let's verify the normalisation  by viewing the `QFeatures` object. We can call
`experiments` to view all the assays we have created,

```{r}
experiments(cc_qf)
```


:::{.callout-exercise}
#### Challenge 2: Visualising the data prior and post-normalisation
{{< level 3 >}}

Create two boxplots pre- and post-normalisation to visualise the effect it has
had on the data and add colour to distinguish between conditions.

::: {.callout-answer collapse=true}

Using `ggplot2`,

```{r}
pre_norm <- cc_qf[["log_proteins"]] %>%
  assay() %>%
  longFormat() %>%
  ggplot(aes(x = colname, y = value)) +
  geom_boxplot() +
  labs(x = "Sample", y = "log2(abundance)", title = "Pre-normalization") 

post_norm <- cc_qf[["log_norm_proteins"]] %>%
  assay() %>%
  longFormat() %>%
  ggplot(aes(x = colname, y = value)) +
  geom_boxplot() +
  labs(x = "Sample", y = "log2(abundance)", title = "Post-normalization") 

pre_norm  + post_norm 
```

Colour coding by condition,

```{r}
pre_norm <- cc_qf[["log_proteins"]] %>%
  assay() %>%
  longFormat() %>%
  mutate(Condition = strsplit(colname, split = "_") %>% 
           sapply("[[", 1)) %>%
  ggplot(aes(x = colname, y = value, fill = Condition))  +
  geom_boxplot() +
  labs(x = "Sample", y = "log2(abundance)", title = "Pre-normalization") +
  theme(legend.position = "none")

post_norm <- cc_qf[["log_norm_proteins"]] %>%
  assay() %>%
  longFormat() %>%
  mutate(Condition = strsplit(colname, split = "_") %>% 
           sapply("[[", 1)) %>% 
  ggplot(aes(x = colname, y = value, fill = Condition))  +
  geom_boxplot() +
  labs(x = "Sample", y = "log2(abundance)", title = "Post-normalization") 

pre_norm + post_norm 
```

:::
:::

```{r, include=FALSE}
save(cc_qf, file = here("course_files/preprocessed/lesson04.rda"))
```



::: {.callout-tip}
#### Key Points

- Expression proteomics data should be log2 transformed to generate a Gaussian distribution which is suitable for parametric statistical testing. This is done using the `logTransform` function.
- Aggregation from lower level data (e.g., PSM) to high level identification and quantification (e.g., protein) is achieved using the `aggregateFeatures` function, which also creates explicit links between the original and newly created `assays`.
- To remove non-biological variation, data normalisation should be completed using the `normalize` function. To help users decide which normalisation method is appropriate for their data we recommend using the `normalyzer` function to create a report containing a comparison of methods.
:::

## References {-}
