---
title: Data normalisation and data aggregation
bibliography: course_refs.bib
editor_options: 
  chunk_output_type: console
---

::: {.callout-tip}
#### Learning Objectives

* Be able to aggregate peptide-level information to protein-level using the `aggregateFeatures` function in the `QFeatures` infrastructure
* Recognise the importance of log transformation (`logTransform`) 
* Know how to normalise your data (using `normalize`) and explore the most appropriate methods for expression proteomics data 
:::



```{r, eval=TRUE, include=FALSE}
library("QFeatures")
library("ggplot2")
library("stringr")
library("dplyr")
library("tibble")
library("NormalyzerDE")
library("corrplot")
library("Biostrings")
library("limma")
library("statmod")
library("factoextra")
library("org.Hs.eg.db")
library("clusterProfiler")
library("enrichplot")
library("patchwork")
load("output/lesson_5.rda", verbose = TRUE)
```

Let's start by recapping which stage we have reached in the processing of our 
quantitative proteomics data. In the previous two lessons we have so far learnt,

* how to import our data into R and store it in a `QFeatures` object
* work with the structure of `QFeatures` objects
* clean data using a series of non-specific and data-dependent filters

In this next lesson we will continue processing the PSM level data, explore log
transformation, normalisation and then aggregate our data to protein-level
intensities.

```{r, echo = FALSE, fig.align = "center", out.width = "90%"}
knitr::include_graphics("figs/flow_chart/flow_chart.006.png", error = FALSE)
```


## Logarithmic transformation

Let's recap our data,

```{r}
cc_qf
```

Now that we are satisfied with our PSM quality, we need to log2 transform the
quantitative data. If we take a look at our current (raw) quantitative data we will 
see that our abundance values are dramatically skewed towards zero.


```{r, warning = FALSE, message=FALSE}
## Look at distribution of abundance values in untransformed data
cc_qf[["psms_imputed"]] %>%
  assay() %>%
  longFormat() %>%
  ggplot(aes(x = value)) +
  geom_histogram() + 
  theme_bw() +
  xlab("Abundance (raw)")
```


This is to be expected since the majority of proteins exist at low abundances
within the cell and only a few proteins are highly abundant. However, if we 
leave the quantitative data in a non-Gaussian distribution then we will not be
able to apply parametric statistical tests later on. Consider the case where
we have a protein with abundance values across three samples A, B and C. If the
abundance values were 0.1, 1 and 10, we can tell from just looking at the numbers
that the protein is 10-fold more abundant in sample B compared to sample A, and
10-fold more abundant in sample C than sample B. However, even though the fold-
changes are equal, the abundance values in A and B are much closer together on 
a linear scale than those of B and C. A parametric test would not account for 
this bias and would not consider A and B to be as equally different as B and C.
By applying a logarithmic transformation we can convert our skewed asymmetrical 
data distribution into a symmetrical, Gaussian distribution, as visualised below. 

::: {.callout-note}
#### Why use base-2 logarithmic transformation?
Although there is no mathematical reason for applying a log2 transformation 
rather than using a higher base such as log10, the log2 scale provides an easy
visualisation tool. Any protein that halves in abundance between conditions will
have a 0.5 fold change, which translates into a log2 fold change of -1. Any protein
that doubles in abundance will have a fold change of 2 and a log2 fold change of
+1. 

:::


```{r, warning = FALSE, message=FALSE}
## Look at distribution of abundance values in untransformed data
cc_qf[["psms_imputed"]] %>%
  assay() %>%
  longFormat() %>%
  ggplot(aes(x = log2(value))) +
  geom_histogram() + 
  theme_bw() +
  xlab("(Log2) Abundance")
```

To apply this log2 transformation to our data we use the `logTransform` function
and specify `base = 2`.

```{r}
cc_qf <- logTransform(object = cc_qf, 
                      base = 2, 
                      i = "psms_imputed", 
                      name = "log_psms_imputed")
```

Let's take a look again at our `QFeatures` object,

```{r}
cc_qf
```

## Aggregation of PSMs to peptides to proteins

```{r, echo = FALSE, fig.align = "center", out.width = "90%"}
knitr::include_graphics("figs/flow_chart/flow_chart.007.png", error = FALSE)
```


We have now reached the point where we are ready to aggregate our PSM level data
upward to the protein level. In a bottom-up MS experiment we initially identify
and quantify peptides. Further, each peptide can be identified and quantified on 
the basis of multiple matched spectra (the peptide spectrum matches, PSMs). We 
now want to group information from all PSMs that correspond to the same master
protein accession. 

To aggregate upwards from PSM to proteins we can either do this (i) directly
(from PSM straight to protein, if we are not interested in peptide level
information) or (ii) include an intermediate step of aggregating from PSM to
peptides, and then from the peptide level to proteins. Which you do will depend
on your biological question. For the purpose of demonstration, let's perform
the explicit step of PSM to peptide aggregation.

In your console run the `aggregateFeatures` function on your `QFeatures` object.
We wish to aggregate from PSM to peptide level so pass the argument 
`i = "log_imputed_psms"` to specify we wish to aggregate the log transformed PSM
data, and then pass `fcol = "Sequence"` to specify we wish to
group by the peptide amino acid sequence.

```{r, warning = FALSE, message=FALSE}
cc_qf <- aggregateFeatures(cc_qf, 
                           i = "log_psms_imputed", 
                           fcol = "Sequence",
                           name = "log_peptides",
                           fun = MsCoreUtils::robustSummary,
                           na.rm = TRUE)

cc_qf
```

We see we have created a new assay called `log_peptides` and summarised 
`r nrow(cc_qf[["log_psms_imputed"]])` PSMs into `r nrow(cc_qf[["log_peptides"]])`
peptides.

There are many ways in which we can combine the quantitative values from each of
the contributing PSMs into a single consensus peptide or protein quantitation.
Simple methods for doing this include calculating the peptide or master protein
quantitation based on the mean, median or sum PSM quantitation. Although the use
of these simple mathematical functions can be effective, using `colMeans` or
`colMedians` can become difficult for data sets that still contain missing
values. Similarly, using `colSums` can result in protein quantitation values
being biased by the presence of missing values. Here we will use
`robustSummary`, a state-of-the art aggregation method that is able to aggregate
effectively even in the presence of missing values @Sticker2020.

Let's complete our aggregation by now aggregating our peptide level data to 
protein level data. Let's again use the `aggregateFeatures` function and pass
`fcol = "Master.Protein.Accessions"` to specify we wish to
group by `"Master.Protein.Accessions"`. 

```{r, warning = FALSE, message=FALSE}
cc_qf <- aggregateFeatures(cc_qf, 
                           i = "log_peptides", 
                           fcol = "Master.Protein.Accessions",
                           name = "log_proteins",
                           fun = MsCoreUtils::robustSummary,
                           na.rm = TRUE)

cc_qf
```

We see we have now created a new assay with `r nrow(cc_qf[["log_proteins"]])` 
protein groups. 


::: {.callout-note}
#### Protein groups
Since we are aggregating all PSMs that are assigned to the same master protein
accession, the downstream statistical analysis will be carried out at the 
level of protein groups. This is important to consider since most people will 
report "proteins" as displaying significantly different abundances across 
conditions, when in reality they are referring to protein groups.

:::

## Normalisation of quantitative data 

```{r, echo = FALSE, fig.align = "center", out.width = "90%"}
knitr::include_graphics("figs/flow_chart/flow_chart.008.png", error = FALSE)
```


We now have log protein level abundance data to which we could apply a parametric
statistical test. However, to perform a statistical test and discover whether any 
proteins differ in abundance between conditions (here cell cycle stages), we first
need to account for non-biological variance that may contribute to any differential
abundance. Such variance can arise from experimental error or technical variation,
although the latter is much more prominent when dealing with label-free DDA data.

Normalisation is the process by which we account for non-biological variation in
protein abundance between samples and attempt to return our quantitative data 
back to its 'normal' condition i.e., representative of how it was in the original
biological system. There are various methods that exist to normalise expression
proteomics data and it is necessary to consider which of these to apply on a 
case-by-case basis.

Unfortunately, there is not currently a single normalization method which
performs best for all quantitative proteomics datasets. Within the R Bioconductor
packages, however, exists [`NormalyzerDE`](https://bioconductor.org/packages/release/bioc/html/NormalyzerDE.html) @Willforss2018, a tool for evaluating different
normalisation methods.

:::{.callout-exercise}
#### Challenge 1: Using NormalyzerDE
{{< level 1 >}}

The `NormalyzerDE` package provides a function called `normalyzer` which is 
useful for getting an overview of how different normalisation methods perform
on a dataset. The `normalyzer` function however **requires a raw intensity matrix
as input, prior to any log transformation.** 

1. Taking the your data from the `psms_imputed` level, create a new assay in
your `QFeatures` object (`cc_qf`) that aggregates the data from this level 
directly to protein level. Call this assay `"proteins_direct"`.

2. Run the `normalyzer` function on the newly created (un-transformed) 
protein level data using the below code,

```{r, eval=FALSE}
normalyzer(jobName = "normalyzer",
           experimentObj = cc_qf[["proteins_direct"]],
           sampleColName = "sample",
           groupColName = "condition",
           outputDir = ".",
           requireReplicates = FALSE)
```

If your job is successful a new folder will be created in your working directory
called `normalyzer`. Take a look at the PDF report. What method do you think is
appropriate?

::: {.callout-answer collapse=true}

**Task 1** Create a new protein level assay that takes the imputed PSMs and 
aggregates directly to protein level.

```{r, message=FALSE, warning=FALSE}
cc_qf <- aggregateFeatures(cc_qf,
                           i = "psms_imputed", 
                           fcol = "Master.Protein.Accessions",
                           name = "proteins_direct",
                           fun = MsCoreUtils::robustSummary,
                           na.rm = TRUE)

## Verify
cc_qf
```

**Task 2** Running `normalyzer` on your assay.

```{r, eval=FALSE}
normalyzer(jobName = "normalyzer",
           experimentObj = cc_qf[["proteins_direct"]],
           sampleColName = "sample",
           groupColName = "condition",
           outputDir = ".",
           requireReplicates = FALSE)
```

Note: To run `normalyzer` on this data we need to pass `requireReplicates =
FALSE` as we have only one sample of the control. For more details on using the
`NormalyzerDE` package take a look at the [package vignette](https://bioconductor.org/packages/release/bioc/vignettes/NormalyzerDE/inst/doc/vignette.html).


:::
:::

The `"center.median"` method looks reasonable so we proceed to normalise our
data with this method. In `QFeatures` we can use the `normalize` function.
To see which other normalisation methods are supported within this function,
type `?normalize` to access the function's help page. Before normalising the 
data complete the following exercise,

:::{.callout-exercise}
#### Challenge 2: Aggregating PSM straight to protein
{{< level 1 >}}

For this biological question we are not interested in peptide level data and
wish to avoid the intermediate summarisation step of aggreagting PSMs to
peptides. Take the log PSM data and aggregate the data straight to the protein level. 

::: {.callout-answer collapse=true}

```{r, message=FALSE, warning=FALSE}
cc_qf <- aggregateFeatures(cc_qf,
                           i = "psms_imputed", 
                           fcol = "Master.Protein.Accessions",
                           name = "log_proteins_direct",
                           fun = MsCoreUtils::robustSummary,
                           na.rm = TRUE)

## Verify
cc_qf@ExperimentList
```

:::
:::


Now let's normalise the protein level data that has been directly aggregated
from PSMs, 

```{r}
cc_qf <- normalize(cc_qf, 
                   i = "log_proteins", 
                   name = "log_norm_proteins",
                   method = "center.median")
```

Let's verify the normalisation  by viewing the `QFeatures` object. We can call
`@ExperimentList` to view all the assays we have created,

```{r}
cc_qf@ExperimentList
```


:::{.callout-exercise}
#### Challenge 3: Visualising the data prior and post-normalisation
{{< level 3 >}}

Create two boxplots pre- and post-normalisation to visualise the effect it has
had on the data and add colour to distinguish between conditions.

::: {.callout-answer collapse=true}

Using `ggplot2`,

```{r}
pre_norm <- cc_qf[["log_proteins"]] %>%
  assay() %>%
  longFormat() %>%
  ggplot(aes(x = colname, y = value)) +
  geom_boxplot() +
  labs(x = "Sample", y = "log2(abundance)", title = "Pre-normalization") 

post_norm <- cc_qf[["log_norm_proteins"]] %>%
  assay() %>%
  longFormat() %>%
  ggplot(aes(x = colname, y = value)) +
  geom_boxplot() +
  labs(x = "Sample", y = "log2(abundance)", title = "Post-normalization") 

pre_norm  + post_norm 
```

Colour coding by condition,

```{r}
pre_norm <- cc_qf[["log_proteins"]] %>%
  assay() %>%
  longFormat() %>%
  mutate(Condition = strsplit(colname, split = "_") %>% 
           sapply("[[", 1)) %>%
  ggplot(aes(x = colname, y = value, fill = Condition))  +
  geom_boxplot() +
  labs(x = "Sample", y = "log2(abundance)", title = "Pre-normalization") +
  theme(legend.position = "none")

post_norm <- cc_qf[["log_norm_proteins"]] %>%
  assay() %>%
  longFormat() %>%
  mutate(Condition = strsplit(colname, split = "_") %>% 
           sapply("[[", 1)) %>% 
  ggplot(aes(x = colname, y = value, fill = Condition))  +
  geom_boxplot() +
  labs(x = "Sample", y = "log2(abundance)", title = "Post-normalization") 

pre_norm + post_norm 
```

:::
:::

```{r, include=FALSE}
save(cc_qf, file = "output/lesson_6.rda")
```



::: {.callout-tip}
#### Key Points

- Expression proteomics data should be log2 transformed to generate a Gaussian distribution which is suitable for parametric statistical testing. This is done using the `logTransform` function.
- Aggregation from lower level data (e.g., PSM) to high level identification and quantification (e.g., protein) is achieved using the `aggregateFeatures` function, which also creates explicit links between the original and newly created `assays`.
- To remove non-biological variation, data normalisation should be completed using the `normalize` function. To help users decide which normalisation method is appropriate for their data we recommend using the `normalyzer` function to create a report containing a comparison of methods.
:::

## References {-}


